{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7b1bf07",
   "metadata": {},
   "source": [
    "# Code Challenge 1 \u2014 B10 Reconstruction & Inference Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a95877",
   "metadata": {},
   "source": [
    "This notebook trains a lightweight CNN to reconstruct the missing Sentinel-2 B10 band and then applies a pre-trained EuroSAT classifier to Kaggle tiles after inserting the predicted band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b68e34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cyrilgabriele/anaconda3/envs/ml/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import os, random, math, re, zipfile, platform\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import rasterio\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, roc_curve, auc, roc_auc_score, precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available() and hasattr(torch, 'mps'):\n",
    "        torch.mps.manual_seed(seed)  # type: ignore[attr-defined]\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "def resolve_device() -> torch.device:\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "set_seed(RANDOM_SEED)\n",
    "\n",
    "DEVICE = resolve_device()\n",
    "print(f\"Using device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdd83418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already available at /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/EuroSAT_MS\n",
      "RUN_TIMESTAMP=20251112_114559\n",
      "Plots -> /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/plots\n",
      "Models -> /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/models\n",
      "Outputs -> /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/outputs\n"
     ]
    }
   ],
   "source": [
    "def _env_path(var_name: str, default: Path) -> Path:\n",
    "    default_path = Path(default)\n",
    "    value = os.environ.get(var_name)\n",
    "    return Path(value).expanduser() if value else default_path\n",
    "\n",
    "REPO_ROOT = Path.cwd()\n",
    "DATA_BASE = _env_path('EUROSAT_DATA_BASE', Path('/Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project'))\n",
    "DATA_ROOT = _env_path('EUROSAT_DATA_ROOT', DATA_BASE / 'EuroSAT_MS')\n",
    "DATA_ZIP = _env_path('EUROSAT_DATA_ZIP', DATA_BASE / 'EuroSAT_MS.zip')\n",
    "MODELS_DIR = _env_path('EUROSAT_MODELS_DIR', REPO_ROOT / 'artifacts' / 'models')\n",
    "PLOT_DIR = _env_path('EUROSAT_PLOTS_DIR', REPO_ROOT / 'artifacts' / 'plots')\n",
    "B10_MODEL_DIR = _env_path('EUROSAT_B10_MODEL_DIR', MODELS_DIR / 'cirrus_cnn')\n",
    "OUTPUT_DIR = _env_path('EUROSAT_OUTPUT_DIR', REPO_ROOT / 'outputs')\n",
    "KAGGLE_TEST_DIR = _env_path('EUROSAT_KAGGLE_TEST_DIR', DATA_BASE / 'kaggle_data' / 'testset' / 'testset')\n",
    "\n",
    "for path in (MODELS_DIR, PLOT_DIR, B10_MODEL_DIR, OUTPUT_DIR):\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not DATA_ROOT.exists():\n",
    "    if DATA_ZIP.exists():\n",
    "        print(f\"Extracting dataset from {DATA_ZIP} ...\")\n",
    "        with zipfile.ZipFile(DATA_ZIP, 'r') as zip_ref:\n",
    "            zip_ref.extractall(DATA_ROOT.parent)\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Dataset directory {DATA_ROOT} not found. Update EUROSAT_DATA_ROOT or place an archive at {DATA_ZIP}.\"\n",
    "        )\n",
    "else:\n",
    "    print(f\"Dataset already available at {DATA_ROOT}\")\n",
    "\n",
    "RUN_TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(f\"RUN_TIMESTAMP={RUN_TIMESTAMP}\")\n",
    "print(f\"Plots -> {PLOT_DIR}\")\n",
    "print(f\"Models -> {MODELS_DIR}\")\n",
    "print(f\"Outputs -> {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 3 \u2013 Canonical band bookkeeping\nThe EuroSAT training archive stores all 13 Sentinel-2 bands (`B1`\u2026`B12` plus `B8A`), whereas the Kaggle `.npy` tiles contain only 12 bands and skip `B10`. This cell documents each ordering so we can reason about reshaping tensors: `TRAIN_BAND_ORDER` enumerates the 13-band training layout, `TEST_BAND_ORDER` mirrors the Kaggle layout, and `DROP_BAND_NAME/INDEX` encode the missing band. We precompute `CANONICAL_12_BAND_ORDER` (training order without `B10`) and `TEST_TO_CANONICAL_12`, the index map that reorders a 12-band Kaggle tile into that canonical layout. Those arrays are reused later when we insert a synthetic/predicted `B10` slice and when we fine-tune the classifier, guaranteeing that every dataset obeys the same band semantics despite the test set\u2019s missing channel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efe40d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 10 classes\n",
      "Total samples: 27000\n"
     ]
    }
   ],
   "source": [
    "CLASS_NAMES = []\n",
    "CIRRUS_TILE_PATHS = []\n",
    "\n",
    "if DATA_ROOT.exists():\n",
    "    class_dirs = sorted([d for d in DATA_ROOT.iterdir() if d.is_dir()])\n",
    "    for d in class_dirs:\n",
    "        label = len(CLASS_NAMES)\n",
    "        CLASS_NAMES.append(d.name)\n",
    "        for tif_path in sorted(d.glob('*.tif')):\n",
    "            CIRRUS_TILE_PATHS.append(tif_path)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"{DATA_ROOT} not found. Extract the archive first.\")\n",
    "\n",
    "CLASS_TO_IDX = {name: idx for idx, name in enumerate(CLASS_NAMES)}\n",
    "IDX_TO_CLASS = {idx: name for name, idx in CLASS_TO_IDX.items()}\n",
    "\n",
    "print(f\"Detected {len(CLASS_NAMES)} classes\")\n",
    "print(f\"Total samples: {len(CIRRUS_TILE_PATHS)}\")\n",
    "\n",
    "TRAIN_BAND_ORDER = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B9', 'B10', 'B11', 'B12', 'B8A']\n",
    "TEST_BAND_ORDER = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12']\n",
    "DROP_BAND_NAME = 'B10'\n",
    "DROP_BAND_INDEX = TRAIN_BAND_ORDER.index(DROP_BAND_NAME)\n",
    "KEEP_IDX_13 = np.array([i for i, band in enumerate(TRAIN_BAND_ORDER) if band != DROP_BAND_NAME])\n",
    "CANONICAL_12_BAND_ORDER = [band for band in TRAIN_BAND_ORDER if band != DROP_BAND_NAME]\n",
    "KEEP_IDX_12 = np.arange(len(CANONICAL_12_BAND_ORDER))\n",
    "TEST_TO_CANONICAL_12 = np.array([CANONICAL_12_BAND_ORDER.index(band) for band in TEST_BAND_ORDER], dtype=np.int64)\n",
    "CIRRUS_SCALE = 10000.0\n",
    "CIRRUS_MODEL = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "band_order_utils",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_test_to_canonical(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Reorders 12-band Sentinel-2 L2A (test layout) tiles to the canonical training layout without B10.\"\"\"\n",
    "    if arr.shape[0] != len(TEST_BAND_ORDER):\n",
    "        raise ValueError(f\"Expected array with {len(TEST_BAND_ORDER)} bands, got {arr.shape[0]}\")\n",
    "    out = np.empty_like(arr)\n",
    "    for src_idx, dst_idx in enumerate(TEST_TO_CANONICAL_12):\n",
    "        out[dst_idx] = arr[src_idx]\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf8d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CirrusCNN(nn.Module):\n",
    "    def __init__(self, in_channels: int = 12, hidden_dim: int = 64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_dim, 1, kernel_size=1, bias=True)\n",
    "        )\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "def sample_patches(arr: np.ndarray, num_patches: int, patch_size: int, rng: np.random.Generator):\n",
    "    c, h, w = arr.shape\n",
    "    ps = min(patch_size, h, w)\n",
    "    patches_x = []\n",
    "    patches_y = []\n",
    "    for _ in range(num_patches):\n",
    "        top = int(rng.integers(0, max(1, h - ps + 1)))\n",
    "        left = int(rng.integers(0, max(1, w - ps + 1)))\n",
    "        patch = arr[:, top:top + ps, left:left + ps]\n",
    "        patches_x.append(patch[KEEP_IDX_13])\n",
    "        patches_y.append(patch[DROP_BAND_INDEX:DROP_BAND_INDEX + 1])\n",
    "    return patches_x, patches_y\n",
    "\n",
    "\n",
    "def _iter_patch_batches(tile_paths, patches_per_tile, patch_size, batch_size, rng: np.random.Generator, desc: str | None = None):\n",
    "    if not tile_paths:\n",
    "        return\n",
    "\n",
    "    order = np.arange(len(tile_paths))\n",
    "    rng.shuffle(order)\n",
    "    iterator = order\n",
    "    if desc is not None:\n",
    "        iterator = tqdm(order, desc=desc, leave=False)\n",
    "    batch_x, batch_y = [], []\n",
    "    for idx in iterator:\n",
    "        path = tile_paths[idx]\n",
    "        with rasterio.open(path) as src:\n",
    "            arr = src.read().astype(np.float32)\n",
    "        if arr.shape[0] != 13:\n",
    "            continue\n",
    "        arr = np.clip(arr, 0.0, CIRRUS_SCALE) / CIRRUS_SCALE\n",
    "        px, py = sample_patches(arr, patches_per_tile, patch_size, rng)\n",
    "        for x_patch, y_patch in zip(px, py):\n",
    "            batch_x.append(x_patch)\n",
    "            batch_y.append(y_patch)\n",
    "            if len(batch_x) == batch_size:\n",
    "                yield torch.from_numpy(np.stack(batch_x)).float(), torch.from_numpy(np.stack(batch_y)).float()\n",
    "                batch_x, batch_y = [], []\n",
    "    if batch_x:\n",
    "        yield torch.from_numpy(np.stack(batch_x)).float(), torch.from_numpy(np.stack(batch_y)).float()\n",
    "\n",
    "\n",
    "def fit_cirrus_cnn(sample_paths,\n",
    "                    patches_per_tile: int = 64,\n",
    "                    patch_size: int = 64,\n",
    "                    epochs: int = 5,\n",
    "                    batch_size: int = 128,\n",
    "                    lr: float = 5e-4,\n",
    "                    val_fraction: float = 0.1,\n",
    "                    max_tiles: int | None = None,\n",
    "                    early_stopping_patience: int = 3) -> dict:\n",
    "    if not sample_paths:\n",
    "        raise ValueError(\"No samples provided for cirrus CNN fitting\")\n",
    "\n",
    "    base_rng = np.random.default_rng(RANDOM_SEED)\n",
    "    paths = list(sample_paths)\n",
    "    if max_tiles is not None and len(paths) > max_tiles:\n",
    "        idx = base_rng.choice(len(paths), size=max_tiles, replace=False)\n",
    "        paths = [paths[i] for i in idx]\n",
    "    base_rng.shuffle(paths)\n",
    "\n",
    "    val_count = max(1, int(len(paths) * val_fraction))\n",
    "    val_paths = paths[:val_count]\n",
    "    train_paths = paths[val_count:]\n",
    "    if not train_paths:\n",
    "        raise ValueError(\"Not enough tiles for training after validation split\")\n",
    "\n",
    "    print(f\"[CirrusCNN] Training on {len(train_paths)} tiles (+{len(val_paths)} val) with {patches_per_tile} patches per tile per epoch.\")\n",
    "\n",
    "    model = CirrusCNN().to(DEVICE)\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "    best_state = None\n",
    "    best_val = float('inf')\n",
    "    best_epoch = 0\n",
    "\n",
    "    history = []\n",
    "\n",
    "    patience = max(1, early_stopping_patience)\n",
    "    no_improve_epochs = 0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_rng = np.random.default_rng(base_rng.integers(0, 1 << 32))\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_samples = 0\n",
    "        for xb, yb in _iter_patch_batches(train_paths, patches_per_tile, patch_size, batch_size, epoch_rng, desc=f'Train patches (epoch {epoch})'):\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * xb.size(0)\n",
    "            train_samples += xb.size(0)\n",
    "        train_loss = train_loss / max(1, train_samples)\n",
    "\n",
    "        val_rng = np.random.default_rng(epoch_rng.integers(0, 1 << 32))\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in _iter_patch_batches(val_paths, patches_per_tile, patch_size, batch_size, val_rng, desc=f'Val patches (epoch {epoch})'):\n",
    "                xb = xb.to(DEVICE)\n",
    "                yb = yb.to(DEVICE)\n",
    "                preds = model(xb)\n",
    "                val_loss += criterion(preds, yb).item() * xb.size(0)\n",
    "                val_samples += xb.size(0)\n",
    "        val_loss = val_loss / max(1, val_samples)\n",
    "        print(f\"[CirrusCNN] epoch {epoch}/{epochs} train={train_loss:.6f} val={val_loss:.6f}\")\n",
    "\n",
    "        history.append({'epoch': epoch, 'train_loss': train_loss, 'val_loss': val_loss, 'train_samples': train_samples, 'val_samples': val_samples})\n",
    "\n",
    "        if val_loss < best_val and val_samples > 0:\n",
    "            best_val = val_loss\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            best_epoch = epoch\n",
    "            no_improve_epochs = 0\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "            if no_improve_epochs >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch}; best val {best_val:.6f} at epoch {best_epoch}\")\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    eval_rng = np.random.default_rng(RANDOM_SEED + 1234)\n",
    "    mae_sum = 0.0\n",
    "    mse_sum = 0.0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in _iter_patch_batches(paths, patches_per_tile, patch_size, 256, eval_rng, desc='Evaluating cirrus CNN'):\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "            preds = model(xb)\n",
    "            mae_sum += torch.nn.functional.l1_loss(preds, yb, reduction='sum').item()\n",
    "            mse_sum += torch.nn.functional.mse_loss(preds, yb, reduction='sum').item()\n",
    "            count += xb.size(0)\n",
    "    mae = mae_sum / max(1, count)\n",
    "    rmse = math.sqrt(mse_sum / max(1, count))\n",
    "\n",
    "    print(f\"[CirrusCNN] Aggregated over ~{count} patches | MAE={mae:.6f} | RMSE={rmse:.6f}\")\n",
    "\n",
    "    if history:\n",
    "        hist_df = pd.DataFrame(history)\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        ax.plot(hist_df['epoch'], hist_df['train_loss'], label='Train')\n",
    "        ax.plot(hist_df['epoch'], hist_df['val_loss'], label='Val')\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('SmoothL1 Loss')\n",
    "        ax.set_title('CirrusCNN Training History')\n",
    "        ax.legend()\n",
    "        ax.grid(True, linestyle='--', alpha=0.3)\n",
    "        fig.tight_layout()\n",
    "        plot_path = PLOT_DIR / f'cirrus_cnn_history_{RUN_TIMESTAMP}.png'\n",
    "        fig.savefig(plot_path, dpi=180, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "        print(f\"Saved CirrusCNN training plot to {plot_path}\")\n",
    "\n",
    "    return {\n",
    "        'module': model,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'scale': CIRRUS_SCALE,\n",
    "    }\n",
    "\n",
    "\n",
    "def synthesize_cirrus(arr: np.ndarray, band_order: str | None = None) -> np.ndarray:\n",
    "    arr = np.asarray(arr, dtype=np.float32)\n",
    "    if CIRRUS_MODEL is None:\n",
    "        raise RuntimeError('CIRRUS_MODEL is None. Train or load the B10 reconstruction model before calling synthesize_cirrus.')\n",
    "\n",
    "    if band_order is None:\n",
    "        if arr.shape[0] == len(TRAIN_BAND_ORDER):\n",
    "            band_order = 'train'\n",
    "        elif arr.shape[0] == len(TEST_BAND_ORDER):\n",
    "            band_order = 'test'\n",
    "        elif arr.shape[0] == len(CANONICAL_12_BAND_ORDER):\n",
    "            band_order = 'canonical_12'\n",
    "        else:\n",
    "            raise ValueError(f\"Expected 12 or 13 bands, got {arr.shape}\")\n",
    "\n",
    "    scale = CIRRUS_MODEL['scale']\n",
    "    if band_order == 'train':\n",
    "        arr_scaled = np.clip(arr, 0.0, scale) / scale\n",
    "        feats = arr_scaled[KEEP_IDX_13]\n",
    "    elif band_order == 'test':\n",
    "        reordered = reorder_test_to_canonical(arr)\n",
    "        arr_scaled = np.clip(reordered, 0.0, scale) / scale\n",
    "        feats = arr_scaled\n",
    "    elif band_order == 'canonical_12':\n",
    "        if arr.shape[0] != len(CANONICAL_12_BAND_ORDER):\n",
    "            raise ValueError(f\"Expected canonical 12-band array with shape (12, H, W), got {arr.shape}\")\n",
    "        arr_scaled = np.clip(arr, 0.0, scale) / scale\n",
    "        feats = arr_scaled\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported band_order: {band_order}\")\n",
    "\n",
    "    tensor = torch.from_numpy(feats).unsqueeze(0).to(DEVICE)\n",
    "    module = CIRRUS_MODEL['module'].to(DEVICE)\n",
    "    CIRRUS_MODEL['module'] = module\n",
    "    module.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = module(tensor).squeeze(0).squeeze(0).detach().cpu().numpy()\n",
    "    pred = np.clip(pred, 0.0, 1.0) * scale\n",
    "    return pred.astype(np.float32)\n",
    "\n",
    "\n",
    "def pad_to_13_bands(arr: np.ndarray, band_order: str | None = None) -> np.ndarray:\n",
    "    arr = np.asarray(arr, dtype=np.float32)\n",
    "    if band_order is None:\n",
    "        if arr.shape[0] == len(TRAIN_BAND_ORDER):\n",
    "            band_order = 'train'\n",
    "        elif arr.shape[0] == len(TEST_BAND_ORDER):\n",
    "            band_order = 'test'\n",
    "        elif arr.shape[0] == len(CANONICAL_12_BAND_ORDER):\n",
    "            band_order = 'canonical_12'\n",
    "        else:\n",
    "            raise ValueError(f\"Expected 12 or 13 bands, got {arr.shape}\")\n",
    "\n",
    "    if band_order == 'train':\n",
    "        out = arr.copy()\n",
    "        out[DROP_BAND_INDEX] = synthesize_cirrus(arr, band_order='train')\n",
    "        return out\n",
    "\n",
    "    if band_order == 'test':\n",
    "        canonical = reorder_test_to_canonical(arr)\n",
    "    elif band_order == 'canonical_12':\n",
    "        if arr.shape[0] != len(CANONICAL_12_BAND_ORDER):\n",
    "            raise ValueError(f\"Expected canonical 12-band array with shape (12, H, W), got {arr.shape}\")\n",
    "        canonical = arr\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported band_order: {band_order}\")\n",
    "\n",
    "    cirrus = synthesize_cirrus(canonical, band_order='canonical_12')\n",
    "    return np.concatenate(\n",
    "        [canonical[:DROP_BAND_INDEX], cirrus[np.newaxis, ...], canonical[DROP_BAND_INDEX:]],\n",
    "        axis=0\n",
    "    )\n",
    "\n",
    "\n",
    "def robust_normalize(arr: np.ndarray) -> np.ndarray:\n",
    "    arr = arr.astype(np.float32, copy=False)\n",
    "    out = np.empty_like(arr)\n",
    "    for i in range(arr.shape[0]):\n",
    "        band = arr[i]\n",
    "        lo, hi = np.percentile(band, [2, 98])\n",
    "        if hi > lo:\n",
    "            band = (band - lo) / (hi - lo)\n",
    "        else:\n",
    "            min_v, max_v = band.min(), band.max()\n",
    "            if max_v > min_v:\n",
    "                band = (band - min_v) / (max_v - min_v)\n",
    "            else:\n",
    "                band = np.zeros_like(band)\n",
    "        out[i] = np.clip(band, 0.0, 1.0)\n",
    "    return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0617de28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CirrusCNN] Training on 24300 tiles (+2700 val) with 64 patches per tile per epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CirrusCNN] epoch 1/3 train=0.000277 val=0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CirrusCNN] epoch 2/3 train=0.000000 val=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CirrusCNN] epoch 3/3 train=0.000000 val=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CirrusCNN] Aggregated over ~1728000 patches | MAE=1.292108 | RMSE=0.030317\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CirrusCNN training plot to /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/plots/cirrus_cnn_history_20251112_114559.png\n",
      "Saved B10 reconstruction weights to /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/models/cirrus_cnn/cirrus_cnn_20251112_114559.pt\n"
     ]
    }
   ],
   "source": [
    "cirrus_paths = CIRRUS_TILE_PATHS\n",
    "CIRRUS_MODEL = fit_cirrus_cnn(cirrus_paths, epochs=3, patches_per_tile=64, patch_size=64)\n",
    "CIRRUS_MODEL['module'] = CIRRUS_MODEL['module'].to(DEVICE)\n",
    "CIRRUS_MODEL['module'].eval()\n",
    "\n",
    "cirrus_state_dict = {k: v.detach().cpu() for k, v in CIRRUS_MODEL['module'].state_dict().items()}\n",
    "\n",
    "b10_bundle = {\n",
    "    'state_dict': cirrus_state_dict,\n",
    "    'mae': CIRRUS_MODEL['mae'],\n",
    "    'rmse': CIRRUS_MODEL['rmse'],\n",
    "    'scale': CIRRUS_MODEL['scale'],\n",
    "    'drop_band_index': DROP_BAND_INDEX,\n",
    "    'keep_idx_12': KEEP_IDX_12,\n",
    "    'keep_idx_13': KEEP_IDX_13,\n",
    "    'train_band_order': TRAIN_BAND_ORDER,\n",
    "    'test_band_order': TEST_BAND_ORDER,\n",
    "    'canonical_12_band_order': CANONICAL_12_BAND_ORDER,\n",
    "}\n",
    "\n",
    "b10_model_path = B10_MODEL_DIR / f'cirrus_cnn_{RUN_TIMESTAMP}.pt'\n",
    "torch.save(b10_bundle, b10_model_path)\n",
    "print(f\"Saved B10 reconstruction weights to {b10_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b837ed81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading classifier Rhodham96/EuroSatCNN (source=auto)\n",
      "Resolved local directory: /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/Rhodham96-EuroSatCNN\n",
      "Loaded local weights from /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/Rhodham96-EuroSatCNN/pytorch_model.bin\n",
      "Using fallback processor.\n",
      "Classifier ready for inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = 'Rhodham96/EuroSatCNN'\n",
    "MODEL_SOURCE = 'auto'  # auto -> local first, fallback to HF\n",
    "LOCAL_MODEL_DIR_CANDIDATES = [\n",
    "    Path('/Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/Rhodham96-EuroSatCNN'),\n",
    "    MODELS_DIR / 'Rhodham96-EuroSatCNN',\n",
    "    Path('./local_models/Rhodham96-EuroSatCNN'),\n",
    "    Path('./models/Rhodham96-EuroSatCNN'),\n",
    "    Path.home() / 'models' / 'Rhodham96-EuroSatCNN',\n",
    "]\n",
    "\n",
    "LOCAL_MODEL_DIR = next((p for p in LOCAL_MODEL_DIR_CANDIDATES if p.exists()), LOCAL_MODEL_DIR_CANDIDATES[0])\n",
    "LOCAL_MODEL_DEF = LOCAL_MODEL_DIR / 'model_def.py'\n",
    "LOCAL_MODEL_WEIGHTS = LOCAL_MODEL_DIR / 'pytorch_model.bin'\n",
    "\n",
    "print(f\"Loading classifier {MODEL_ID} (source={MODEL_SOURCE})\")\n",
    "print(f\"Resolved local directory: {LOCAL_MODEL_DIR}\")\n",
    "model = None\n",
    "processor = None\n",
    "image_size = 224\n",
    "\n",
    "local_available = LOCAL_MODEL_DEF.exists() and LOCAL_MODEL_WEIGHTS.exists()\n",
    "\n",
    "if MODEL_SOURCE in ('auto', 'local') and local_available:\n",
    "    import importlib.util\n",
    "    spec = importlib.util.spec_from_file_location('eurosat_local_model', LOCAL_MODEL_DEF)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    if not hasattr(module, 'EuroSATCNN'):\n",
    "        raise AttributeError(f\"EuroSATCNN class not found in {LOCAL_MODEL_DEF}\")\n",
    "    EuroSATCNN = module.EuroSATCNN\n",
    "    model = EuroSATCNN(num_classes=len(CLASS_NAMES))\n",
    "    state_dict = torch.load(LOCAL_MODEL_WEIGHTS, map_location='cpu')\n",
    "    if isinstance(state_dict, dict) and 'state_dict' in state_dict:\n",
    "        state_dict = state_dict['state_dict']\n",
    "    model.load_state_dict(state_dict)\n",
    "    image_size = getattr(model, 'image_size', getattr(model, 'input_resolution', 64))\n",
    "    if not hasattr(model, 'image_size'):\n",
    "        model.image_size = image_size\n",
    "    print(f\"Loaded local weights from {LOCAL_MODEL_WEIGHTS}\")\n",
    "\n",
    "if model is None and MODEL_SOURCE in ('auto', 'hf'):\n",
    "    print(f\"Falling back to Hugging Face hub for {MODEL_ID}\")\n",
    "    model = AutoModelForImageClassification.from_pretrained(MODEL_ID)\n",
    "    image_size = getattr(model.config, 'image_size', image_size)\n",
    "    try:\n",
    "        processor = AutoImageProcessor.from_pretrained(MODEL_ID)\n",
    "    except (OSError, IndexError) as hf_proc_err:\n",
    "        print(f\"Processor load failed: {hf_proc_err}\")\n",
    "        processor = None\n",
    "\n",
    "if processor is None:\n",
    "    print('Using fallback processor.')\n",
    "\n",
    "    class EuroSatFallbackImageProcessor:\n",
    "        def __init__(self, image_size: int = 224):\n",
    "            self.image_size = image_size\n",
    "\n",
    "        def _prep_single(self, image):\n",
    "            if isinstance(image, np.ndarray):\n",
    "                tensor = torch.from_numpy(image)\n",
    "                if tensor.dtype != torch.float32:\n",
    "                    tensor = tensor.float()\n",
    "            elif torch.is_tensor(image):\n",
    "                tensor = image.float()\n",
    "            else:\n",
    "                tensor = torch.from_numpy(np.asarray(image, dtype=np.float32))\n",
    "\n",
    "            if tensor.ndim != 3:\n",
    "                raise ValueError(f\"Expected image with 3 dims, got {tuple(tensor.shape)}\")\n",
    "\n",
    "            if tensor.shape[0] not in (3, 13):\n",
    "                tensor = tensor.permute(2, 0, 1)\n",
    "\n",
    "            tensor = tensor.clamp(0.0, 1.0)\n",
    "\n",
    "            if tensor.shape[1:] != (self.image_size, self.image_size):\n",
    "                tensor = torch.nn.functional.interpolate(\n",
    "                    tensor.unsqueeze(0),\n",
    "                    size=(self.image_size, self.image_size),\n",
    "                    mode='bilinear',\n",
    "                    align_corners=False\n",
    "                ).squeeze(0)\n",
    "\n",
    "            return tensor\n",
    "\n",
    "        def __call__(self, images, return_tensors=None):\n",
    "            if isinstance(images, (list, tuple)):\n",
    "                batch = torch.stack([self._prep_single(img) for img in images])\n",
    "            else:\n",
    "                batch = self._prep_single(images).unsqueeze(0)\n",
    "\n",
    "            if return_tensors in (None, 'pt'):\n",
    "                return {'pixel_values': batch}\n",
    "\n",
    "            raise ValueError(f\"Unsupported return_tensors value: {return_tensors!r}\")\n",
    "\n",
    "    processor = EuroSatFallbackImageProcessor(image_size=image_size)\n",
    "\n",
    "if not hasattr(model, 'config'):\n",
    "    from types import SimpleNamespace\n",
    "    model.config = SimpleNamespace()\n",
    "\n",
    "model.config.label2id = {cls: idx for idx, cls in enumerate(CLASS_NAMES)}\n",
    "model.config.id2label = {idx: cls for cls, idx in model.config.label2id.items()}\n",
    "model.config.num_labels = len(CLASS_NAMES)\n",
    "model.config.image_size = image_size\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "print('Classifier ready for inference.')\n",
    "\n",
    "def get_model_logits(model, pixel_values):\n",
    "    try:\n",
    "        outputs = model(pixel_values=pixel_values)\n",
    "    except TypeError:\n",
    "        outputs = model(pixel_values)\n",
    "    if isinstance(outputs, torch.Tensor):\n",
    "        return outputs\n",
    "    if isinstance(outputs, dict):\n",
    "        if 'logits' in outputs:\n",
    "            return outputs['logits']\n",
    "        raise KeyError(\"Model output dict missing 'logits'\")\n",
    "    if hasattr(outputs, 'logits'):\n",
    "        return outputs.logits\n",
    "    raise RuntimeError('Model output does not contain logits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e89200af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] Split sizes -> train: 18900 | val: 4050 | test: 4050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 1/20 | train_loss=2.0665 train_acc=0.4220 | val_loss=1.3684 val_acc=0.5427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 2/20 | train_loss=1.1567 train_acc=0.6116 | val_loss=1.0284 val_acc=0.6637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 3/20 | train_loss=0.9174 train_acc=0.6913 | val_loss=0.8664 val_acc=0.7042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 4/20 | train_loss=0.7878 train_acc=0.7370 | val_loss=0.7549 val_acc=0.7531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 5/20 | train_loss=0.6981 train_acc=0.7683 | val_loss=0.6820 val_acc=0.7716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 6/20 | train_loss=0.6375 train_acc=0.7867 | val_loss=0.6339 val_acc=0.7864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 7/20 | train_loss=0.5912 train_acc=0.8003 | val_loss=0.6284 val_acc=0.7911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 8/20 | train_loss=0.5539 train_acc=0.8093 | val_loss=0.5656 val_acc=0.8099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 9/20 | train_loss=0.5237 train_acc=0.8214 | val_loss=0.5368 val_acc=0.8212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 10/20 | train_loss=0.4991 train_acc=0.8279 | val_loss=0.5220 val_acc=0.8289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 11/20 | train_loss=0.4760 train_acc=0.8349 | val_loss=0.4947 val_acc=0.8370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 12/20 | train_loss=0.4571 train_acc=0.8429 | val_loss=0.5005 val_acc=0.8400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 13/20 | train_loss=0.4402 train_acc=0.8498 | val_loss=0.4787 val_acc=0.8435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 14/20 | train_loss=0.4229 train_acc=0.8562 | val_loss=0.4958 val_acc=0.8425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 15/20 | train_loss=0.4113 train_acc=0.8584 | val_loss=0.4675 val_acc=0.8499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 16/20 | train_loss=0.3961 train_acc=0.8649 | val_loss=0.4490 val_acc=0.8511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 17/20 | train_loss=0.3826 train_acc=0.8679 | val_loss=0.4211 val_acc=0.8674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 18/20 | train_loss=0.3714 train_acc=0.8722 | val_loss=0.4084 val_acc=0.8681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 19/20 | train_loss=0.3616 train_acc=0.8762 | val_loss=0.3943 val_acc=0.8751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 20/20 | train_loss=0.3487 train_acc=0.8781 | val_loss=0.3903 val_acc=0.8758\n",
      "Loaded best fine-tuned weights from epoch 20 (val_acc=0.8758)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune/Test] loss=0.4012 acc=0.8647 | samples=4050\n",
      "Saved plot to /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/plots/finetune_20251112_114559_accuracy_loss.png\n",
      "Saved plot to /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/plots/finetune_20251112_114559_confusion_matrix.png\n",
      "Saved plot to /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/plots/finetune_20251112_114559_per_class_metrics.png\n",
      "Saved plot to /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/plots/finetune_20251112_114559_roc_curves.png\n",
      "Saved plot to /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/plots/finetune_20251112_114559_roc_auc_bars.png\n",
      "Saved plot to /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/plots/finetune_20251112_114559_precision_recall_curves.png\n",
      "Saved plot to /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/plots/finetune_20251112_114559_score_distribution.png\n",
      "Saved fine-tuned classifier weights to /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/models/Rhodham96_EuroSatCNN_cirrus_finetuned_20251112_114559.pt\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the classifier using CirrusCNN-synthesized B10 inputs so it sees the same distribution as at inference time\n",
    "\n",
    "\n",
    "def _build_finetune_records(val_fraction: float = 0.1, test_fraction: float = 0.0, limit_per_class: int | None = None, seed: int = RANDOM_SEED):\n",
    "    if not (0.0 < val_fraction < 1.0):\n",
    "        raise ValueError('val_fraction must be between 0 and 1 for fine-tuning splits')\n",
    "    if not (0.0 <= test_fraction < 1.0):\n",
    "        raise ValueError('test_fraction must be between 0 and 1 for fine-tuning splits')\n",
    "    if val_fraction + test_fraction >= 1.0:\n",
    "        raise ValueError('val_fraction + test_fraction must sum to less than 1.0 for fine-tuning splits')\n",
    "    rng = np.random.default_rng(seed)\n",
    "    train_records: list[tuple[Path, int]] = []\n",
    "    val_records: list[tuple[Path, int]] = []\n",
    "    test_records: list[tuple[Path, int]] = []\n",
    "    for class_name in CLASS_NAMES:\n",
    "        class_idx = CLASS_TO_IDX[class_name]\n",
    "        class_dir = DATA_ROOT / class_name\n",
    "        tif_paths = sorted(class_dir.glob('*.tif'))\n",
    "        if not tif_paths:\n",
    "            continue\n",
    "        if limit_per_class is not None and len(tif_paths) > limit_per_class:\n",
    "            selection = rng.choice(len(tif_paths), size=limit_per_class, replace=False)\n",
    "            tif_paths = [tif_paths[i] for i in selection]\n",
    "        order = rng.permutation(len(tif_paths))\n",
    "        tif_paths = [tif_paths[i] for i in order]\n",
    "        if len(tif_paths) < 2:\n",
    "            train_records.extend((path, class_idx) for path in tif_paths)\n",
    "            continue\n",
    "        total = len(tif_paths)\n",
    "        val_count = 0\n",
    "        test_count = 0\n",
    "        if val_fraction > 0.0:\n",
    "            val_count = max(1, int(total * val_fraction))\n",
    "            val_count = min(total - 1, val_count)\n",
    "        remaining = total - val_count\n",
    "        if test_fraction > 0.0 and remaining > 1:\n",
    "            test_count = max(1, int(total * test_fraction))\n",
    "            test_count = min(test_count, remaining - 1)\n",
    "        val_slice = tif_paths[:val_count]\n",
    "        test_slice = tif_paths[val_count:val_count + test_count]\n",
    "        train_slice = tif_paths[val_count + test_count:]\n",
    "        if not train_slice:\n",
    "            raise RuntimeError('Unable to keep at least one training tile per class; adjust val/test fractions or increase data availability.')\n",
    "        val_records.extend((path, class_idx) for path in val_slice)\n",
    "        test_records.extend((path, class_idx) for path in test_slice)\n",
    "        train_records.extend((path, class_idx) for path in train_slice)\n",
    "    if not train_records or not val_records:\n",
    "        raise RuntimeError('Unable to build stratified fine-tuning splits; consider lowering val_fraction or increasing data availability.')\n",
    "    if test_fraction > 0.0 and not test_records:\n",
    "        raise RuntimeError('Unable to build stratified fine-tuning test split; consider lowering test_fraction or increasing data availability.')\n",
    "    return train_records, val_records, test_records\n",
    "\n",
    "\n",
    "class EuroSATCirrusFinetuneDataset(Dataset):\n",
    "    def __init__(self, records, processor, inject_cirrus_b10: bool = True):\n",
    "        if processor is None:\n",
    "            raise RuntimeError('processor must be initialized before building the fine-tuning dataset')\n",
    "        if inject_cirrus_b10 and CIRRUS_MODEL is None:\n",
    "            raise RuntimeError('CIRRUS_MODEL is None; train or load the B10 reconstruction model before fine-tuning the classifier')\n",
    "        self.records = records\n",
    "        self.processor = processor\n",
    "        self.inject_cirrus_b10 = inject_cirrus_b10\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        path, label = self.records[idx]\n",
    "        with rasterio.open(path) as src:\n",
    "            arr = src.read().astype(np.float32)\n",
    "        if self.inject_cirrus_b10:\n",
    "            arr = pad_to_13_bands(arr, band_order='train')\n",
    "        arr = robust_normalize(arr)\n",
    "        arr = np.moveaxis(arr, 0, -1)\n",
    "        inputs = self.processor(images=arr, return_tensors='pt')\n",
    "        pixel_values = inputs['pixel_values'].squeeze(0)\n",
    "        return {\n",
    "            'pixel_values': pixel_values,\n",
    "            'labels': torch.tensor(label, dtype=torch.long),\n",
    "            'path': str(path),\n",
    "        }\n",
    "\n",
    "\n",
    "def _save_plot(fig, filename: str):\n",
    "    path = PLOT_DIR / filename\n",
    "    fig.savefig(path, dpi=180, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved plot to {path}\")\n",
    "\n",
    "\n",
    "def _plot_training_curves(history: list[dict], tag: str):\n",
    "    if not history:\n",
    "        return\n",
    "    epochs = [entry['epoch'] for entry in history]\n",
    "    train_loss = [entry['train_loss'] for entry in history]\n",
    "    val_loss = [entry['val_loss'] for entry in history]\n",
    "    train_acc = [entry['train_acc'] for entry in history]\n",
    "    val_acc = [entry['val_acc'] for entry in history]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    axes[0].plot(epochs, train_acc, label='Train')\n",
    "    axes[0].plot(epochs, val_acc, label='Val')\n",
    "    axes[0].set_title('Accuracy over epochs')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].grid(True, linestyle='--', alpha=0.3)\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].plot(epochs, train_loss, label='Train')\n",
    "    axes[1].plot(epochs, val_loss, label='Val')\n",
    "    axes[1].set_title('Loss over epochs')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].grid(True, linestyle='--', alpha=0.3)\n",
    "    axes[1].legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    _save_plot(fig, f'{tag}_accuracy_loss.png')\n",
    "\n",
    "\n",
    "def _plot_confusion_matrix(cm: np.ndarray, tag: str):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(len(CLASS_NAMES)),\n",
    "           yticks=np.arange(len(CLASS_NAMES)),\n",
    "           xticklabels=CLASS_NAMES,\n",
    "           yticklabels=CLASS_NAMES,\n",
    "           xlabel='Predicted label',\n",
    "           ylabel='True label',\n",
    "           title='Confusion matrix (test set)')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')\n",
    "\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], 'd'), ha='center', va='center', color='white' if cm[i, j] > cm.max() / 2 else 'black')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    _save_plot(fig, f'{tag}_confusion_matrix.png')\n",
    "\n",
    "\n",
    "def _plot_per_class_metrics(precision: np.ndarray, recall: np.ndarray, f1: np.ndarray, tag: str):\n",
    "    indices = np.arange(len(CLASS_NAMES))\n",
    "    width = 0.25\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    ax.bar(indices - width, precision, width, label='Precision')\n",
    "    ax.bar(indices, recall, width, label='Recall')\n",
    "    ax.bar(indices + width, f1, width, label='F1')\n",
    "    ax.set_xticks(indices)\n",
    "    ax.set_xticklabels(CLASS_NAMES, rotation=45, ha='right')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title('Per-class metrics (test set)')\n",
    "    ax.grid(True, axis='y', linestyle='--', alpha=0.3)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    _save_plot(fig, f'{tag}_per_class_metrics.png')\n",
    "\n",
    "\n",
    "def _plot_roc_curves(y_true: np.ndarray, probs: np.ndarray, tag: str):\n",
    "    classes = np.arange(len(CLASS_NAMES))\n",
    "    y_bin = label_binarize(y_true, classes=classes)\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    auc_scores: dict[str, float] = {}\n",
    "    for idx, class_name in enumerate(CLASS_NAMES):\n",
    "        fpr, tpr, _ = roc_curve(y_bin[:, idx], probs[:, idx])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        auc_scores[class_name] = roc_auc\n",
    "        ax.plot(fpr, tpr, label=f'{class_name} (AUC={roc_auc:.3f})')\n",
    "    micro_fpr, micro_tpr, _ = roc_curve(y_bin.ravel(), probs.ravel())\n",
    "    micro_auc = auc(micro_fpr, micro_tpr)\n",
    "    auc_scores['micro'] = micro_auc\n",
    "    ax.plot(micro_fpr, micro_tpr, color='black', linewidth=2, label=f'Micro (AUC={micro_auc:.3f})')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('ROC curves (one-vs-rest)')\n",
    "    ax.legend(fontsize='small', ncol=2)\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    fig.tight_layout()\n",
    "    _save_plot(fig, f'{tag}_roc_curves.png')\n",
    "    return auc_scores\n",
    "\n",
    "\n",
    "def _plot_roc_auc_bars(auc_scores: dict[str, float], tag: str):\n",
    "    labels = list(auc_scores.keys())\n",
    "    scores = [auc_scores[label] for label in labels]\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    ax.bar(labels, scores, color='teal')\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_ylabel('AUC')\n",
    "    ax.set_title('ROC-AUC by class')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    ax.grid(True, axis='y', linestyle='--', alpha=0.3)\n",
    "    fig.tight_layout()\n",
    "    _save_plot(fig, f'{tag}_roc_auc_bars.png')\n",
    "\n",
    "\n",
    "def _plot_precision_recall_curves(y_true: np.ndarray, probs: np.ndarray, tag: str):\n",
    "    classes = np.arange(len(CLASS_NAMES))\n",
    "    y_bin = label_binarize(y_true, classes=classes)\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    for idx, class_name in enumerate(CLASS_NAMES):\n",
    "        precision, recall, _ = precision_recall_curve(y_bin[:, idx], probs[:, idx])\n",
    "        pr_auc = auc(recall, precision)\n",
    "        ax.plot(recall, precision, label=f'{class_name} (AUC={pr_auc:.3f})')\n",
    "    precision_micro, recall_micro, _ = precision_recall_curve(y_bin.ravel(), probs.ravel())\n",
    "    pr_auc_micro = auc(recall_micro, precision_micro)\n",
    "    ax.plot(recall_micro, precision_micro, color='black', linewidth=2, label=f'Micro (AUC={pr_auc_micro:.3f})')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_title('Precision-Recall curves (one-vs-rest)')\n",
    "    ax.legend(fontsize='small', ncol=2)\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    fig.tight_layout()\n",
    "    _save_plot(fig, f'{tag}_precision_recall_curves.png')\n",
    "\n",
    "\n",
    "def _plot_score_distribution(y_true: np.ndarray, y_pred: np.ndarray, probs: np.ndarray, tag: str):\n",
    "    max_probs = probs.max(axis=1)\n",
    "    correct = y_pred == y_true\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.hist(max_probs[correct], bins=30, alpha=0.7, label='Correct', color='green', density=True)\n",
    "    ax.hist(max_probs[~correct], bins=30, alpha=0.7, label='Incorrect', color='red', density=True)\n",
    "    ax.set_xlabel('Predicted probability (max class)')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Prediction confidence distribution')\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    fig.tight_layout()\n",
    "    _save_plot(fig, f'{tag}_score_distribution.png')\n",
    "\n",
    "\n",
    "def finetune_classifier_with_cirrus(model, processor, cfg: dict):\n",
    "    train_records, val_records, test_records = _build_finetune_records(\n",
    "        val_fraction=cfg.get('val_fraction', 0.1),\n",
    "        test_fraction=cfg.get('test_fraction', 0.0),\n",
    "        limit_per_class=cfg.get('limit_per_class'),\n",
    "        seed=cfg.get('seed', RANDOM_SEED),\n",
    "    )\n",
    "    train_dataset = EuroSATCirrusFinetuneDataset(train_records, processor, inject_cirrus_b10=True)\n",
    "    val_dataset = EuroSATCirrusFinetuneDataset(val_records, processor, inject_cirrus_b10=True)\n",
    "    test_dataset = EuroSATCirrusFinetuneDataset(test_records, processor, inject_cirrus_b10=True) if test_records else None\n",
    "\n",
    "    num_workers = cfg.get('num_workers')\n",
    "    if num_workers is None:\n",
    "        num_workers = 0 if platform.system() == 'Darwin' else 4\n",
    "    pin_memory = DEVICE.type == 'cuda'\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=cfg.get('train_batch_size', 32),\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=cfg.get('val_batch_size', 64),\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "    )\n",
    "    test_loader = None\n",
    "    if test_dataset is not None:\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=cfg.get('test_batch_size', cfg.get('val_batch_size', 64)),\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=pin_memory,\n",
    "        )\n",
    "\n",
    "    print(f\"[FineTune] Split sizes -> train: {len(train_records)} | val: {len(val_records)} | test: {len(test_records)}\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=cfg.get('lr', 5e-5),\n",
    "        weight_decay=cfg.get('weight_decay', 1e-2),\n",
    "    )\n",
    "    max_grad_norm = cfg.get('max_grad_norm', 1.0)\n",
    "    epochs = cfg.get('epochs', 3)\n",
    "    transfer_non_blocking = DEVICE.type == 'cuda'\n",
    "\n",
    "    best_state = None\n",
    "    best_val_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    history = []\n",
    "\n",
    "    patience = max(1, cfg.get('early_stopping_patience', 3))\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_samples = 0\n",
    "        for batch in tqdm(train_loader, desc=f'Fine-tune train {epoch}/{epochs}', leave=False):\n",
    "            pixel_values = batch['pixel_values'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "            labels = batch['labels'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            logits = get_model_logits(model, pixel_values)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            if max_grad_norm is not None and max_grad_norm > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * labels.size(0)\n",
    "            train_correct += (logits.argmax(dim=1) == labels).sum().item()\n",
    "            train_samples += labels.size(0)\n",
    "        train_loss = train_loss / max(1, train_samples)\n",
    "        train_acc = train_correct / max(1, train_samples)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=f'Fine-tune val {epoch}/{epochs}', leave=False):\n",
    "                pixel_values = batch['pixel_values'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "                labels = batch['labels'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "                logits = get_model_logits(model, pixel_values)\n",
    "                loss = criterion(logits, labels)\n",
    "                val_loss += loss.item() * labels.size(0)\n",
    "                val_correct += (logits.argmax(dim=1) == labels).sum().item()\n",
    "                val_samples += labels.size(0)\n",
    "        val_loss = val_loss / max(1, val_samples)\n",
    "        val_acc = val_correct / max(1, val_samples)\n",
    "\n",
    "        history.append({\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'train_samples': train_samples,\n",
    "            'val_samples': val_samples,\n",
    "        })\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            no_improve_epochs = 0\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "            if no_improve_epochs >= patience:\n",
    "                print(f\"[FineTune] Early stopping triggered at epoch {epoch} (patience={patience}).\")\n",
    "                break\n",
    "\n",
    "        print(f\"[FineTune] epoch {epoch}/{epochs} | train_loss={train_loss:.4f} train_acc={train_acc:.4f} | val_loss={val_loss:.4f} val_acc={val_acc:.4f}\")\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "        print(f\"Loaded best fine-tuned weights from epoch {best_epoch} (val_acc={best_val_acc:.4f})\")\n",
    "\n",
    "    test_results = None\n",
    "    test_plot_payload = None\n",
    "    if test_loader is not None:\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct = 0\n",
    "        test_samples = 0\n",
    "        collected_probs = []\n",
    "        collected_labels = []\n",
    "        collected_preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc='Fine-tune test', leave=False):\n",
    "                pixel_values = batch['pixel_values'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "                labels = batch['labels'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "                logits = get_model_logits(model, pixel_values)\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                loss = criterion(logits, labels)\n",
    "                test_loss += loss.item() * labels.size(0)\n",
    "                predictions = probs.argmax(dim=1)\n",
    "                test_correct += (predictions == labels).sum().item()\n",
    "                test_samples += labels.size(0)\n",
    "                collected_probs.append(probs.detach().cpu())\n",
    "                collected_labels.append(labels.detach().cpu())\n",
    "                collected_preds.append(predictions.detach().cpu())\n",
    "        test_loss = test_loss / max(1, test_samples)\n",
    "        test_acc = test_correct / max(1, test_samples)\n",
    "        if collected_probs:\n",
    "            probs_np = torch.cat(collected_probs).numpy()\n",
    "            labels_np = torch.cat(collected_labels).numpy()\n",
    "            preds_np = torch.cat(collected_preds).numpy()\n",
    "            test_plot_payload = {\n",
    "                'labels': labels_np,\n",
    "                'preds': preds_np,\n",
    "                'probs': probs_np,\n",
    "            }\n",
    "        test_results = {\n",
    "            'test_loss': test_loss,\n",
    "            'test_acc': test_acc,\n",
    "            'test_samples': test_samples,\n",
    "        }\n",
    "        print(f\"[FineTune/Test] loss={test_loss:.4f} acc={test_acc:.4f} | samples={test_samples}\")\n",
    "\n",
    "    plot_tag = f'finetune_{RUN_TIMESTAMP}'\n",
    "    _plot_training_curves(history, plot_tag)\n",
    "    if test_plot_payload is not None:\n",
    "        labels = test_plot_payload['labels']\n",
    "        preds = test_plot_payload['preds']\n",
    "        probs = test_plot_payload['probs']\n",
    "        cm = confusion_matrix(labels, preds, labels=list(range(len(CLASS_NAMES))))\n",
    "        _plot_confusion_matrix(cm, plot_tag)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            labels,\n",
    "            preds,\n",
    "            labels=list(range(len(CLASS_NAMES))),\n",
    "            zero_division=0,\n",
    "        )\n",
    "        _plot_per_class_metrics(precision, recall, f1, plot_tag)\n",
    "        auc_scores = _plot_roc_curves(labels, probs, plot_tag)\n",
    "        _plot_roc_auc_bars(auc_scores, plot_tag)\n",
    "        _plot_precision_recall_curves(labels, probs, plot_tag)\n",
    "        _plot_score_distribution(labels, preds, probs, plot_tag)\n",
    "\n",
    "    model.eval()\n",
    "    if cfg.get('save_weights', True):\n",
    "        tag = MODEL_ID.replace('/', '_') if MODEL_ID else 'eurosat_classifier'\n",
    "        save_path = MODELS_DIR / f'{tag}_cirrus_finetuned_{RUN_TIMESTAMP}.pt'\n",
    "        torch.save({\n",
    "            'state_dict': model.state_dict(),\n",
    "            'config': getattr(model, 'config', None),\n",
    "            'history': history,\n",
    "            'class_names': CLASS_NAMES,\n",
    "            'test_results': test_results,\n",
    "        }, save_path)\n",
    "        print(f\"Saved fine-tuned classifier weights to {save_path}\")\n",
    "\n",
    "    return history, test_results\n",
    "\n",
    "\n",
    "FINETUNE_CFG = {\n",
    "    'val_fraction': 0.15,\n",
    "    'test_fraction': 0.15,\n",
    "    'limit_per_class': None,\n",
    "    'epochs': 20,\n",
    "    'early_stopping_patience': 3,\n",
    "    'train_batch_size': 32,\n",
    "    'val_batch_size': 64,\n",
    "    'test_batch_size': 64,\n",
    "    'lr': 5e-5,\n",
    "    'weight_decay': 1e-2,\n",
    "    'max_grad_norm': 1.0,\n",
    "    'num_workers': None,\n",
    "    'save_weights': True,\n",
    "    'seed': RANDOM_SEED,\n",
    "}\n",
    "RUN_CLASSIFIER_FINE_TUNE = True\n",
    "\n",
    "finetune_history = None\n",
    "finetune_test_results = None\n",
    "if RUN_CLASSIFIER_FINE_TUNE:\n",
    "    finetune_history, finetune_test_results = finetune_classifier_with_cirrus(model, processor, FINETUNE_CFG)\n",
    "else:\n",
    "    print('Skipping classifier fine-tuning. Set RUN_CLASSIFIER_FINE_TUNE = True to enable it.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "183c4358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EuroSATNPYDataset(Dataset):\n",
    "    def __init__(self, paths, processor):\n",
    "        self.paths = paths\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        arr = np.load(path, allow_pickle=False)\n",
    "        if arr.ndim == 3 and arr.shape[0] not in (12, 13) and arr.shape[-1] in (12, 13):\n",
    "            arr = np.moveaxis(arr, -1, 0)\n",
    "        arr = pad_to_13_bands(arr, band_order='test')\n",
    "        arr = robust_normalize(arr)\n",
    "        arr = np.moveaxis(arr, 0, -1)\n",
    "        inputs = self.processor(images=arr, return_tensors='pt')\n",
    "        pixel_values = inputs['pixel_values'].squeeze(0)\n",
    "        sample_id = self._extract_id(path.stem)\n",
    "        return {'pixel_values': pixel_values, 'id': sample_id}\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_id(stem: str) -> int:\n",
    "        match = re.search(r'(\\d+)$', stem)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        digits = ''.join(ch for ch in stem if ch.isdigit())\n",
    "        return int(digits) if digits else -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a64c6a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4232 inference tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Kaggle inference: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 133/133 [00:11<00:00, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission to /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/outputs/submission_with_cirrus_20251112_114559.csv\n",
      "   test_id                 label\n",
      "0        0  HerbaceousVegetation\n",
      "1        1                 River\n",
      "2        2  HerbaceousVegetation\n",
      "3        3               SeaLake\n",
      "4        4                 River\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "TEST_ROOT = KAGGLE_TEST_DIR\n",
    "if not TEST_ROOT.exists():\n",
    "    raise FileNotFoundError(f\"Expected test directory at {TEST_ROOT}\")\n",
    "\n",
    "npy_paths = sorted(TEST_ROOT.glob('*.npy'))\n",
    "if not npy_paths:\n",
    "    npy_paths = sorted(TEST_ROOT.glob('**/*.npy'))\n",
    "\n",
    "if len(npy_paths) == 0:\n",
    "    raise FileNotFoundError('No .npy files found in Kaggle test directory')\n",
    "\n",
    "print(f\"Found {len(npy_paths)} inference tiles\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0 if platform.system() == 'Darwin' else 2\n",
    "PIN_MEMORY = DEVICE.type == 'cuda'\n",
    "\n",
    "kaggle_dataset = EuroSATNPYDataset(npy_paths, processor)\n",
    "kaggle_loader = DataLoader(\n",
    "    kaggle_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "pred_ids = []\n",
    "pred_indices = []\n",
    "transfer_non_blocking = DEVICE.type == 'cuda'\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(kaggle_loader, desc='Kaggle inference'):\n",
    "        pixel_values = batch['pixel_values'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "        logits = get_model_logits(model, pixel_values)\n",
    "        preds = logits.argmax(dim=1).cpu().tolist()\n",
    "        pred_indices.extend(preds)\n",
    "        if isinstance(batch['id'], torch.Tensor):\n",
    "            pred_ids.extend(batch['id'].cpu().tolist())\n",
    "        else:\n",
    "            pred_ids.extend(batch['id'])\n",
    "\n",
    "pred_labels = [IDX_TO_CLASS[idx] for idx in pred_indices]\n",
    "submission = pd.DataFrame({'test_id': pred_ids, 'label': pred_labels})\n",
    "submission = submission.sort_values('test_id').reset_index(drop=True)\n",
    "\n",
    "submission_name = f'submission_with_cirrus_{RUN_TIMESTAMP}.csv'\n",
    "submission_path = OUTPUT_DIR / submission_name\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Saved submission to {submission_path}\")\n",
    "print(submission.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}