{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7b1bf07",
   "metadata": {},
   "source": [
    "# Code Challenge 1 — B10 Reconstruction & Inference Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a95877",
   "metadata": {},
   "source": [
    "This notebook trains a lightweight CNN to reconstruct the missing Sentinel-2 B10 band and then applies a pre-trained EuroSAT classifier to Kaggle tiles after inserting the predicted band."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1548d2c7",
   "metadata": {},
   "source": [
    "### Cell 2 – Imports, RNG seeding, and device selection\n",
    "Loads every dependency (NumPy/Pandas/matplotlib, PyTorch, torchvision, rasterio, sklearn metrics), defines helper utilities to fix Python/NumPy/PyTorch seeds, and picks the best accelerator (`cuda`, `mps`, or CPU). This establishes deterministic behavior and reports which device the rest of the notebook will target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b68e34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cyrilgabriele/anaconda3/envs/ml/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import os, random, math, re, zipfile, platform\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "from torchvision.models import ConvNeXt_Base_Weights\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import rasterio\n",
    "from rasterio.plot import reshape_as_image\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, roc_curve, auc, roc_auc_score, precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available() and hasattr(torch, 'mps'):\n",
    "        torch.mps.manual_seed(seed)  # type: ignore[attr-defined]\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "def resolve_device() -> torch.device:\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "set_seed(RANDOM_SEED)\n",
    "\n",
    "DEVICE = resolve_device()\n",
    "print(f\"Using device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68033788",
   "metadata": {},
   "source": [
    "### Cell 3 – Resolve data/model paths and ensure prerequisites\n",
    "Uses `_env_path` to gather all filesystem roots (EuroSAT data, Kaggle test set, artifacts dirs), creates the directories, and unzips `EuroSAT_MS.zip` if the extracted folder is absent. It also stamps the `RUN_TIMESTAMP` and prints where plots, models, and outputs will land.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdd83418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already available at /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/EuroSAT_MS\n",
      "RUN_TIMESTAMP=20251211_140038\n",
      "Plots -> /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/plots\n",
      "Models -> /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/models\n",
      "Outputs -> /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/outputs\n"
     ]
    }
   ],
   "source": [
    "def _env_path(var_name: str, default: Path) -> Path:\n",
    "    default_path = Path(default)\n",
    "    value = os.environ.get(var_name)\n",
    "    return Path(value).expanduser() if value else default_path\n",
    "\n",
    "REPO_ROOT = Path.cwd()\n",
    "DATA_BASE = _env_path('EUROSAT_DATA_BASE', Path('/Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project'))\n",
    "DATA_ROOT = _env_path('EUROSAT_DATA_ROOT', DATA_BASE / 'EuroSAT_MS')\n",
    "DATA_ZIP = _env_path('EUROSAT_DATA_ZIP', DATA_BASE / 'EuroSAT_MS.zip')\n",
    "MODELS_DIR = _env_path('EUROSAT_MODELS_DIR', REPO_ROOT / 'artifacts' / 'models')\n",
    "PLOT_DIR = _env_path('EUROSAT_PLOTS_DIR', REPO_ROOT / 'artifacts' / 'plots')\n",
    "B10_MODEL_DIR = _env_path('EUROSAT_B10_MODEL_DIR', MODELS_DIR / 'cirrus_cnn')\n",
    "OUTPUT_DIR = _env_path('EUROSAT_OUTPUT_DIR', REPO_ROOT / 'outputs')\n",
    "KAGGLE_TEST_DIR = _env_path('EUROSAT_KAGGLE_TEST_DIR', DATA_BASE / 'kaggle_data' / 'testset' / 'testset')\n",
    "\n",
    "for path in (MODELS_DIR, PLOT_DIR, B10_MODEL_DIR, OUTPUT_DIR):\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not DATA_ROOT.exists():\n",
    "    if DATA_ZIP.exists():\n",
    "        print(f\"Extracting dataset from {DATA_ZIP} ...\")\n",
    "        with zipfile.ZipFile(DATA_ZIP, 'r') as zip_ref:\n",
    "            zip_ref.extractall(DATA_ROOT.parent)\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Dataset directory {DATA_ROOT} not found. Update EUROSAT_DATA_ROOT or place an archive at {DATA_ZIP}.\"\n",
    "        )\n",
    "else:\n",
    "    print(f\"Dataset already available at {DATA_ROOT}\")\n",
    "\n",
    "RUN_TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(f\"RUN_TIMESTAMP={RUN_TIMESTAMP}\")\n",
    "print(f\"Plots -> {PLOT_DIR}\")\n",
    "print(f\"Models -> {MODELS_DIR}\")\n",
    "print(f\"Outputs -> {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325340a6",
   "metadata": {},
   "source": [
    "### Cell 4 – Scan EuroSAT dataset and record band semantics\n",
    "Enumerates every EuroSAT class folder, builds the `(path,label)` list for training CirrusCNN and the classifier, and documents how the 13-band training layout differs from the 12-band Kaggle tensors. The resulting index maps (`TRAIN_BAND_ORDER`, `TEST_BAND_ORDER`, etc.) drive all later band reordering/padding logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efe40d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 10 classes\n",
      "Total samples: 27000\n"
     ]
    }
   ],
   "source": [
    "CLASS_NAMES = []\n",
    "CIRRUS_TILE_PATHS = []\n",
    "\n",
    "if DATA_ROOT.exists():\n",
    "    class_dirs = sorted([d for d in DATA_ROOT.iterdir() if d.is_dir()])\n",
    "    for d in class_dirs:\n",
    "        label = len(CLASS_NAMES)\n",
    "        CLASS_NAMES.append(d.name)\n",
    "        for tif_path in sorted(d.glob('*.tif')):\n",
    "            CIRRUS_TILE_PATHS.append(tif_path)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"{DATA_ROOT} not found. Extract the archive first.\")\n",
    "\n",
    "CLASS_TO_IDX = {name: idx for idx, name in enumerate(CLASS_NAMES)}\n",
    "IDX_TO_CLASS = {idx: name for name, idx in CLASS_TO_IDX.items()}\n",
    "\n",
    "print(f\"Detected {len(CLASS_NAMES)} classes\")\n",
    "print(f\"Total samples: {len(CIRRUS_TILE_PATHS)}\")\n",
    "\n",
    "TRAIN_BAND_ORDER = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B9', 'B10', 'B11', 'B12', 'B8A']\n",
    "TEST_BAND_ORDER = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12']\n",
    "DROP_BAND_NAME = 'B10'\n",
    "DROP_BAND_INDEX = TRAIN_BAND_ORDER.index(DROP_BAND_NAME)\n",
    "KEEP_IDX_13 = np.array([i for i, band in enumerate(TRAIN_BAND_ORDER) if band != DROP_BAND_NAME])\n",
    "CANONICAL_12_BAND_ORDER = [band for band in TRAIN_BAND_ORDER if band != DROP_BAND_NAME]\n",
    "KEEP_IDX_12 = np.arange(len(CANONICAL_12_BAND_ORDER))\n",
    "TEST_TO_CANONICAL_12 = np.array([CANONICAL_12_BAND_ORDER.index(band) for band in TEST_BAND_ORDER], dtype=np.int64)\n",
    "CIRRUS_SCALE = 10000.0\n",
    "CIRRUS_MODEL = None\n",
    "RGB_BANDS = ('B4', 'B3', 'B2')\n",
    "RGB_BAND_INDICES = [TRAIN_BAND_ORDER.index(b) for b in RGB_BANDS]\n",
    "def normalize_for_display(band_data: np.ndarray) -> np.ndarray:\n",
    "    band_data = np.asarray(band_data, dtype=np.float32)\n",
    "    lower = np.percentile(band_data, 2, axis=(0, 1))\n",
    "    upper = np.percentile(band_data, 98, axis=(0, 1))\n",
    "    denom = np.maximum(upper - lower, 1e-6)\n",
    "    normalized = (band_data - lower) / denom\n",
    "    return np.clip(normalized, 0.0, 1.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def multispectral_to_rgb(arr: np.ndarray) -> np.ndarray:\n",
    "    if arr.ndim != 3:\n",
    "        raise ValueError(f'Expected 3D array (C,H,W), got {arr.shape}')\n",
    "    image = reshape_as_image(arr)\n",
    "    normalized = normalize_for_display(image)\n",
    "    return normalized[:, :, RGB_BAND_INDICES]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db04fc3",
   "metadata": {},
   "source": [
    "### Cell 5 – Reorder Kaggle tiles into canonical layout\n",
    "Provides `reorder_test_to_canonical`, the helper that shuffles Kaggle’s 12-band order into the canonical order (without B10) so the B10 synthesizer and classifier can reason over consistent channel semantics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "band_order_utils",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_test_to_canonical(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Reorders 12-band Sentinel-2 L2A (test layout) tiles to the canonical training layout without B10.\"\"\"\n",
    "    if arr.shape[0] != len(TEST_BAND_ORDER):\n",
    "        raise ValueError(f\"Expected array with {len(TEST_BAND_ORDER)} bands, got {arr.shape[0]}\")\n",
    "    out = np.empty_like(arr)\n",
    "    for src_idx, dst_idx in enumerate(TEST_TO_CANONICAL_12):\n",
    "        out[dst_idx] = arr[src_idx]\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32be3f64",
   "metadata": {},
   "source": [
    "### Cell 6 – CirrusCNN architecture, patch sampling, and normalization utilities\n",
    "Defines the lightweight convolutional regressor for B10 reconstruction plus all supporting plumbing: random patch extraction from GeoTIFFs (with percentile-based scaling), the minibatch iterator, the training loop with SmoothL1 loss + early stopping + history plotting, MAE/RMSE evaluation, and helpers (`synthesize_cirrus`, `pad_to_13_bands`, `robust_normalize`) that insert the predicted band back into any 12-band tensor. This is the heavy lifting block that makes Kaggle tiles compatible with the 13-band training distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf8d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CirrusCNN(nn.Module):\n",
    "    def __init__(self, in_channels: int = 12, hidden_dim: int = 64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_dim, 1, kernel_size=1, bias=True)\n",
    "        )\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "def sample_patches(arr: np.ndarray, num_patches: int, patch_size: int, rng: np.random.Generator):\n",
    "    c, h, w = arr.shape\n",
    "    ps = min(patch_size, h, w)\n",
    "    patches_x = []\n",
    "    patches_y = []\n",
    "    for _ in range(num_patches):\n",
    "        top = int(rng.integers(0, max(1, h - ps + 1)))\n",
    "        left = int(rng.integers(0, max(1, w - ps + 1)))\n",
    "        patch = arr[:, top:top + ps, left:left + ps]\n",
    "        patches_x.append(patch[KEEP_IDX_13])\n",
    "        patches_y.append(patch[DROP_BAND_INDEX:DROP_BAND_INDEX + 1])\n",
    "    return patches_x, patches_y\n",
    "\n",
    "\n",
    "def _iter_patch_batches(tile_paths, patches_per_tile, patch_size, batch_size, rng: np.random.Generator, desc: str | None = None):\n",
    "    if not tile_paths:\n",
    "        return\n",
    "\n",
    "    order = np.arange(len(tile_paths))\n",
    "    rng.shuffle(order)\n",
    "    iterator = order\n",
    "    if desc is not None:\n",
    "        iterator = tqdm(order, desc=desc, leave=False)\n",
    "    batch_x, batch_y = [], []\n",
    "    for idx in iterator:\n",
    "        path = tile_paths[idx]\n",
    "        with rasterio.open(path) as src:\n",
    "            arr = src.read().astype(np.float32)\n",
    "        if arr.shape[0] != 13:\n",
    "            continue\n",
    "        arr = np.clip(arr, 0.0, CIRRUS_SCALE) / CIRRUS_SCALE\n",
    "        px, py = sample_patches(arr, patches_per_tile, patch_size, rng)\n",
    "        for x_patch, y_patch in zip(px, py):\n",
    "            batch_x.append(x_patch)\n",
    "            batch_y.append(y_patch)\n",
    "            if len(batch_x) == batch_size:\n",
    "                yield torch.from_numpy(np.stack(batch_x)).float(), torch.from_numpy(np.stack(batch_y)).float()\n",
    "                batch_x, batch_y = [], []\n",
    "    if batch_x:\n",
    "        yield torch.from_numpy(np.stack(batch_x)).float(), torch.from_numpy(np.stack(batch_y)).float()\n",
    "\n",
    "\n",
    "def fit_cirrus_cnn(sample_paths,\n",
    "                    patches_per_tile: int = 64,\n",
    "                    patch_size: int = 64,\n",
    "                    epochs: int = 5,\n",
    "                    batch_size: int = 128,\n",
    "                    lr: float = 5e-4,\n",
    "                    val_fraction: float = 0.1,\n",
    "                    max_tiles: int | None = None,\n",
    "                    early_stopping_patience: int = 3) -> dict:\n",
    "    if not sample_paths:\n",
    "        raise ValueError(\"No samples provided for cirrus CNN fitting\")\n",
    "\n",
    "    base_rng = np.random.default_rng(RANDOM_SEED)\n",
    "    paths = list(sample_paths)\n",
    "    if max_tiles is not None and len(paths) > max_tiles:\n",
    "        idx = base_rng.choice(len(paths), size=max_tiles, replace=False)\n",
    "        paths = [paths[i] for i in idx]\n",
    "    base_rng.shuffle(paths)\n",
    "\n",
    "    val_count = max(1, int(len(paths) * val_fraction))\n",
    "    val_paths = paths[:val_count]\n",
    "    train_paths = paths[val_count:]\n",
    "    if not train_paths:\n",
    "        raise ValueError(\"Not enough tiles for training after validation split\")\n",
    "\n",
    "    print(f\"[CirrusCNN] Training on {len(train_paths)} tiles (+{len(val_paths)} val) with {patches_per_tile} patches per tile per epoch.\")\n",
    "\n",
    "    model = CirrusCNN().to(DEVICE)\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "    best_state = None\n",
    "    best_val = float('inf')\n",
    "    best_epoch = 0\n",
    "\n",
    "    history = []\n",
    "\n",
    "    patience = max(1, early_stopping_patience)\n",
    "    no_improve_epochs = 0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_rng = np.random.default_rng(base_rng.integers(0, 1 << 32))\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_samples = 0\n",
    "        for xb, yb in _iter_patch_batches(train_paths, patches_per_tile, patch_size, batch_size, epoch_rng, desc=f'Train patches (epoch {epoch})'):\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * xb.size(0)\n",
    "            train_samples += xb.size(0)\n",
    "        train_loss = train_loss / max(1, train_samples)\n",
    "\n",
    "        val_rng = np.random.default_rng(epoch_rng.integers(0, 1 << 32))\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in _iter_patch_batches(val_paths, patches_per_tile, patch_size, batch_size, val_rng, desc=f'Val patches (epoch {epoch})'):\n",
    "                xb = xb.to(DEVICE)\n",
    "                yb = yb.to(DEVICE)\n",
    "                preds = model(xb)\n",
    "                val_loss += criterion(preds, yb).item() * xb.size(0)\n",
    "                val_samples += xb.size(0)\n",
    "        val_loss = val_loss / max(1, val_samples)\n",
    "        print(f\"[CirrusCNN] epoch {epoch}/{epochs} train={train_loss:.6f} val={val_loss:.6f}\")\n",
    "\n",
    "        history.append({'epoch': epoch, 'train_loss': train_loss, 'val_loss': val_loss, 'train_samples': train_samples, 'val_samples': val_samples})\n",
    "\n",
    "        if val_loss < best_val and val_samples > 0:\n",
    "            best_val = val_loss\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            best_epoch = epoch\n",
    "            no_improve_epochs = 0\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "            if no_improve_epochs >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch}; best val {best_val:.6f} at epoch {best_epoch}\")\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    eval_rng = np.random.default_rng(RANDOM_SEED + 1234)\n",
    "    mae_sum = 0.0\n",
    "    mse_sum = 0.0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in _iter_patch_batches(paths, patches_per_tile, patch_size, 256, eval_rng, desc='Evaluating cirrus CNN'):\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "            preds = model(xb)\n",
    "            mae_sum += torch.nn.functional.l1_loss(preds, yb, reduction='sum').item()\n",
    "            mse_sum += torch.nn.functional.mse_loss(preds, yb, reduction='sum').item()\n",
    "            count += xb.size(0)\n",
    "    mae = mae_sum / max(1, count)\n",
    "    rmse = math.sqrt(mse_sum / max(1, count))\n",
    "\n",
    "    print(f\"[CirrusCNN] Aggregated over ~{count} patches | MAE={mae:.6f} | RMSE={rmse:.6f}\")\n",
    "\n",
    "    if history:\n",
    "        hist_df = pd.DataFrame(history)\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        ax.plot(hist_df['epoch'], hist_df['train_loss'], label='Train')\n",
    "        ax.plot(hist_df['epoch'], hist_df['val_loss'], label='Val')\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('SmoothL1 Loss')\n",
    "        ax.set_title('CirrusCNN Training History')\n",
    "        ax.legend()\n",
    "        ax.grid(True, linestyle='--', alpha=0.3)\n",
    "        fig.tight_layout()\n",
    "        plot_path = PLOT_DIR / f'cirrus_cnn_history_{RUN_TIMESTAMP}.png'\n",
    "        fig.savefig(plot_path, dpi=180, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "        print(f\"Saved CirrusCNN training plot to {plot_path}\")\n",
    "\n",
    "    return {\n",
    "        'module': model,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'scale': CIRRUS_SCALE,\n",
    "    }\n",
    "\n",
    "\n",
    "def synthesize_cirrus(arr: np.ndarray, band_order: str | None = None) -> np.ndarray:\n",
    "    arr = np.asarray(arr, dtype=np.float32)\n",
    "    if CIRRUS_MODEL is None:\n",
    "        raise RuntimeError('CIRRUS_MODEL is None. Train or load the B10 reconstruction model before calling synthesize_cirrus.')\n",
    "\n",
    "    if band_order is None:\n",
    "        if arr.shape[0] == len(TRAIN_BAND_ORDER):\n",
    "            band_order = 'train'\n",
    "        elif arr.shape[0] == len(TEST_BAND_ORDER):\n",
    "            band_order = 'test'\n",
    "        elif arr.shape[0] == len(CANONICAL_12_BAND_ORDER):\n",
    "            band_order = 'canonical_12'\n",
    "        else:\n",
    "            raise ValueError(f\"Expected 12 or 13 bands, got {arr.shape}\")\n",
    "\n",
    "    scale = CIRRUS_MODEL['scale']\n",
    "    if band_order == 'train':\n",
    "        arr_scaled = np.clip(arr, 0.0, scale) / scale\n",
    "        feats = arr_scaled[KEEP_IDX_13]\n",
    "    elif band_order == 'test':\n",
    "        reordered = reorder_test_to_canonical(arr)\n",
    "        arr_scaled = np.clip(reordered, 0.0, scale) / scale\n",
    "        feats = arr_scaled\n",
    "    elif band_order == 'canonical_12':\n",
    "        if arr.shape[0] != len(CANONICAL_12_BAND_ORDER):\n",
    "            raise ValueError(f\"Expected canonical 12-band array with shape (12, H, W), got {arr.shape}\")\n",
    "        arr_scaled = np.clip(arr, 0.0, scale) / scale\n",
    "        feats = arr_scaled\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported band_order: {band_order}\")\n",
    "\n",
    "    tensor = torch.from_numpy(feats).unsqueeze(0).to(DEVICE)\n",
    "    module = CIRRUS_MODEL['module'].to(DEVICE)\n",
    "    CIRRUS_MODEL['module'] = module\n",
    "    module.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = module(tensor).squeeze(0).squeeze(0).detach().cpu().numpy()\n",
    "    pred = np.clip(pred, 0.0, 1.0) * scale\n",
    "    return pred.astype(np.float32)\n",
    "\n",
    "\n",
    "def pad_to_13_bands(arr: np.ndarray, band_order: str | None = None) -> np.ndarray:\n",
    "    arr = np.asarray(arr, dtype=np.float32)\n",
    "    if band_order is None:\n",
    "        if arr.shape[0] == len(TRAIN_BAND_ORDER):\n",
    "            band_order = 'train'\n",
    "        elif arr.shape[0] == len(TEST_BAND_ORDER):\n",
    "            band_order = 'test'\n",
    "        elif arr.shape[0] == len(CANONICAL_12_BAND_ORDER):\n",
    "            band_order = 'canonical_12'\n",
    "        else:\n",
    "            raise ValueError(f\"Expected 12 or 13 bands, got {arr.shape}\")\n",
    "\n",
    "    if band_order == 'train':\n",
    "        out = arr.copy()\n",
    "        out[DROP_BAND_INDEX] = synthesize_cirrus(arr, band_order='train')\n",
    "        return out\n",
    "\n",
    "    if band_order == 'test':\n",
    "        canonical = reorder_test_to_canonical(arr)\n",
    "    elif band_order == 'canonical_12':\n",
    "        if arr.shape[0] != len(CANONICAL_12_BAND_ORDER):\n",
    "            raise ValueError(f\"Expected canonical 12-band array with shape (12, H, W), got {arr.shape}\")\n",
    "        canonical = arr\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported band_order: {band_order}\")\n",
    "\n",
    "    cirrus = synthesize_cirrus(canonical, band_order='canonical_12')\n",
    "    return np.concatenate(\n",
    "        [canonical[:DROP_BAND_INDEX], cirrus[np.newaxis, ...], canonical[DROP_BAND_INDEX:]],\n",
    "        axis=0\n",
    "    )\n",
    "\n",
    "\n",
    "def robust_normalize(arr: np.ndarray) -> np.ndarray:\n",
    "    arr = arr.astype(np.float32, copy=False)\n",
    "    out = np.empty_like(arr)\n",
    "    for i in range(arr.shape[0]):\n",
    "        band = arr[i]\n",
    "        lo, hi = np.percentile(band, [2, 98])\n",
    "        if hi > lo:\n",
    "            band = (band - lo) / (hi - lo)\n",
    "        else:\n",
    "            min_v, max_v = band.min(), band.max()\n",
    "            if max_v > min_v:\n",
    "                band = (band - min_v) / (max_v - min_v)\n",
    "            else:\n",
    "                band = np.zeros_like(band)\n",
    "        out[i] = np.clip(band, 0.0, 1.0)\n",
    "    return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550d888b",
   "metadata": {},
   "source": [
    "### Cell 7 – Train CirrusCNN and persist reconstruction bundle\n",
    "Runs `fit_cirrus_cnn` on all tiles, transfers the fitted module to the active device, strips CPU state dict weights, and saves the checkpoint plus metadata (band order, error metrics, scaling) under `EUROSAT_B10_MODEL_DIR` for reuse during fine-tuning and inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0617de28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CirrusCNN] Training on 24300 tiles (+2700 val) with 64 patches per tile per epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train patches (epoch 1):  34%|███▎      | 8142/24300 [04:13<08:09, 33.00it/s]"
     ]
    }
   ],
   "source": [
    "cirrus_paths = CIRRUS_TILE_PATHS\n",
    "CIRRUS_MODEL = fit_cirrus_cnn(cirrus_paths, epochs=3, patches_per_tile=64, patch_size=64)\n",
    "CIRRUS_MODEL['module'] = CIRRUS_MODEL['module'].to(DEVICE)\n",
    "CIRRUS_MODEL['module'].eval()\n",
    "\n",
    "cirrus_state_dict = {k: v.detach().cpu() for k, v in CIRRUS_MODEL['module'].state_dict().items()}\n",
    "\n",
    "b10_bundle = {\n",
    "    'state_dict': cirrus_state_dict,\n",
    "    'mae': CIRRUS_MODEL['mae'],\n",
    "    'rmse': CIRRUS_MODEL['rmse'],\n",
    "    'scale': CIRRUS_MODEL['scale'],\n",
    "    'drop_band_index': DROP_BAND_INDEX,\n",
    "    'keep_idx_12': KEEP_IDX_12,\n",
    "    'keep_idx_13': KEEP_IDX_13,\n",
    "    'train_band_order': TRAIN_BAND_ORDER,\n",
    "    'test_band_order': TEST_BAND_ORDER,\n",
    "    'canonical_12_band_order': CANONICAL_12_BAND_ORDER,\n",
    "}\n",
    "\n",
    "b10_model_path = B10_MODEL_DIR / f'cirrus_cnn_{RUN_TIMESTAMP}.pt'\n",
    "torch.save(b10_bundle, b10_model_path)\n",
    "print(f\"Saved B10 reconstruction weights to {b10_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425c7158",
   "metadata": {},
   "source": [
    "### Cell 8 – Build ConvNeXt foundation classifier and processor\n",
    "Bootstraps torchvision’s `convnext_base` with ImageNet-1K weights, freezes the feature extractor, swaps in a new linear classifier head sized to `len(CLASS_NAMES)`, and constructs a minimal processor that mirrors the pretrained normalization/cropping pipeline. This sets up the foundation model that will be fine-tuned on EuroSAT tiles with synthetic B10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b837ed81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading foundation model convnext_base with ImageNet pretrained weights\n",
      "Feature extractor frozen; fine-tuning classifier head only.\n"
     ]
    }
   ],
   "source": [
    "FOUNDATION_MODEL_NAME = 'convnext_base'\n",
    "FOUNDATION_WEIGHTS = ConvNeXt_Base_Weights.IMAGENET1K_V1\n",
    "\n",
    "class FoundationImageProcessor:\n",
    "    def __init__(self, image_size: int, mean, std):\n",
    "        self.image_size = image_size\n",
    "        self.mean = torch.tensor(mean, dtype=torch.float32).view(3, 1, 1)\n",
    "        self.std = torch.tensor(std, dtype=torch.float32).view(3, 1, 1)\n",
    "\n",
    "    def _to_tensor(self, image):\n",
    "        if isinstance(image, np.ndarray):\n",
    "            tensor = torch.from_numpy(image).float()\n",
    "        elif torch.is_tensor(image):\n",
    "            tensor = image.float()\n",
    "        else:\n",
    "            tensor = torch.as_tensor(image, dtype=torch.float32)\n",
    "        if tensor.ndim != 3:\n",
    "            raise ValueError(f'Expected image with 3 dims, got {tuple(tensor.shape)}')\n",
    "        if tensor.shape[0] not in (3,):\n",
    "            tensor = tensor.permute(2, 0, 1)\n",
    "        tensor = torch.clamp(tensor, 0.0, 1.0)\n",
    "        tensor = torch.nn.functional.interpolate(\n",
    "            tensor.unsqueeze(0),\n",
    "            size=(self.image_size, self.image_size),\n",
    "            mode='bilinear',\n",
    "            align_corners=False,\n",
    "        ).squeeze(0)\n",
    "        tensor = (tensor - self.mean) / self.std\n",
    "        return tensor\n",
    "\n",
    "    def __call__(self, images, return_tensors: str | None = 'pt'):\n",
    "        tensor = self._to_tensor(images)\n",
    "        if return_tensors in (None, 'pt'):\n",
    "            return {'pixel_values': tensor}\n",
    "        raise ValueError(f'Unsupported return_tensors value: {return_tensors!r}')\n",
    "\n",
    "\n",
    "def build_foundation_classifier(num_classes: int):\n",
    "      weights = FOUNDATION_WEIGHTS\n",
    "      model = models.convnext_base(weights=weights)\n",
    "      for param in model.features.parameters():\n",
    "          param.requires_grad = False\n",
    "      in_features = model.classifier[2].in_features\n",
    "      model.classifier[2] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "      tfm = weights.transforms()\n",
    "      processor = FoundationImageProcessor(\n",
    "          image_size=tfm.crop_size[0],\n",
    "          mean=tfm.mean,\n",
    "          std=tfm.std,\n",
    "      )\n",
    "      return model, processor\n",
    "\n",
    "\n",
    "print(f'Loading foundation model {FOUNDATION_MODEL_NAME} with ImageNet pretrained weights')\n",
    "model, processor = build_foundation_classifier(len(CLASS_NAMES))\n",
    "model.to(DEVICE)\n",
    "print('Feature extractor frozen; fine-tuning classifier head only.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45786c7",
   "metadata": {},
   "source": [
    "### Cell 9 – Unified logits accessor\n",
    "Adds `get_model_logits`, a small shim that normalizes different return types (tensor vs dict vs objects) so downstream training/inference code can always grab logits regardless of the underlying model signature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e170d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_logits(model, pixel_values):\n",
    "    try:\n",
    "        outputs = model(pixel_values=pixel_values)\n",
    "    except TypeError:\n",
    "        outputs = model(pixel_values)\n",
    "    if isinstance(outputs, torch.Tensor):\n",
    "        return outputs\n",
    "    if isinstance(outputs, dict):\n",
    "        if 'logits' in outputs:\n",
    "            return outputs['logits']\n",
    "        raise KeyError(\"Model output dict missing 'logits'\")\n",
    "    if hasattr(outputs, 'logits'):\n",
    "        return outputs.logits\n",
    "    raise RuntimeError('Model output does not contain logits')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff695d5",
   "metadata": {},
   "source": [
    "### Cell 10 – Fine-tuning pipeline with synthesized B10 inputs\n",
    "Builds stratified train/val/test splits, loads GeoTIFFs, calls `pad_to_13_bands` to inject CirrusCNN predictions, converts them into RGB tensors for ConvNeXt, and trains the classifier head with AdamW, gradient clipping, patience-based early stopping, and rich metric logging (accuracy, confusion matrix, ROC/PR curves). The cell also saves the fine-tuned weights plus plots/history to the artifacts folders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89200af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] Split sizes -> train: 18900 | val: 4050 | test: 4050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 1/4 | train_loss=1.4778 train_acc=0.7032 | val_loss=0.8447 val_acc=0.8802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 2/4 | train_loss=0.6705 train_acc=0.8974 | val_loss=0.4649 val_acc=0.9123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 3/4 | train_loss=0.4291 train_acc=0.9162 | val_loss=0.3393 val_acc=0.9257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune] epoch 4/4 | train_loss=0.3338 train_acc=0.9283 | val_loss=0.2814 val_acc=0.9333\n",
      "Loaded best fine-tuned weights from epoch 4 (val_acc=0.9333)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune/Test] loss=0.2628 acc=0.9400 | samples=4050\n",
      "Saved plot to /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/plots/finetune_20251113_082242_accuracy_loss.png\n",
      "Saved plot to /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/plots/finetune_20251113_082242_confusion_matrix.png\n",
      "Saved plot to /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/plots/finetune_20251113_082242_per_class_metrics.png\n",
      "Saved plot to /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/plots/finetune_20251113_082242_roc_curves.png\n",
      "Saved plot to /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/plots/finetune_20251113_082242_roc_auc_bars.png\n",
      "Saved plot to /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/plots/finetune_20251113_082242_precision_recall_curves.png\n",
      "Saved plot to /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/plots/finetune_20251113_082242_score_distribution.png\n",
      "Saved fine-tuned classifier weights to /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/models/convnext_base_cirrus_finetuned_20251113_082242.pt\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the classifier using CirrusCNN-synthesized B10 inputs so it sees the same distribution as at inference time\n",
    "\n",
    "\n",
    "def _build_finetune_records(val_fraction: float = 0.1, test_fraction: float = 0.0, limit_per_class: int | None = None, seed: int = RANDOM_SEED):\n",
    "    if not (0.0 < val_fraction < 1.0):\n",
    "        raise ValueError('val_fraction must be between 0 and 1 for fine-tuning splits')\n",
    "    if not (0.0 <= test_fraction < 1.0):\n",
    "        raise ValueError('test_fraction must be between 0 and 1 for fine-tuning splits')\n",
    "    if val_fraction + test_fraction >= 1.0:\n",
    "        raise ValueError('val_fraction + test_fraction must sum to less than 1.0 for fine-tuning splits')\n",
    "    rng = np.random.default_rng(seed)\n",
    "    train_records: list[tuple[Path, int]] = []\n",
    "    val_records: list[tuple[Path, int]] = []\n",
    "    test_records: list[tuple[Path, int]] = []\n",
    "    for class_name in CLASS_NAMES:\n",
    "        class_idx = CLASS_TO_IDX[class_name]\n",
    "        class_dir = DATA_ROOT / class_name\n",
    "        tif_paths = sorted(class_dir.glob('*.tif'))\n",
    "        if not tif_paths:\n",
    "            continue\n",
    "        if limit_per_class is not None and len(tif_paths) > limit_per_class:\n",
    "            selection = rng.choice(len(tif_paths), size=limit_per_class, replace=False)\n",
    "            tif_paths = [tif_paths[i] for i in selection]\n",
    "        order = rng.permutation(len(tif_paths))\n",
    "        tif_paths = [tif_paths[i] for i in order]\n",
    "        if len(tif_paths) < 2:\n",
    "            train_records.extend((path, class_idx) for path in tif_paths)\n",
    "            continue\n",
    "        total = len(tif_paths)\n",
    "        val_count = 0\n",
    "        test_count = 0\n",
    "        if val_fraction > 0.0:\n",
    "            val_count = max(1, int(total * val_fraction))\n",
    "            val_count = min(total - 1, val_count)\n",
    "        remaining = total - val_count\n",
    "        if test_fraction > 0.0 and remaining > 1:\n",
    "            test_count = max(1, int(total * test_fraction))\n",
    "            test_count = min(test_count, remaining - 1)\n",
    "        val_slice = tif_paths[:val_count]\n",
    "        test_slice = tif_paths[val_count:val_count + test_count]\n",
    "        train_slice = tif_paths[val_count + test_count:]\n",
    "        if not train_slice:\n",
    "            raise RuntimeError('Unable to keep at least one training tile per class; adjust val/test fractions or increase data availability.')\n",
    "        val_records.extend((path, class_idx) for path in val_slice)\n",
    "        test_records.extend((path, class_idx) for path in test_slice)\n",
    "        train_records.extend((path, class_idx) for path in train_slice)\n",
    "    if not train_records or not val_records:\n",
    "        raise RuntimeError('Unable to build stratified fine-tuning splits; consider lowering val_fraction or increasing data availability.')\n",
    "    if test_fraction > 0.0 and not test_records:\n",
    "        raise RuntimeError('Unable to build stratified fine-tuning test split; consider lowering test_fraction or increasing data availability.')\n",
    "    return train_records, val_records, test_records\n",
    "\n",
    "\n",
    "class EuroSATCirrusFinetuneDataset(Dataset):\n",
    "    def __init__(self, records, processor, inject_cirrus_b10: bool = True):\n",
    "        if processor is None:\n",
    "            raise RuntimeError('processor must be initialized before building the fine-tuning dataset')\n",
    "        if inject_cirrus_b10 and CIRRUS_MODEL is None:\n",
    "            raise RuntimeError('CIRRUS_MODEL is None; train or load the B10 reconstruction model before fine-tuning the classifier')\n",
    "        self.records = records\n",
    "        self.processor = processor\n",
    "        self.inject_cirrus_b10 = inject_cirrus_b10\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        path, label = self.records[idx]\n",
    "        with rasterio.open(path) as src:\n",
    "            arr = src.read().astype(np.float32)\n",
    "        if self.inject_cirrus_b10:\n",
    "            arr = pad_to_13_bands(arr, band_order='train')\n",
    "        rgb = multispectral_to_rgb(arr)\n",
    "        inputs = self.processor(images=rgb, return_tensors='pt')\n",
    "        pixel_values = inputs['pixel_values'].squeeze(0)\n",
    "        return {\n",
    "            'pixel_values': pixel_values,\n",
    "            'labels': torch.tensor(label, dtype=torch.long),\n",
    "            'path': str(path),\n",
    "        }\n",
    "\n",
    "\n",
    "def _save_plot(fig, filename: str):\n",
    "    path = PLOT_DIR / filename\n",
    "    fig.savefig(path, dpi=180, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved plot to {path}\")\n",
    "\n",
    "\n",
    "def _plot_training_curves(history: list[dict], tag: str):\n",
    "    if not history:\n",
    "        return\n",
    "    epochs = [entry['epoch'] for entry in history]\n",
    "    train_loss = [entry['train_loss'] for entry in history]\n",
    "    val_loss = [entry['val_loss'] for entry in history]\n",
    "    train_acc = [entry['train_acc'] for entry in history]\n",
    "    val_acc = [entry['val_acc'] for entry in history]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    axes[0].plot(epochs, train_acc, label='Train')\n",
    "    axes[0].plot(epochs, val_acc, label='Val')\n",
    "    axes[0].set_title('Accuracy over epochs')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].grid(True, linestyle='--', alpha=0.3)\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].plot(epochs, train_loss, label='Train')\n",
    "    axes[1].plot(epochs, val_loss, label='Val')\n",
    "    axes[1].set_title('Loss over epochs')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].grid(True, linestyle='--', alpha=0.3)\n",
    "    axes[1].legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    _save_plot(fig, f'{tag}_accuracy_loss.png')\n",
    "\n",
    "\n",
    "def _plot_confusion_matrix(cm: np.ndarray, tag: str):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(len(CLASS_NAMES)),\n",
    "           yticks=np.arange(len(CLASS_NAMES)),\n",
    "           xticklabels=CLASS_NAMES,\n",
    "           yticklabels=CLASS_NAMES,\n",
    "           xlabel='Predicted label',\n",
    "           ylabel='True label',\n",
    "           title='Confusion matrix (test set)')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')\n",
    "\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], 'd'), ha='center', va='center', color='white' if cm[i, j] > cm.max() / 2 else 'black')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    _save_plot(fig, f'{tag}_confusion_matrix.png')\n",
    "\n",
    "\n",
    "def _plot_per_class_metrics(precision: np.ndarray, recall: np.ndarray, f1: np.ndarray, tag: str):\n",
    "    indices = np.arange(len(CLASS_NAMES))\n",
    "    width = 0.25\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    ax.bar(indices - width, precision, width, label='Precision')\n",
    "    ax.bar(indices, recall, width, label='Recall')\n",
    "    ax.bar(indices + width, f1, width, label='F1')\n",
    "    ax.set_xticks(indices)\n",
    "    ax.set_xticklabels(CLASS_NAMES, rotation=45, ha='right')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title('Per-class metrics (test set)')\n",
    "    ax.grid(True, axis='y', linestyle='--', alpha=0.3)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    _save_plot(fig, f'{tag}_per_class_metrics.png')\n",
    "\n",
    "\n",
    "def _plot_roc_curves(y_true: np.ndarray, probs: np.ndarray, tag: str):\n",
    "    classes = np.arange(len(CLASS_NAMES))\n",
    "    y_bin = label_binarize(y_true, classes=classes)\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    auc_scores: dict[str, float] = {}\n",
    "    for idx, class_name in enumerate(CLASS_NAMES):\n",
    "        fpr, tpr, _ = roc_curve(y_bin[:, idx], probs[:, idx])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        auc_scores[class_name] = roc_auc\n",
    "        ax.plot(fpr, tpr, label=f'{class_name} (AUC={roc_auc:.3f})')\n",
    "    micro_fpr, micro_tpr, _ = roc_curve(y_bin.ravel(), probs.ravel())\n",
    "    micro_auc = auc(micro_fpr, micro_tpr)\n",
    "    auc_scores['micro'] = micro_auc\n",
    "    ax.plot(micro_fpr, micro_tpr, color='black', linewidth=2, label=f'Micro (AUC={micro_auc:.3f})')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('ROC curves (one-vs-rest)')\n",
    "    ax.legend(fontsize='small', ncol=2)\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    fig.tight_layout()\n",
    "    _save_plot(fig, f'{tag}_roc_curves.png')\n",
    "    return auc_scores\n",
    "\n",
    "\n",
    "def _plot_roc_auc_bars(auc_scores: dict[str, float], tag: str):\n",
    "    labels = list(auc_scores.keys())\n",
    "    scores = [auc_scores[label] for label in labels]\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    ax.bar(labels, scores, color='teal')\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_ylabel('AUC')\n",
    "    ax.set_title('ROC-AUC by class')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    ax.grid(True, axis='y', linestyle='--', alpha=0.3)\n",
    "    fig.tight_layout()\n",
    "    _save_plot(fig, f'{tag}_roc_auc_bars.png')\n",
    "\n",
    "\n",
    "def _plot_precision_recall_curves(y_true: np.ndarray, probs: np.ndarray, tag: str):\n",
    "    classes = np.arange(len(CLASS_NAMES))\n",
    "    y_bin = label_binarize(y_true, classes=classes)\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    for idx, class_name in enumerate(CLASS_NAMES):\n",
    "        precision, recall, _ = precision_recall_curve(y_bin[:, idx], probs[:, idx])\n",
    "        pr_auc = auc(recall, precision)\n",
    "        ax.plot(recall, precision, label=f'{class_name} (AUC={pr_auc:.3f})')\n",
    "    precision_micro, recall_micro, _ = precision_recall_curve(y_bin.ravel(), probs.ravel())\n",
    "    pr_auc_micro = auc(recall_micro, precision_micro)\n",
    "    ax.plot(recall_micro, precision_micro, color='black', linewidth=2, label=f'Micro (AUC={pr_auc_micro:.3f})')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_title('Precision-Recall curves (one-vs-rest)')\n",
    "    ax.legend(fontsize='small', ncol=2)\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    fig.tight_layout()\n",
    "    _save_plot(fig, f'{tag}_precision_recall_curves.png')\n",
    "\n",
    "\n",
    "def _plot_score_distribution(y_true: np.ndarray, y_pred: np.ndarray, probs: np.ndarray, tag: str):\n",
    "    max_probs = probs.max(axis=1)\n",
    "    correct = y_pred == y_true\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.hist(max_probs[correct], bins=30, alpha=0.7, label='Correct', color='green', density=True)\n",
    "    ax.hist(max_probs[~correct], bins=30, alpha=0.7, label='Incorrect', color='red', density=True)\n",
    "    ax.set_xlabel('Predicted probability (max class)')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Prediction confidence distribution')\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    fig.tight_layout()\n",
    "    _save_plot(fig, f'{tag}_score_distribution.png')\n",
    "\n",
    "\n",
    "def finetune_classifier_with_cirrus(model, processor, cfg: dict):\n",
    "    train_records, val_records, test_records = _build_finetune_records(\n",
    "        val_fraction=cfg.get('val_fraction', 0.1),\n",
    "        test_fraction=cfg.get('test_fraction', 0.0),\n",
    "        limit_per_class=cfg.get('limit_per_class'),\n",
    "        seed=cfg.get('seed', RANDOM_SEED),\n",
    "    )\n",
    "    train_dataset = EuroSATCirrusFinetuneDataset(train_records, processor, inject_cirrus_b10=True)\n",
    "    val_dataset = EuroSATCirrusFinetuneDataset(val_records, processor, inject_cirrus_b10=True)\n",
    "    test_dataset = EuroSATCirrusFinetuneDataset(test_records, processor, inject_cirrus_b10=True) if test_records else None\n",
    "\n",
    "    num_workers = cfg.get('num_workers')\n",
    "    if num_workers is None:\n",
    "        num_workers = 0 if platform.system() == 'Darwin' else 4\n",
    "    pin_memory = DEVICE.type == 'cuda'\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=cfg.get('train_batch_size', 32),\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=cfg.get('val_batch_size', 64),\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "    )\n",
    "    test_loader = None\n",
    "    if test_dataset is not None:\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=cfg.get('test_batch_size', cfg.get('val_batch_size', 64)),\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=pin_memory,\n",
    "        )\n",
    "\n",
    "    print(f\"[FineTune] Split sizes -> train: {len(train_records)} | val: {len(val_records)} | test: {len(test_records)}\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        trainable_params,\n",
    "        lr=cfg.get('lr', 5e-5),\n",
    "        weight_decay=cfg.get('weight_decay', 1e-2),\n",
    "    )\n",
    "    max_grad_norm = cfg.get('max_grad_norm', 1.0)\n",
    "    epochs = cfg.get('epochs', 3)\n",
    "    transfer_non_blocking = DEVICE.type == 'cuda'\n",
    "\n",
    "    best_state = None\n",
    "    best_val_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    history = []\n",
    "\n",
    "    patience = max(1, cfg.get('early_stopping_patience', 3))\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_samples = 0\n",
    "        for batch in tqdm(train_loader, desc=f'Fine-tune train {epoch}/{epochs}', leave=False):\n",
    "            pixel_values = batch['pixel_values'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "            labels = batch['labels'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            logits = get_model_logits(model, pixel_values)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            if max_grad_norm is not None and max_grad_norm > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * labels.size(0)\n",
    "            train_correct += (logits.argmax(dim=1) == labels).sum().item()\n",
    "            train_samples += labels.size(0)\n",
    "        train_loss = train_loss / max(1, train_samples)\n",
    "        train_acc = train_correct / max(1, train_samples)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=f'Fine-tune val {epoch}/{epochs}', leave=False):\n",
    "                pixel_values = batch['pixel_values'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "                labels = batch['labels'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "                logits = get_model_logits(model, pixel_values)\n",
    "                loss = criterion(logits, labels)\n",
    "                val_loss += loss.item() * labels.size(0)\n",
    "                val_correct += (logits.argmax(dim=1) == labels).sum().item()\n",
    "                val_samples += labels.size(0)\n",
    "        val_loss = val_loss / max(1, val_samples)\n",
    "        val_acc = val_correct / max(1, val_samples)\n",
    "\n",
    "        history.append({\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'train_samples': train_samples,\n",
    "            'val_samples': val_samples,\n",
    "        })\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            no_improve_epochs = 0\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "            if no_improve_epochs >= patience:\n",
    "                print(f\"[FineTune] Early stopping triggered at epoch {epoch} (patience={patience}).\")\n",
    "                break\n",
    "\n",
    "        print(f\"[FineTune] epoch {epoch}/{epochs} | train_loss={train_loss:.4f} train_acc={train_acc:.4f} | val_loss={val_loss:.4f} val_acc={val_acc:.4f}\")\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "        print(f\"Loaded best fine-tuned weights from epoch {best_epoch} (val_acc={best_val_acc:.4f})\")\n",
    "\n",
    "    test_results = None\n",
    "    test_plot_payload = None\n",
    "    if test_loader is not None:\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct = 0\n",
    "        test_samples = 0\n",
    "        collected_probs = []\n",
    "        collected_labels = []\n",
    "        collected_preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc='Fine-tune test', leave=False):\n",
    "                pixel_values = batch['pixel_values'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "                labels = batch['labels'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "                logits = get_model_logits(model, pixel_values)\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                loss = criterion(logits, labels)\n",
    "                test_loss += loss.item() * labels.size(0)\n",
    "                predictions = probs.argmax(dim=1)\n",
    "                test_correct += (predictions == labels).sum().item()\n",
    "                test_samples += labels.size(0)\n",
    "                collected_probs.append(probs.detach().cpu())\n",
    "                collected_labels.append(labels.detach().cpu())\n",
    "                collected_preds.append(predictions.detach().cpu())\n",
    "        test_loss = test_loss / max(1, test_samples)\n",
    "        test_acc = test_correct / max(1, test_samples)\n",
    "        if collected_probs:\n",
    "            probs_np = torch.cat(collected_probs).numpy()\n",
    "            labels_np = torch.cat(collected_labels).numpy()\n",
    "            preds_np = torch.cat(collected_preds).numpy()\n",
    "            test_plot_payload = {\n",
    "                'labels': labels_np,\n",
    "                'preds': preds_np,\n",
    "                'probs': probs_np,\n",
    "            }\n",
    "        test_results = {\n",
    "            'test_loss': test_loss,\n",
    "            'test_acc': test_acc,\n",
    "            'test_samples': test_samples,\n",
    "        }\n",
    "        print(f\"[FineTune/Test] loss={test_loss:.4f} acc={test_acc:.4f} | samples={test_samples}\")\n",
    "\n",
    "    plot_tag = f'finetune_{RUN_TIMESTAMP}'\n",
    "    _plot_training_curves(history, plot_tag)\n",
    "    if test_plot_payload is not None:\n",
    "        labels = test_plot_payload['labels']\n",
    "        preds = test_plot_payload['preds']\n",
    "        probs = test_plot_payload['probs']\n",
    "        cm = confusion_matrix(labels, preds, labels=list(range(len(CLASS_NAMES))))\n",
    "        _plot_confusion_matrix(cm, plot_tag)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            labels,\n",
    "            preds,\n",
    "            labels=list(range(len(CLASS_NAMES))),\n",
    "            zero_division=0,\n",
    "        )\n",
    "        _plot_per_class_metrics(precision, recall, f1, plot_tag)\n",
    "        auc_scores = _plot_roc_curves(labels, probs, plot_tag)\n",
    "        _plot_roc_auc_bars(auc_scores, plot_tag)\n",
    "        _plot_precision_recall_curves(labels, probs, plot_tag)\n",
    "        _plot_score_distribution(labels, preds, probs, plot_tag)\n",
    "\n",
    "    model.eval()\n",
    "    if cfg.get('save_weights', True):\n",
    "        tag = FOUNDATION_MODEL_NAME.replace('/', '_')\n",
    "        save_path = MODELS_DIR / f'{tag}_cirrus_finetuned_{RUN_TIMESTAMP}.pt'\n",
    "        torch.save({\n",
    "            'state_dict': model.state_dict(),\n",
    "            'config': getattr(model, 'config', None),\n",
    "            'history': history,\n",
    "            'class_names': CLASS_NAMES,\n",
    "            'test_results': test_results,\n",
    "        }, save_path)\n",
    "        print(f\"Saved fine-tuned classifier weights to {save_path}\")\n",
    "\n",
    "    return history, test_results\n",
    "\n",
    "\n",
    "FINETUNE_CFG = {\n",
    "    'val_fraction': 0.15,\n",
    "    'test_fraction': 0.15,\n",
    "    'limit_per_class': None,\n",
    "    'epochs': 4,\n",
    "    'early_stopping_patience': 3,\n",
    "    'train_batch_size': 32,\n",
    "    'val_batch_size': 64,\n",
    "    'test_batch_size': 64,\n",
    "    'lr': 5e-5,\n",
    "    'weight_decay': 1e-2,\n",
    "    'max_grad_norm': 1.0,\n",
    "    'num_workers': None,\n",
    "    'save_weights': True,\n",
    "    'seed': RANDOM_SEED,\n",
    "}\n",
    "RUN_CLASSIFIER_FINE_TUNE = True\n",
    "\n",
    "finetune_history = None\n",
    "finetune_test_results = None\n",
    "if RUN_CLASSIFIER_FINE_TUNE:\n",
    "    finetune_history, finetune_test_results = finetune_classifier_with_cirrus(model, processor, FINETUNE_CFG)\n",
    "else:\n",
    "    print('Skipping classifier fine-tuning. Set RUN_CLASSIFIER_FINE_TUNE = True to enable it.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c40ec0",
   "metadata": {},
   "source": [
    "### Cell 11 – Kaggle `.npy` dataset wrapper\n",
    "Defines `EuroSATNPYDataset` which loads each Kaggle tile, reorders/pads/normalizes bands via the Cirrus helpers, converts them into RGB tensors through the foundation processor, and returns tensors plus `test_id`. This keeps the inference DataLoader consistent with the fine-tuning preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c4358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EuroSATNPYDataset(Dataset):\n",
    "    def __init__(self, paths, processor):\n",
    "        self.paths = paths\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        arr = np.load(path, allow_pickle=False)\n",
    "        if arr.ndim == 3 and arr.shape[0] not in (12, 13) and arr.shape[-1] in (12, 13):\n",
    "            arr = np.moveaxis(arr, -1, 0)\n",
    "        arr = pad_to_13_bands(arr, band_order='test')\n",
    "        rgb = multispectral_to_rgb(arr)\n",
    "        inputs = self.processor(images=rgb, return_tensors='pt')\n",
    "        pixel_values = inputs['pixel_values'].squeeze(0)\n",
    "        sample_id = self._extract_id(path.stem)\n",
    "        return {'pixel_values': pixel_values, 'id': sample_id}\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_id(stem: str) -> int:\n",
    "        match = re.search(r'(\\d+)$', stem)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        digits = ''.join(ch for ch in stem if ch.isdigit())\n",
    "        return int(digits) if digits else -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7de540",
   "metadata": {},
   "source": [
    "### Cell 12 – Kaggle inference loop and submission writer\n",
    "Validates the Kaggle directory, builds a DataLoader over the dataset above, streams batches through the fine-tuned ConvNeXt head on the chosen device, collects predictions, maps indices back to class names, and writes `submission_with_cirrus_<timestamp>.csv` under `EUROSAT_OUTPUT_DIR` ready for Kaggle upload.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c6a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4232 inference tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Kaggle inference: 100%|██████████| 133/133 [01:09<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission to /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/outputs/submission_with_cirrus_20251113_082242.csv\n",
      "   test_id    label\n",
      "0        0  Pasture\n",
      "1        1    River\n",
      "2        2   Forest\n",
      "3        3  SeaLake\n",
      "4        4    River\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "TEST_ROOT = KAGGLE_TEST_DIR\n",
    "if not TEST_ROOT.exists():\n",
    "    raise FileNotFoundError(f\"Expected test directory at {TEST_ROOT}\")\n",
    "\n",
    "npy_paths = sorted(TEST_ROOT.glob('*.npy'))\n",
    "if not npy_paths:\n",
    "    npy_paths = sorted(TEST_ROOT.glob('**/*.npy'))\n",
    "\n",
    "if len(npy_paths) == 0:\n",
    "    raise FileNotFoundError('No .npy files found in Kaggle test directory')\n",
    "\n",
    "print(f\"Found {len(npy_paths)} inference tiles\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0 if platform.system() == 'Darwin' else 2\n",
    "PIN_MEMORY = DEVICE.type == 'cuda'\n",
    "\n",
    "kaggle_dataset = EuroSATNPYDataset(npy_paths, processor)\n",
    "kaggle_loader = DataLoader(\n",
    "    kaggle_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "pred_ids = []\n",
    "pred_indices = []\n",
    "transfer_non_blocking = DEVICE.type == 'cuda'\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(kaggle_loader, desc='Kaggle inference'):\n",
    "        pixel_values = batch['pixel_values'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "        logits = get_model_logits(model, pixel_values)\n",
    "        preds = logits.argmax(dim=1).cpu().tolist()\n",
    "        pred_indices.extend(preds)\n",
    "        if isinstance(batch['id'], torch.Tensor):\n",
    "            pred_ids.extend(batch['id'].cpu().tolist())\n",
    "        else:\n",
    "            pred_ids.extend(batch['id'])\n",
    "\n",
    "pred_labels = [IDX_TO_CLASS[idx] for idx in pred_indices]\n",
    "submission = pd.DataFrame({'test_id': pred_ids, 'label': pred_labels})\n",
    "submission = submission.sort_values('test_id').reset_index(drop=True)\n",
    "\n",
    "submission_name = f'submission_with_cirrus_{RUN_TIMESTAMP}.csv'\n",
    "submission_path = OUTPUT_DIR / submission_name\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Saved submission to {submission_path}\")\n",
    "print(submission.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
