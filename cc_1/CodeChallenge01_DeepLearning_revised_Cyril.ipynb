{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c35de42",
   "metadata": {
    "id": "6c35de42"
   },
   "source": [
    "# EuroSAT_MS – Pretrained Deep Learning Pipeline\n",
    "\n",
    "This notebook fine-tunes the Hugging Face `Rhodham96/EuroSatCNN` multispectral classifier on the 13-channel EuroSAT dataset and prepares a Kaggle submission using the resulting deep learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac33d11",
   "metadata": {
    "id": "2ac33d11"
   },
   "source": [
    "## 1) Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cca310b8",
   "metadata": {
    "id": "cca310b8"
   },
   "outputs": [],
   "source": [
    "!pip install -q rasterio transformers huggingface_hub accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036fda54",
   "metadata": {
    "id": "036fda54"
   },
   "source": [
    "## 2) Imports & Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d5677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from pathlib import Path\n",
    "import os, random, math, time, shutil, glob, re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "from collections import Counter\n",
    "from functools import lru_cache\n",
    "from huggingface_hub import hf_hub_download\n",
    "import importlib.util\n",
    "from types import SimpleNamespace\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import GroupShuffleSplit, StratifiedGroupKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import rasterio\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "set_seed(RANDOM_SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44796f7b",
   "metadata": {
    "id": "44796f7b"
   },
   "source": [
    "## 3) Mount Drive and Extract EuroSAT_MS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4f699cd7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4f699cd7",
    "outputId": "e4e59b9d-ff68-4675-d3f9-4af6866b740e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Dataset already available at /content/EuroSAT_MS\n",
      "DATA_ROOT: /content/EuroSAT_MS\n"
     ]
    }
   ],
   "source": [
    "\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "KAGGLE_ZIP_PATH = Path('/content/drive/MyDrive/ML_HSG/kaggle_data.zip')\n",
    "KAGGLE_ROOT = Path('/content/kaggle_data')\n",
    "\n",
    "if not KAGGLE_ROOT.exists():\n",
    "    if not KAGGLE_ZIP_PATH.exists():\n",
    "        raise FileNotFoundError(f\"Kaggle archive not found at {KAGGLE_ZIP_PATH}\")\n",
    "    print(f\"Extracting dataset from {KAGGLE_ZIP_PATH} ...\")\n",
    "    !unzip -q -o \"$KAGGLE_ZIP_PATH\" -d \"/content\"\n",
    "else:\n",
    "    print(f\"Kaggle data already available at {KAGGLE_ROOT}\")\n",
    "\n",
    "print(\"KAGGLE_ROOT:\", KAGGLE_ROOT.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641dda0f",
   "metadata": {
    "id": "641dda0f"
   },
   "source": [
    "## 4) Collect Samples and Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08828621",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CLASS_NAMES = []\n",
    "samples = []\n",
    "\n",
    "\n",
    "def load_kaggle_train_metadata():\n",
    "    csv_candidates = [\n",
    "        Path('/content/drive/MyDrive/ML_HSG/kaggle_data/train.csv'),\n",
    "        Path('/content/kaggle_data/train.csv'),\n",
    "        Path('/content/kaggle_data/kaggle/train.csv'),\n",
    "        Path('/content/kaggle_data/train/train.csv'),\n",
    "    ]\n",
    "    for candidate in csv_candidates:\n",
    "        if candidate.exists():\n",
    "            df = pd.read_csv(candidate)\n",
    "            return df, 'file', candidate\n",
    "\n",
    "    if KAGGLE_ZIP_PATH.exists():\n",
    "        import zipfile\n",
    "        with zipfile.ZipFile(KAGGLE_ZIP_PATH, 'r') as zf:\n",
    "            members = ['train.csv', 'train/train.csv', 'kaggle/train.csv']\n",
    "            for member in members:\n",
    "                if member in zf.namelist():\n",
    "                    with zf.open(member) as fh:\n",
    "                        df = pd.read_csv(fh)\n",
    "                        return df, 'zip', f\"{KAGGLE_ZIP_PATH}:{member}\"\n",
    "    return None, None, None\n",
    "\n",
    "\n",
    "def iter_candidate_directories(root: Path, max_depth: int = 3) -> list[Path]:\n",
    "    candidates = []\n",
    "    stack = [(root, 0)]\n",
    "    visited = set()\n",
    "    while stack:\n",
    "        current, depth = stack.pop()\n",
    "        resolved = current.resolve()\n",
    "        if resolved in visited:\n",
    "            continue\n",
    "        visited.add(resolved)\n",
    "        candidates.append(current)\n",
    "        if depth >= max_depth:\n",
    "            continue\n",
    "        try:\n",
    "            for child in current.iterdir():\n",
    "                if child.is_dir():\n",
    "                    stack.append((child, depth + 1))\n",
    "        except PermissionError:\n",
    "            continue\n",
    "    return candidates\n",
    "\n",
    "\n",
    "def infer_data_root(kaggle_root: Path, rel_paths: list[Path]) -> Path:\n",
    "    if not rel_paths:\n",
    "        raise ValueError('No relative paths provided to infer data root.')\n",
    "    candidates = iter_candidate_directories(kaggle_root, max_depth=2)\n",
    "    best_match = None\n",
    "    best_hits = -1\n",
    "    sample_subset = rel_paths[: min(200, len(rel_paths))]\n",
    "    for candidate in candidates:\n",
    "        hits = 0\n",
    "        for rel_path in sample_subset:\n",
    "            if (candidate / rel_path).exists():\n",
    "                hits += 1\n",
    "        if hits > best_hits:\n",
    "            best_hits = hits\n",
    "            best_match = candidate\n",
    "        if hits == len(sample_subset):\n",
    "            break\n",
    "    if best_match is None or best_hits == 0:\n",
    "        raise FileNotFoundError(\n",
    "            'Unable to locate training tiles specified in Kaggle train.csv under '\n",
    "            f'{kaggle_root}. Best candidate {best_match} with hits={best_hits}.'\n",
    "        )\n",
    "    return best_match\n",
    "\n",
    "\n",
    "kaggle_train_df, metadata_kind, metadata_location = load_kaggle_train_metadata()\n",
    "if kaggle_train_df is None:\n",
    "    raise FileNotFoundError(\n",
    "        'Kaggle train.csv was not found. Ensure the archive is extracted to '\n",
    "        '/content/kaggle_data or available on Google Drive.'\n",
    "    )\n",
    "\n",
    "CLASS_NAMES = sorted(kaggle_train_df['label'].astype(str).unique())\n",
    "CLASS_TO_IDX = {name: idx for idx, name in enumerate(CLASS_NAMES)}\n",
    "IDX_TO_CLASS = {idx: name for name, idx in CLASS_TO_IDX.items()}\n",
    "print(f\"Detected {len(CLASS_NAMES)} classes from Kaggle metadata -> {CLASS_NAMES}\")\n",
    "\n",
    "relative_paths = [Path(str(p).strip()) for p in kaggle_train_df['path']]\n",
    "DATA_ROOT = infer_data_root(KAGGLE_ROOT, relative_paths)\n",
    "print(f\"Resolved DATA_ROOT from Kaggle archive: {DATA_ROOT}\")\n",
    "\n",
    "missing_paths = []\n",
    "for row in kaggle_train_df.itertuples():\n",
    "    rel_path = Path(str(row.path).strip())\n",
    "    abs_path = DATA_ROOT / rel_path\n",
    "    if not abs_path.exists():\n",
    "        missing_paths.append(str(rel_path))\n",
    "        continue\n",
    "    label_name = str(row.label).strip()\n",
    "    label_idx = CLASS_TO_IDX.get(label_name)\n",
    "    if label_idx is None:\n",
    "        missing_paths.append(f\"UNKNOWN_LABEL::{label_name}\")\n",
    "        continue\n",
    "    samples.append((abs_path, label_idx))\n",
    "\n",
    "if missing_paths:\n",
    "    preview = ', '.join(missing_paths[:5])\n",
    "    print(\n",
    "        f\"Warning: {len(missing_paths)} entries from Kaggle train.csv could not be matched under {DATA_ROOT}. \"\n",
    "        f\"First entries: {preview}\"\n",
    "    )\n",
    "print(f\"Using Kaggle train.csv metadata ({metadata_kind}) from {metadata_location} -> matched {len(samples)} samples\")\n",
    "\n",
    "TOTAL_TILES = len(samples)\n",
    "print(f\"Total samples: {TOTAL_TILES}\")\n",
    "\n",
    "GLOBAL_BAND_STATS = None\n",
    "\n",
    "\n",
    "def pad_to_13_bands(arr: np.ndarray) -> np.ndarray:\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.shape[0] == 13:\n",
    "        return arr\n",
    "    if arr.shape[0] == 12:\n",
    "        zero_band = np.zeros((1, *arr.shape[1:]), dtype=arr.dtype)\n",
    "        return np.concatenate([arr[:9], zero_band, arr[9:]], axis=0)\n",
    "    raise ValueError(f\"Expected 12 or 13 bands, got {arr.shape}\")\n",
    "\n",
    "\n",
    "def robust_normalize(arr: np.ndarray) -> np.ndarray:\n",
    "    arr = arr.astype(np.float32, copy=False)\n",
    "    out = np.empty_like(arr)\n",
    "    for i in range(arr.shape[0]):\n",
    "        band = arr[i]\n",
    "        lo, hi = np.percentile(band, [2, 98])\n",
    "        if hi > lo:\n",
    "            band = (band - lo) / (hi - lo)\n",
    "        else:\n",
    "            min_v, max_v = band.min(), band.max()\n",
    "            if max_v > min_v:\n",
    "                band = (band - min_v) / (max_v - min_v)\n",
    "            else:\n",
    "                band = np.zeros_like(band)\n",
    "        out[i] = np.clip(band, 0.0, 1.0)\n",
    "    return out\n",
    "\n",
    "\n",
    "def normalize_with_stats(arr: np.ndarray, stats: dict) -> np.ndarray:\n",
    "    arr = arr.astype(np.float32, copy=False)\n",
    "    low = stats[\"low\"][:, None, None]\n",
    "    high = stats[\"high\"][:, None, None]\n",
    "    scale = np.maximum(high - low, 1e-6)\n",
    "    normalized = (arr - low) / scale\n",
    "    return np.clip(normalized, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def update_global_band_stats(stats: dict) -> None:\n",
    "    global GLOBAL_BAND_STATS\n",
    "    GLOBAL_BAND_STATS = stats\n",
    "\n",
    "\n",
    "def apply_normalization(arr: np.ndarray) -> np.ndarray:\n",
    "    if GLOBAL_BAND_STATS is not None:\n",
    "        return normalize_with_stats(arr, GLOBAL_BAND_STATS)\n",
    "    return robust_normalize(arr)\n",
    "\n",
    "\n",
    "def read_multispectral(path: Path) -> np.ndarray:\n",
    "    with rasterio.open(path) as src:\n",
    "        arr = src.read()\n",
    "    arr = pad_to_13_bands(arr)\n",
    "    return arr.astype(np.float32, copy=False)\n",
    "\n",
    "\n",
    "def load_multispectral(path: Path, normalize: bool = True) -> np.ndarray:\n",
    "    arr = read_multispectral(path)\n",
    "    if normalize:\n",
    "        arr = apply_normalization(arr)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def ensure_channel_first(arr: np.ndarray, source: str = 'array') -> np.ndarray:\n",
    "    if arr.ndim != 3:\n",
    "        raise ValueError(f\"Expected 3D array for {source}, got shape={arr.shape}\")\n",
    "    if arr.shape[0] in (12, 13):\n",
    "        return arr.astype(np.float32, copy=False)\n",
    "    if arr.shape[-1] in (12, 13):\n",
    "        return np.moveaxis(arr, -1, 0).astype(np.float32, copy=False)\n",
    "    raise ValueError(f\"Could not infer channel axis for {source}; shape={arr.shape}\")\n",
    "\n",
    "\n",
    "def compute_band_percentiles(\n",
    "    sample_paths,\n",
    "    sample_per_image: int = 512,\n",
    "    low: float = 2.0,\n",
    "    high: float = 98.0,\n",
    "    max_images: int = 1000,\n",
    "    seed: int = RANDOM_SEED,\n",
    "):\n",
    "    sample_paths = list(sample_paths)\n",
    "    if len(sample_paths) == 0:\n",
    "        raise ValueError(\"No paths provided to compute_band_percentiles.\")\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first = read_multispectral(sample_paths[0])\n",
    "    num_bands = first.shape[0]\n",
    "    buckets = [[] for _ in range(num_bands)]\n",
    "\n",
    "    for idx, path in enumerate(sample_paths):\n",
    "        if idx >= max_images:\n",
    "            break\n",
    "        arr = read_multispectral(path)\n",
    "        flat = arr.reshape(num_bands, -1)\n",
    "        take = min(sample_per_image, flat.shape[1])\n",
    "        sampled_idx = rng.choice(flat.shape[1], size=take, replace=False)\n",
    "        for band_idx in range(num_bands):\n",
    "            buckets[band_idx].append(flat[band_idx, sampled_idx])\n",
    "\n",
    "    lows = []\n",
    "    highs = []\n",
    "    for band_idx in range(num_bands):\n",
    "        band_samples = np.concatenate(buckets[band_idx], axis=0)\n",
    "        lows.append(np.percentile(band_samples, low))\n",
    "        highs.append(np.percentile(band_samples, high))\n",
    "\n",
    "    stats = {\n",
    "        'low': np.array(lows, dtype=np.float32),\n",
    "        'high': np.array(highs, dtype=np.float32),\n",
    "        'num_images': min(len(sample_paths), max_images),\n",
    "        'sample_per_image': sample_per_image,\n",
    "        'low_pct': low,\n",
    "        'high_pct': high,\n",
    "    }\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b002a26",
   "metadata": {},
   "source": [
    "### Kaggle train.csv – Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81e1c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "if kaggle_train_df is None:\n",
    "    raise RuntimeError(\"Run the metadata loading cell above before executing the EDA block.\")\n",
    "\n",
    "kaggle_train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b53393",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_train_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46588485",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = kaggle_train_df['label'].value_counts().sort_index()\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d3726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(label_counts.index, label_counts.values)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel('Class Label')\n",
    "plt.ylabel('Tile Count')\n",
    "plt.title('Kaggle train.csv Class Distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43a5658",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mean = np.mean(label_counts.values)\n",
    "label_std = np.std(label_counts.values)\n",
    "{\n",
    "    'mean_tiles_per_class': label_mean,\n",
    "    'std_tiles_per_class': label_std,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de85dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_checks = {\n",
    "    'missing_values': kaggle_train_df.isna().sum().to_dict(),\n",
    "    'duplicate_paths': int(kaggle_train_df['path'].duplicated().sum()),\n",
    "}\n",
    "eda_checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98245a68",
   "metadata": {},
   "source": [
    "### Kaggle test set – Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce458ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not KAGGLE_ZIP_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Kaggle archive not found at {KAGGLE_ZIP_PATH}\")\n",
    "\n",
    "KAGGLE_ROOT = Path('/content/kaggle_data')\n",
    "KAGGLE_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not any(KAGGLE_ROOT.iterdir()):\n",
    "    print(f\"Extracting {KAGGLE_ZIP_PATH} ...\")\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(KAGGLE_ZIP_PATH, 'r') as zf:\n",
    "        zf.extractall(KAGGLE_ROOT)\n",
    "else:\n",
    "    print(f\"Kaggle data available under {KAGGLE_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e07822",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_search_patterns = [\n",
    "    str(KAGGLE_ROOT / '**' / 'testset' / 'testset' / '*.npy'),\n",
    "    str(KAGGLE_ROOT / '**' / 'testset' / '*.npy'),\n",
    "    str(KAGGLE_ROOT / '**' / '*.npy'),\n",
    "]\n",
    "\n",
    "test_npy_paths = []\n",
    "for pattern in test_search_patterns:\n",
    "    hits = sorted(Path(p) for p in glob.glob(pattern, recursive=True))\n",
    "    if hits:\n",
    "        test_npy_paths = hits\n",
    "        break\n",
    "\n",
    "if not test_npy_paths:\n",
    "    raise FileNotFoundError('No .npy files found in Kaggle test set extraction')\n",
    "\n",
    "print(f\"Kaggle test tiles detected: {len(test_npy_paths)}\")\n",
    "print(f\"Sample test files: {[p.name for p in test_npy_paths[:5]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02127f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "train_cap = min(128, len(samples))\n",
    "train_indices = rng.choice(len(samples), size=train_cap, replace=False) if train_cap else []\n",
    "train_channel_counts = Counter()\n",
    "train_min, train_max = float('inf'), float('-inf')\n",
    "for idx in train_indices:\n",
    "    arr = read_multispectral(samples[idx][0])\n",
    "    train_channel_counts[arr.shape[0]] += 1\n",
    "    train_min = min(train_min, float(arr.min()))\n",
    "    train_max = max(train_max, float(arr.max()))\n",
    "\n",
    "test_cap = min(256, len(test_npy_paths))\n",
    "test_indices = rng.choice(len(test_npy_paths), size=test_cap, replace=False) if test_cap else []\n",
    "test_channel_counts = Counter()\n",
    "test_min, test_max = float('inf'), float('-inf')\n",
    "for idx in test_indices:\n",
    "    path = test_npy_paths[idx]\n",
    "    arr = np.load(path, allow_pickle=False)\n",
    "    arr = ensure_channel_first(arr, source=str(path))\n",
    "    test_channel_counts[arr.shape[0]] += 1\n",
    "    test_min = min(test_min, float(arr.min()))\n",
    "    test_max = max(test_max, float(arr.max()))\n",
    "\n",
    "comparison_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            'split': 'train',\n",
    "            'tiles_total': len(samples),\n",
    "            'sampled_tiles': int(train_cap),\n",
    "            'unique_labels': len(CLASS_NAMES),\n",
    "            'value_min': float(train_min),\n",
    "            'value_max': float(train_max),\n",
    "        },\n",
    "        {\n",
    "            'split': 'test',\n",
    "            'tiles_total': len(test_npy_paths),\n",
    "            'sampled_tiles': int(test_cap),\n",
    "            'unique_labels': np.nan,\n",
    "            'value_min': float(test_min),\n",
    "            'value_max': float(test_max),\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "display(comparison_df)\n",
    "\n",
    "{\n",
    "    'train_channel_counts': dict(sorted(train_channel_counts.items())),\n",
    "    'test_channel_counts': dict(sorted(test_channel_counts.items())),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b4d20f",
   "metadata": {
    "id": "b3b4d20f"
   },
   "source": [
    "## 5) Train / Validation / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4e60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = np.array([str(p) for p, _ in samples], dtype=object)\n",
    "labels = np.array([label for _, label in samples], dtype=np.int64)\n",
    "indices = np.arange(len(samples))\n",
    "\n",
    "META_SCENE_KEYS = (\n",
    "    \"scene_id\",\n",
    "    \"tile_id\",\n",
    "    \"TILE_ID\",\n",
    "    \"PRODUCT_ID\",\n",
    "    \"DATATAKE_IDENTIFIER\",\n",
    "    \"GRANULE_ID\",\n",
    "    \"MGRS_TILE\",\n",
    "    \"SENSING_TIME\",\n",
    ")\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def infer_scene_id(path_str: str) -> str:\n",
    "    path = Path(path_str)\n",
    "    try:\n",
    "        with rasterio.open(path) as src:\n",
    "            tags = src.tags()\n",
    "            for key in META_SCENE_KEYS:\n",
    "                value = tags.get(key)\n",
    "                if value:\n",
    "                    return f\"{path.parent.name}_{value}\"\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    stem = path.stem\n",
    "    digits = ''.join(ch for ch in stem if ch.isdigit())\n",
    "    if digits:\n",
    "        return f\"{path.parent.name}_{digits}\"\n",
    "    parts = stem.split('_')\n",
    "    if len(parts) > 1:\n",
    "        base = '_'.join(parts[:-1])\n",
    "    else:\n",
    "        base = stem\n",
    "    return f\"{path.parent.name}_{base}\"\n",
    "\n",
    "\n",
    "def build_fold_assignments(paths, labels, groups, n_splits: int = 5):\n",
    "    sgkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "    fold_ids = np.full(len(paths), -1, dtype=np.int64)\n",
    "    for fold_id, (_, val_idx) in enumerate(sgkf.split(paths, labels, groups)):\n",
    "        fold_ids[val_idx] = fold_id\n",
    "    if (fold_ids < 0).any():\n",
    "        raise RuntimeError(\"Some samples were not assigned to a fold.\"\n",
    "                           \" Check group construction.\")\n",
    "    return fold_ids\n",
    "\n",
    "scene_ids = np.array([infer_scene_id(p) for p in paths], dtype=object)\n",
    "print(f\"Unique scene ids inferred: {len(np.unique(scene_ids))} (over {len(scene_ids)} samples)\")\n",
    "\n",
    "try:\n",
    "    fold_assignments = build_fold_assignments(paths, labels, scene_ids, n_splits=5)\n",
    "    fold_counts = Counter(fold_assignments)\n",
    "    print(\"Fold sizes:\", dict(sorted(fold_counts.items())))\n",
    "    ordered_folds = [fold for fold, _ in fold_counts.most_common()]\n",
    "    if len(ordered_folds) < 2:\n",
    "        raise ValueError(\"Need at least two folds for validation/testing.\")\n",
    "    test_fold = ordered_folds[0]\n",
    "    val_fold = ordered_folds[1]\n",
    "    train_idx = np.where((fold_assignments != test_fold) & (fold_assignments != val_fold))[0]\n",
    "    val_idx = np.where(fold_assignments == val_fold)[0]\n",
    "    test_idx = np.where(fold_assignments == test_fold)[0]\n",
    "except Exception as exc:\n",
    "    print(f\"StratifiedGroupKFold failed ({exc}). Falling back to GroupShuffleSplit without stratification.\")\n",
    "    gss_test = GroupShuffleSplit(n_splits=1, test_size=0.20, random_state=RANDOM_SEED)\n",
    "    trainval_idx, test_idx = next(gss_test.split(paths, labels, scene_ids))\n",
    "    gss_val = GroupShuffleSplit(n_splits=1, test_size=0.20, random_state=RANDOM_SEED)\n",
    "    train_idx_rel, val_idx_rel = next(gss_val.split(paths[trainval_idx], labels[trainval_idx], scene_ids[trainval_idx]))\n",
    "    train_idx = trainval_idx[train_idx_rel]\n",
    "    val_idx = trainval_idx[val_idx_rel]\n",
    "\n",
    "train_samples = [samples[i] for i in train_idx]\n",
    "val_samples = [samples[i] for i in val_idx]\n",
    "test_samples = [samples[i] for i in test_idx]\n",
    "\n",
    "\n",
    "def describe_split(name: str, subset_idx: np.ndarray) -> None:\n",
    "    subset_labels = labels[subset_idx]\n",
    "    subset_groups = scene_ids[subset_idx]\n",
    "    total = len(subset_idx)\n",
    "    unique_groups = len(np.unique(subset_groups))\n",
    "    counts = Counter(subset_labels)\n",
    "    missing = sorted(set(range(len(CLASS_NAMES))) - set(counts.keys()))\n",
    "    missing_names = [IDX_TO_CLASS[idx] for idx in missing]\n",
    "    print(f\"{name}: {total} samples | {unique_groups} unique scene ids\")\n",
    "    head = sorted(counts.items(), key=lambda kv: kv[1], reverse=True)[:3]\n",
    "    head_desc = \", \".join(f\"{IDX_TO_CLASS[idx]}: {count} ({count / total:.1%})\" for idx, count in head)\n",
    "    print(f\"  Top classes -> {head_desc}\")\n",
    "    if missing:\n",
    "        print(f\"  Missing classes -> {missing_names}\")\n",
    "    else:\n",
    "        print(\"  Missing classes -> None\")\n",
    "\n",
    "\n",
    "def assert_class_coverage(name: str, subset_idx: np.ndarray) -> None:\n",
    "    subset_labels = set(labels[subset_idx])\n",
    "    missing = sorted(set(range(len(CLASS_NAMES))) - subset_labels)\n",
    "    if missing:\n",
    "        missing_names = \", \".join(IDX_TO_CLASS[idx] for idx in missing)\n",
    "        raise ValueError(f\"{name} split is missing classes: {missing_names}\")\n",
    "\n",
    "\n",
    "describe_split(\"Train\", train_idx)\n",
    "describe_split(\"Val\", val_idx)\n",
    "describe_split(\"Test\", test_idx)\n",
    "\n",
    "assert_class_coverage(\"Train\", train_idx)\n",
    "assert_class_coverage(\"Val\", val_idx)\n",
    "assert_class_coverage(\"Test\", test_idx)\n",
    "\n",
    "print(f\"Train: {len(train_samples)} | Val: {len(val_samples)} | Test: {len(test_samples)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21009ca",
   "metadata": {},
   "source": [
    "\n",
    "### Data Exploration – EuroSAT splits\n",
    "Understanding how many samples each split contains per class helps verify the stratification and spot imbalance we might want to address with weighted losses or sampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be68c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_frames = []\n",
    "for subset_name, subset_idx in (\"train\", train_idx), (\"val\", val_idx), (\"test\", test_idx):\n",
    "    subset_labels = labels[subset_idx]\n",
    "    frame = (\n",
    "        pd.DataFrame({\"subset\": subset_name, \"label_idx\": subset_labels})\n",
    "        .assign(class_name=lambda df: df[\"label_idx\"].map(IDX_TO_CLASS))\n",
    "    )\n",
    "    split_frames.append(frame)\n",
    "\n",
    "distribution_df = pd.concat(split_frames, ignore_index=True)\n",
    "counts = (\n",
    "    distribution_df\n",
    "    .groupby([\"subset\", \"class_name\"], as_index=False)\n",
    "    .size()\n",
    "    .rename(columns={\"size\": \"count\"})\n",
    ")\n",
    "\n",
    "display(counts.pivot(index=\"class_name\", columns=\"subset\", values=\"count\").fillna(0).astype(int))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "for subset_name, subset_df in counts.groupby(\"subset\"):\n",
    "    ax.plot(\n",
    "        subset_df[\"class_name\"],\n",
    "        subset_df[\"count\"],\n",
    "        marker=\"o\",\n",
    "        label=subset_name,\n",
    "    )\n",
    "ax.set_xlabel(\"Class\")\n",
    "ax.set_ylabel(\"Sample count\")\n",
    "ax.set_title(\"Per-class sample counts across splits\")\n",
    "ax.tick_params(axis=\"x\", rotation=45)\n",
    "ax.legend()\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c08fc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths_for_stats = [path for path, _ in train_samples]\n",
    "band_stats = compute_band_percentiles(\n",
    "    train_paths_for_stats,\n",
    "    sample_per_image=1024,\n",
    "    low=2.0,\n",
    "    high=98.0,\n",
    "    max_images=1500,\n",
    "    seed=RANDOM_SEED,\n",
    ")\n",
    "update_global_band_stats(band_stats)\n",
    "\n",
    "print(\n",
    "    f\"Computed global band stats from {band_stats['num_images']} training tiles \"\n",
    "    f\"(sample_per_image={band_stats['sample_per_image']}).\"\n",
    ")\n",
    "for band_idx, (lo, hi) in enumerate(zip(band_stats[\"low\"], band_stats[\"high\"])):\n",
    "    print(f\"  Band {band_idx:02d}: low={lo:.2f}, high={hi:.2f}, range={hi - lo:.2f}\")\n",
    "\n",
    "example_arr = load_multispectral(train_samples[0][0])\n",
    "print(\n",
    "    f\"Example normalized tile stats -> min={example_arr.min():.3f}, \"\n",
    "    f\"max={example_arr.max():.3f}, mean={example_arr.mean():.3f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4858aa1f",
   "metadata": {
    "id": "4858aa1f"
   },
   "source": [
    "## 6) Load Hugging Face EuroSatCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e60759",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LOCAL_MODEL_DIR = Path('/content/drive/MyDrive/ML_HSG/models/Rhodham96-EuroSatCNN')\n",
    "MODEL_DEF_PATH = LOCAL_MODEL_DIR / 'model_def.py'\n",
    "WEIGHTS_PATH = LOCAL_MODEL_DIR / 'pytorch_model.bin'\n",
    "\n",
    "HF_REPO_ID = 'Rhodham96/EuroSatCNN'\n",
    "HF_CACHE_DIR = Path('/content/hf_cache')\n",
    "HF_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "hf_token = os.getenv('HF_TOKEN')\n",
    "hf_download_kwargs = {\n",
    "    'repo_id': HF_REPO_ID,\n",
    "    'cache_dir': str(HF_CACHE_DIR),\n",
    "}\n",
    "if hf_token:\n",
    "    hf_download_kwargs['token'] = hf_token\n",
    "\n",
    "\n",
    "def resolve_model_file(filename: str) -> Path:\n",
    "    local_path = LOCAL_MODEL_DIR / filename\n",
    "    if local_path.exists():\n",
    "        return local_path\n",
    "    return Path(hf_hub_download(filename=filename, **hf_download_kwargs))\n",
    "\n",
    "\n",
    "def load_module_from_path(module_name: str, file_path: Path):\n",
    "    spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    return module\n",
    "\n",
    "\n",
    "model_def_path = resolve_model_file('model_def.py')\n",
    "model_def_module = load_module_from_path('hf_eurosatcnn_def', model_def_path)\n",
    "EuroSatCNN = getattr(model_def_module, 'EuroSatCNN', None)\n",
    "if EuroSatCNN is None:\n",
    "    EuroSatCNN = getattr(model_def_module, 'EuroSATCNN', None)\n",
    "if EuroSatCNN is None:\n",
    "    available = [name for name in dir(model_def_module) if not name.startswith('_')]\n",
    "    raise AttributeError(f\"EuroSatCNN class not found in model_def.py. Available objects: {available}\")\n",
    "\n",
    "weights_path = resolve_model_file('pytorch_model.bin')\n",
    "state_dict = torch.load(weights_path, map_location='cpu')\n",
    "\n",
    "model = EuroSatCNN(num_classes=len(CLASS_NAMES))\n",
    "missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
    "if missing_keys:\n",
    "    print(f\"Warning: missing keys when loading pretrained weights -> {missing_keys}\")\n",
    "if unexpected_keys:\n",
    "    print(f\"Warning: unexpected keys when loading pretrained weights -> {unexpected_keys}\")\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "\n",
    "class EuroSatCNNProcessor:\n",
    "    def __call__(self, images, return_tensors: str = 'pt'):\n",
    "        arr = np.asarray(images, dtype=np.float32)\n",
    "        if arr.ndim != 3:\n",
    "            raise ValueError(f'Expected image with 3 dimensions (H, W, C); got shape={arr.shape}')\n",
    "        if arr.max() > 1.5:\n",
    "            arr = arr / 2750.0\n",
    "        arr = np.clip(arr, 0.0, 1.0)\n",
    "        tensor = torch.from_numpy(np.moveaxis(arr, -1, 0).copy()).float().contiguous()\n",
    "        if return_tensors == 'pt':\n",
    "            tensor = tensor.unsqueeze(0)\n",
    "        return {'pixel_values': tensor}\n",
    "\n",
    "\n",
    "processor = EuroSatCNNProcessor()\n",
    "model.config = SimpleNamespace(\n",
    "    id2label={idx: name for idx, name in enumerate(CLASS_NAMES)},\n",
    "    label2id={name: idx for idx, name in enumerate(CLASS_NAMES)},\n",
    "    num_labels=len(CLASS_NAMES),\n",
    ")\n",
    "\n",
    "print(f\"Loaded EuroSatCNN weights from {weights_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2ce121",
   "metadata": {
    "id": "9e2ce121"
   },
   "source": [
    "## 7) Dataset & DataLoaders with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab209181",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EuroSATDataset(Dataset):\n",
    "    def __init__(self, samples, processor, train: bool = False, augment: bool = False):\n",
    "        self.samples = samples\n",
    "        self.processor = processor\n",
    "        self.train = train\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "\n",
    "    def random_augment(self, arr: np.ndarray) -> np.ndarray:\n",
    "        if random.random() < 0.5:\n",
    "            arr = np.flip(arr, axis=0).copy()\n",
    "        if random.random() < 0.5:\n",
    "            arr = np.flip(arr, axis=1).copy()\n",
    "        if random.random() < 0.5:\n",
    "            k = random.randint(1, 3)\n",
    "            arr = np.rot90(arr, k=k, axes=(0, 1)).copy()\n",
    "        if random.random() < 0.3:\n",
    "            noise = np.random.normal(0.0, 0.02, size=arr.shape).astype(np.float32)\n",
    "            arr = np.clip(arr + noise, 0.0, 1.0)\n",
    "        return arr\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        path, label = self.samples[idx]\n",
    "        arr = load_multispectral(path, normalize=False)  # keep raw reflectance values\n",
    "        arr = np.moveaxis(arr, 0, -1).astype(np.float32, copy=False)   # (H, W, C)\n",
    "        if arr.max() > 1.5:  # scale raw reflectance to match EuroSATCNN training\n",
    "            arr = np.clip(arr / 2750.0, 0.0, 1.0)\n",
    "        if self.train and self.augment:\n",
    "            arr = self.random_augment(arr)\n",
    "        inputs = self.processor(images=arr, return_tensors=\"pt\")\n",
    "        pixel_values = inputs[\"pixel_values\"].squeeze(0)\n",
    "        return {\n",
    "            \"pixel_values\": pixel_values,\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7628f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0  # avoid multiprocessing issues in notebook/Colab environments\n",
    "\n",
    "train_dataset = EuroSATDataset(train_samples, processor, train=True, augment=True)\n",
    "val_dataset = EuroSATDataset(val_samples, processor, train=False, augment=False)\n",
    "test_dataset = EuroSATDataset(test_samples, processor, train=False, augment=False)\n",
    "\n",
    "def make_loader(ds, shuffle: bool = False):\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "train_loader = make_loader(train_dataset, shuffle=True)\n",
    "val_loader = make_loader(val_dataset)\n",
    "test_loader = make_loader(test_dataset)\n",
    "\n",
    "print(f\"Batches -> train: {len(train_loader)} | val: {len(val_loader)} | test: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e53a1af",
   "metadata": {
    "id": "1e53a1af"
   },
   "source": [
    "## 8) Optimiser, Regularisation & Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "29d4ddce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488,
     "referenced_widgets": [
      "8689230883bf465ca8897ed1533bd59a",
      "445d7b6f7cf64846ad3b483454c04bf7",
      "0e0bf93161974ef5b50e11c0c7a9e8a6",
      "0bd84a9a71d3478fa6939b512b5c5fdc",
      "ff30436c33e64ce29fbcf33d7fb773eb",
      "28a88f87747245c69c31b69e47dd99e1",
      "3b98d9b832674465839b2ec4783d51fa",
      "6b69fd21bd0f4287b5b384c4afde789e",
      "f424ea51a39c43e19c7d4ea7159e765b",
      "e93998efa9e7493383d316941d8b9f3f",
      "a800694b6cad413592855b182ac92e7f"
     ]
    },
    "id": "29d4ddce",
    "outputId": "3b39855a-3925-46ea-baba-8e5eef45cf46"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-2110853381.py:17: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8689230883bf465ca8897ed1533bd59a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/15 [train]:   0%|          | 0/540 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-2110853381.py:65: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=USE_AMP):\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "EuroSATCNN.forward() got an unexpected keyword argument 'pixel_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2110853381.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mUSE_AMP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: EuroSATCNN.forward() got an unexpected keyword argument 'pixel_values'"
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "LEARNING_RATE = 2e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "LABEL_SMOOTHING = 0.05\n",
    "GRAD_CLIP = 1.0\n",
    "PATIENCE = 4\n",
    "USE_AMP = torch.cuda.is_available()\n",
    "\n",
    "steps_per_epoch = len(train_loader)\n",
    "total_steps = steps_per_epoch * EPOCHS\n",
    "warmup_steps = max(10, int(0.1 * total_steps))\n",
    "\n",
    "criterion_train = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
    "criterion_eval = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
    "\n",
    "try:\n",
    "    scaler = torch.amp.GradScaler(\"cuda\", enabled=USE_AMP)\n",
    "except TypeError:\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n",
    "\n",
    "_AUTOCAST_KWARGS = {}\n",
    "if hasattr(torch, \"amp\") and hasattr(torch.amp, \"autocast\"):\n",
    "    try:\n",
    "        _ = torch.amp.autocast(device_type=\"cuda\", enabled=False)\n",
    "        autocast_cm = torch.amp.autocast\n",
    "        _AUTOCAST_KWARGS = {\"device_type\": \"cuda\"}\n",
    "    except TypeError:\n",
    "        autocast_cm = torch.cuda.amp.autocast\n",
    "else:\n",
    "    autocast_cm = torch.cuda.amp.autocast\n",
    "\n",
    "def get_model_logits(model, pixel_values):\n",
    "    try:\n",
    "        outputs = model(pixel_values=pixel_values)\n",
    "    except TypeError:\n",
    "        outputs = model(pixel_values)\n",
    "    if isinstance(outputs, torch.Tensor):\n",
    "        return outputs\n",
    "    if isinstance(outputs, dict):\n",
    "        if \"logits\" in outputs:\n",
    "            return outputs[\"logits\"]\n",
    "        raise KeyError(\"Model output dict missing 'logits'\")\n",
    "    if hasattr(outputs, \"logits\"):\n",
    "        return outputs.logits\n",
    "    raise AttributeError(\"Model output does not include logits\")\n",
    "\n",
    "def evaluate(model, loader, criterion=None):\n",
    "    model.eval()\n",
    "    loss_sum = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            pixel_values = batch[\"pixel_values\"].to(DEVICE, non_blocking=True)\n",
    "            labels = batch[\"labels\"].to(DEVICE, non_blocking=True)\n",
    "            logits = get_model_logits(model, pixel_values)\n",
    "            if criterion is not None:\n",
    "                loss = criterion(logits, labels)\n",
    "                loss_sum += loss.item() * labels.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_preds.append(preds.cpu())\n",
    "    avg_loss = (loss_sum / total) if (criterion is not None and total > 0) else float('nan')\n",
    "    acc = correct / total if total else 0.0\n",
    "    all_labels = torch.cat(all_labels).numpy() if all_labels else np.array([])\n",
    "    all_preds = torch.cat(all_preds).numpy() if all_preds else np.array([])\n",
    "    return {\"loss\": avg_loss, \"acc\": acc, \"labels\": all_labels, \"preds\": all_preds}\n",
    "\n",
    "history = []\n",
    "best_state = None\n",
    "best_val_acc = 0.0\n",
    "best_epoch = -1\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    epoch_correct = 0\n",
    "    epoch_total = 0\n",
    "    progress = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} [train]\", leave=False)\n",
    "    for batch in progress:\n",
    "        pixel_values = batch[\"pixel_values\"].to(DEVICE, non_blocking=True)\n",
    "        labels = batch[\"labels\"].to(DEVICE, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with autocast_cm(enabled=USE_AMP, **_AUTOCAST_KWARGS):\n",
    "            logits = get_model_logits(model, pixel_values)\n",
    "            loss = criterion_train(logits, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        preds = logits.detach().argmax(dim=1)\n",
    "        epoch_loss += loss.item() * labels.size(0)\n",
    "        epoch_correct += (preds == labels).sum().item()\n",
    "        epoch_total += labels.size(0)\n",
    "\n",
    "        progress.set_postfix({\n",
    "            \"loss\": f\"{loss.item():.4f}\",\n",
    "            \"acc\": f\"{(preds == labels).float().mean().item():.3f}\"\n",
    "        })\n",
    "\n",
    "    train_loss = epoch_loss / epoch_total\n",
    "    train_acc = epoch_correct / epoch_total\n",
    "\n",
    "    val_metrics = evaluate(model, val_loader, criterion_eval)\n",
    "    history.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"val_loss\": val_metrics[\"loss\"],\n",
    "        \"val_acc\": val_metrics[\"acc\"]\n",
    "    })\n",
    "\n",
    "    print(f\"Epoch {epoch}: train_loss={train_loss:.4f} train_acc={train_acc:.4f} | val_loss={val_metrics['loss']:.4f} val_acc={val_metrics['acc']:.4f}\")\n",
    "\n",
    "    if val_metrics[\"acc\"] > best_val_acc:\n",
    "        best_val_acc = val_metrics[\"acc\"]\n",
    "        best_epoch = epoch\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "        patience_counter = 0\n",
    "        print(f\"--> New best model (val_acc={best_val_acc:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "    torch.save(best_state, \"eurosatcnn_best.pt\")\n",
    "    print(f\"Restored best model from epoch {best_epoch} (val_acc={best_val_acc:.4f})\")\n",
    "else:\n",
    "    print(\"Warning: best_state is None – training may have failed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1c42ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history)\n",
    "if history_df.empty:\n",
    "    print(\"Training history is empty; no plots to display.\")\n",
    "else:\n",
    "    display(history_df)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    axes[0].plot(history_df['epoch'], history_df['train_loss'], label='Train', marker='o')\n",
    "    axes[0].plot(history_df['epoch'], history_df['val_loss'], label='Validation', marker='o')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Loss per Epoch')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "    axes[1].plot(history_df['epoch'], history_df['train_acc'], label='Train', marker='o')\n",
    "    axes[1].plot(history_df['epoch'], history_df['val_acc'], label='Validation', marker='o')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Accuracy per Epoch')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    best_idx = history_df['val_acc'].idxmax()\n",
    "    best_row = history_df.loc[best_idx]\n",
    "    print(f\"Best validation accuracy: {best_row['val_acc']:.4f} at epoch {int(best_row['epoch'])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d75d60",
   "metadata": {
    "id": "81d75d60"
   },
   "source": [
    "## 9) Evaluate on Held-out Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19608276",
   "metadata": {
    "id": "19608276"
   },
   "outputs": [],
   "source": [
    "test_metrics = evaluate(model, test_loader, criterion_eval)\n",
    "print(f\"Test accuracy: {test_metrics['acc']:.4f}\")\n",
    "\n",
    "report_dict = classification_report(\n",
    "    test_metrics['labels'],\n",
    "    test_metrics['preds'],\n",
    "    target_names=CLASS_NAMES,\n",
    "    digits=4,\n",
    "    output_dict=True\n",
    ")\n",
    "report_df = pd.DataFrame(report_dict).T\n",
    "report_df.index.name = 'class'\n",
    "report_df.reset_index(inplace=True)\n",
    "display(report_df)\n",
    "\n",
    "cm = confusion_matrix(test_metrics['labels'], test_metrics['preds'])\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=CLASS_NAMES,\n",
    "    yticklabels=CLASS_NAMES,\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_xlabel('Predicted label')\n",
    "ax.set_ylabel('True label')\n",
    "ax.set_title('Confusion Matrix (Test Set)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "per_class_df = (\n",
    "    pd.DataFrame({\n",
    "        'label': test_metrics['labels'],\n",
    "        'pred': test_metrics['preds']\n",
    "    })\n",
    "    .assign(correct=lambda df: (df['label'] == df['pred']).astype(float))\n",
    "    .groupby('label')['correct']\n",
    "    .mean()\n",
    "    .mul(100)\n",
    "    .rename('accuracy')\n",
    "    .reset_index()\n",
    ")\n",
    "per_class_df['class'] = per_class_df['label'].map(IDX_TO_CLASS)\n",
    "per_class_df = per_class_df.sort_values('accuracy', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "positions = np.arange(len(per_class_df))\n",
    "ax.bar(positions, per_class_df['accuracy'], color='steelblue')\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(per_class_df['class'], rotation=45, ha='right')\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_title('Per-class Accuracy (Test Set)')\n",
    "ax.set_ylim(0, 100)\n",
    "ax.grid(True, axis='y', linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2dfb09",
   "metadata": {
    "id": "9b2dfb09"
   },
   "source": [
    "## 10) Kaggle Inference & Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b8586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount (again) in case the session was reset before inference\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "if not KAGGLE_ZIP_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Kaggle archive not found at {KAGGLE_ZIP_PATH}\")\n",
    "\n",
    "KAGGLE_ROOT = Path('/content/kaggle_data')\n",
    "KAGGLE_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not any(KAGGLE_ROOT.iterdir()):\n",
    "    print(f\"Extracting {KAGGLE_ZIP_PATH} ...\")\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(KAGGLE_ZIP_PATH, 'r') as zf:\n",
    "        zf.extractall(KAGGLE_ROOT)\n",
    "else:\n",
    "    print(f\"Kaggle data already extracted at {KAGGLE_ROOT}\")\n",
    "\n",
    "search_patterns = [\n",
    "    str(KAGGLE_ROOT / '**' / 'testset' / 'testset' / '*.npy'),\n",
    "    str(KAGGLE_ROOT / '**' / 'testset' / '*.npy'),\n",
    "    str(KAGGLE_ROOT / '**' / '*.npy'),\n",
    "]\n",
    "\n",
    "npy_paths = []\n",
    "for pattern in search_patterns:\n",
    "    hits = sorted(Path(p) for p in glob.glob(pattern, recursive=True))\n",
    "    if hits:\n",
    "        npy_paths = hits\n",
    "        break\n",
    "\n",
    "if len(npy_paths) == 0:\n",
    "    raise FileNotFoundError('No .npy files found in Kaggle archive')\n",
    "\n",
    "print(f\"Found {len(npy_paths)} inference tiles. Example: {npy_paths[:3]}\")\n",
    "\n",
    "def summarize_kaggle_tiles(paths, max_files: int = None):\n",
    "    channel_counter = Counter()\n",
    "    global_min = float('inf')\n",
    "    global_max = float('-inf')\n",
    "    examined = 0\n",
    "    for path in paths if max_files is None else paths[:max_files]:\n",
    "        arr = np.load(path, allow_pickle=False)\n",
    "        arr = ensure_channel_first(arr, source=str(path))\n",
    "        channel_counter[arr.shape[0]] += 1\n",
    "        global_min = min(global_min, float(arr.min()))\n",
    "        global_max = max(global_max, float(arr.max()))\n",
    "        examined += 1\n",
    "    print(f\"Kaggle tiles examined: {examined}\")\n",
    "    print('Channel-count distribution:', dict(sorted(channel_counter.items())))\n",
    "    print(f\"Global value range across examined tiles: [{global_min:.4f}, {global_max:.4f}]\")\n",
    "\n",
    "summarize_kaggle_tiles(npy_paths)\n",
    "\n",
    "def extract_id(stem: str) -> int:\n",
    "    match = re.search(r'(\\d+)$', stem)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    digits = ''.join(ch for ch in stem if ch.isdigit())\n",
    "    return int(digits) if digits else -1\n",
    "\n",
    "\n",
    "class EuroSATNPYDataset(Dataset):\n",
    "    def __init__(self, paths, processor, check_preview: bool = True):\n",
    "        self.paths = paths\n",
    "        self.processor = processor\n",
    "        self.check_preview = check_preview\n",
    "        if self.check_preview and len(self.paths) > 0:\n",
    "            self._preview_statistics()\n",
    "\n",
    "    def _preview_statistics(self, num_examples: int = 3):\n",
    "        mins = []\n",
    "        maxs = []\n",
    "        channel_counts = []\n",
    "        for path in self.paths[:num_examples]:\n",
    "            arr = np.load(path, allow_pickle=False)\n",
    "            arr = ensure_channel_first(arr, source=str(path))\n",
    "            channel_counts.append(arr.shape[0])\n",
    "            mins.append(float(arr.min()))\n",
    "            maxs.append(float(arr.max()))\n",
    "        print(\n",
    "            'Kaggle tile preview -> '\n",
    "            f\"channels={sorted(set(channel_counts))} | \"\n",
    "            f\"value range~[{min(mins):.3f}, {max(maxs):.3f}]\"\n",
    "        )\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        arr = np.load(path, allow_pickle=False)\n",
    "        arr = ensure_channel_first(arr, source=str(path))\n",
    "        arr = pad_to_13_bands(arr)\n",
    "        arr = np.moveaxis(arr, 0, -1).astype(np.float32, copy=False)\n",
    "        if arr.max() > 1.5:\n",
    "            arr = np.clip(arr / 2750.0, 0.0, 1.0)\n",
    "        if self.processor is not None:\n",
    "            inputs = self.processor(images=arr, return_tensors='pt')\n",
    "            pixel_values = inputs['pixel_values'].squeeze(0)\n",
    "        else:\n",
    "            chw = np.moveaxis(arr, -1, 0)\n",
    "            pixel_values = torch.from_numpy(chw.copy()).float()\n",
    "        sample_id = extract_id(path.stem)\n",
    "        return {'pixel_values': pixel_values, 'id': sample_id}\n",
    "\n",
    "\n",
    "kaggle_dataset = EuroSATNPYDataset(npy_paths, processor)\n",
    "kaggle_loader = DataLoader(kaggle_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "model.eval()\n",
    "pred_ids = []\n",
    "pred_indices = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(kaggle_loader, desc='Kaggle inference'):\n",
    "        pixel_values = batch['pixel_values'].to(DEVICE, non_blocking=True)\n",
    "        logits = get_model_logits(model, pixel_values)\n",
    "        preds = logits.argmax(dim=1).cpu().tolist()\n",
    "        pred_indices.extend(preds)\n",
    "        if isinstance(batch['id'], torch.Tensor):\n",
    "            pred_ids.extend(batch['id'].cpu().tolist())\n",
    "        else:\n",
    "            pred_ids.extend(batch['id'])\n",
    "\n",
    "pred_labels = [IDX_TO_CLASS[idx] for idx in pred_indices]\n",
    "submission = pd.DataFrame({'test_id': pred_ids, 'label': pred_labels})\n",
    "submission = submission.sort_values('test_id').reset_index(drop=True)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "submission_filename = f'submission_{timestamp}.csv'\n",
    "submission_path = Path('/content') / submission_filename\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f'Saved submission to {submission_path}')\n",
    "print(submission.head())\n",
    "\n",
    "output_dir = Path('/content/drive/MyDrive/ML_HSG/kaggle_submissions')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "drive_path = output_dir / submission_filename\n",
    "shutil.copy(submission_path, drive_path)\n",
    "print(f'Copied submission to {drive_path}')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0bd84a9a71d3478fa6939b512b5c5fdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e93998efa9e7493383d316941d8b9f3f",
      "placeholder": "​",
      "style": "IPY_MODEL_a800694b6cad413592855b182ac92e7f",
      "value": " 0/540 [00:02&lt;?, ?it/s]"
     }
    },
    "0e0bf93161974ef5b50e11c0c7a9e8a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b69fd21bd0f4287b5b384c4afde789e",
      "max": 540,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f424ea51a39c43e19c7d4ea7159e765b",
      "value": 0
     }
    },
    "28a88f87747245c69c31b69e47dd99e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b98d9b832674465839b2ec4783d51fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "445d7b6f7cf64846ad3b483454c04bf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28a88f87747245c69c31b69e47dd99e1",
      "placeholder": "​",
      "style": "IPY_MODEL_3b98d9b832674465839b2ec4783d51fa",
      "value": "Epoch 1/15 [train]:   0%"
     }
    },
    "6b69fd21bd0f4287b5b384c4afde789e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8689230883bf465ca8897ed1533bd59a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_445d7b6f7cf64846ad3b483454c04bf7",
       "IPY_MODEL_0e0bf93161974ef5b50e11c0c7a9e8a6",
       "IPY_MODEL_0bd84a9a71d3478fa6939b512b5c5fdc"
      ],
      "layout": "IPY_MODEL_ff30436c33e64ce29fbcf33d7fb773eb"
     }
    },
    "a800694b6cad413592855b182ac92e7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e93998efa9e7493383d316941d8b9f3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f424ea51a39c43e19c7d4ea7159e765b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ff30436c33e64ce29fbcf33d7fb773eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
