{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3ce5556",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 900px; height: auto\" src=\"../assets/banner.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a15df93",
   "metadata": {},
   "source": [
    "###  Coding Challenge Template - EuroSAT Classification\n",
    "\n",
    "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"../assets/hsg_logo.png\">\n",
    "<img align=\"center\" style=\"max-width: 300px; height: auto\" src=\"./sentinel2.jpg\">\n",
    "\n",
    "7,854,1.00 MCS Machine Learning, University of St.Gallen (HSG)\n",
    "\n",
    "**Task**: Create a model to predict the most likely EuroSAT class for each image of the testset.\n",
    "\n",
    "**Approach**: Build a complete machine learning pipeline including data loading, preprocessing, model architecture, training, and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0c4808",
   "metadata": {},
   "source": [
    "### Objectives:\n",
    "- Create a dataset class and data-loader for training\n",
    "- Design and implement a suitable model architecture\n",
    "- Address the potential domain shift between train and test data\n",
    "- Train and evaluate the model performance\n",
    "- Generate predictions for the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f690df86",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2581c21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Raster data handling\n",
    "import rasterio as rio\n",
    "from rasterio.plot import reshape_as_image\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Machine Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Utilities\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b43ce01",
   "metadata": {},
   "source": [
    "## 2. Configuration and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac597f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'eurosat_dir': \"/ds2/remote_sensing/eurosat\",  # Update this path\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 50,\n",
    "    'learning_rate': 0.001,\n",
    "    'validation_split': 0.2,\n",
    "    'num_workers': 4,\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "}\n",
    "\n",
    "# EuroSAT classes\n",
    "CLASSES = [\n",
    "    \"AnnualCrop\",\n",
    "    \"Forest\", \n",
    "    \"HerbaceousVegetation\",\n",
    "    \"Highway\",\n",
    "    \"Industrial\",\n",
    "    \"Pasture\",\n",
    "    \"PermanentCrop\",\n",
    "    \"Residential\",\n",
    "    \"River\",\n",
    "    \"SeaLake\",\n",
    "]\n",
    "\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "CLASS_TO_IDX = {cls: idx for idx, cls in enumerate(CLASSES)}\n",
    "IDX_TO_CLASS = {idx: cls for idx, cls in enumerate(CLASSES)}\n",
    "\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")\n",
    "print(f\"Using device: {CONFIG['device']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aea4c33",
   "metadata": {},
   "source": [
    "## 3. Data Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f86e32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_for_display(band_data):\n",
    "    \"\"\"Normalize multi-spectral imagery across bands for visualization.\"\"\"\n",
    "    band_data = np.array(band_data)\n",
    "    lower_perc = np.percentile(band_data, 2, axis=(0,1))\n",
    "    upper_perc = np.percentile(band_data, 98, axis=(0,1))\n",
    "    \n",
    "    return (band_data - lower_perc) / (upper_perc - lower_perc)\n",
    "\n",
    "def normalize_for_model(band_data):\n",
    "    \"\"\"Normalize multi-spectral imagery for model training.\n",
    "    \n",
    "    TODO: Implement proper normalization strategy for model input.\n",
    "    Consider:\n",
    "    - Per-band standardization (z-score)\n",
    "    - Min-max normalization\n",
    "    - Using training set statistics for test set\n",
    "    \"\"\"\n",
    "    # Placeholder - implement your normalization strategy\n",
    "    return band_data.astype(np.float32)\n",
    "\n",
    "def visualize_sample(img_data, title=\"Sample\", figsize=(10, 5)):\n",
    "    \"\"\"Visualize a multi-spectral sample.\"\"\"\n",
    "    normalized_img = normalize_for_display(img_data)\n",
    "    rgb_img = normalized_img[:, :, [3, 2, 1]]  # RGB bands for Sentinel-2\n",
    "    \n",
    "    # Calculate NDVI\n",
    "    b8 = img_data[:, :, 7]  # Near-infrared\n",
    "    b4 = img_data[:, :, 3]  # Red\n",
    "    ndvi = (b8 - b4) / (b8 + b4 + 1e-8)  # Add small epsilon to avoid division by zero\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "    \n",
    "    ax1.imshow(rgb_img)\n",
    "    ax1.set_title(f\"{title} - RGB\")\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2.imshow(ndvi, cmap='RdYlGn')\n",
    "    ax2.set_title(f\"{title} - NDVI\")\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad06e59f",
   "metadata": {},
   "source": [
    "## 4. Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70e523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EuroSATDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for EuroSAT satellite imagery.\"\"\"\n",
    "    \n",
    "    def __init__(self, file_paths, labels=None, transform=None, is_test=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_paths: List of file paths to images\n",
    "            labels: List of labels (None for test set)\n",
    "            transform: Optional transform to be applied on a sample\n",
    "            is_test: Boolean indicating if this is test data\n",
    "        \"\"\"\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        \n",
    "        # Load data based on file type\n",
    "        if file_path.endswith('.npy'):\n",
    "            # Test data (.npy files)\n",
    "            img = np.load(file_path)\n",
    "        else:\n",
    "            # Training data (.tif files)\n",
    "            with rio.open(file_path, \"r\") as f:\n",
    "                img = f.read([1,2,3,4,5,6,7,8,9,10,11,12,13])\n",
    "                img = reshape_as_image(img)\n",
    "        \n",
    "        # Normalize for model input\n",
    "        img = normalize_for_model(img)\n",
    "        \n",
    "        # Convert to tensor and rearrange dimensions (H, W, C) -> (C, H, W)\n",
    "        img = torch.from_numpy(img).permute(2, 0, 1)\n",
    "        \n",
    "        # Apply transforms if provided\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        if self.is_test:\n",
    "            return img, file_path\n",
    "        else:\n",
    "            label = self.labels[idx]\n",
    "            return img, label\n",
    "\n",
    "# TODO: Implement data augmentation transforms\n",
    "# Consider transforms like:\n",
    "# - Random rotation\n",
    "# - Random horizontal/vertical flip\n",
    "# - Random crop and resize\n",
    "# - Color jittering (for RGB bands)\n",
    "# - Gaussian noise addition\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    # TODO: Add your data augmentation transforms here\n",
    "    # transforms.RandomRotation(degrees=30),\n",
    "    # transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # transforms.RandomVerticalFlip(p=0.5),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    # TODO: Add validation transforms (usually just normalization)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e713c122",
   "metadata": {},
   "source": [
    "## 5. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21413bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data file paths and labels\n",
    "train_samples = glob.glob(os.path.join(CONFIG['eurosat_dir'], \"*\", \"*.tif\"))\n",
    "print(f\"Found {len(train_samples)} training samples\")\n",
    "\n",
    "# Extract labels from file paths\n",
    "train_labels = []\n",
    "for sample in train_samples:\n",
    "    label = sample.split('/')[-1].split('_')[0]\n",
    "    train_labels.append(CLASS_TO_IDX[label])\n",
    "\n",
    "print(f\"Number of training samples: {len(train_samples)}\")\n",
    "print(f\"Label distribution:\")\n",
    "label_counts = pd.Series(train_labels).value_counts().sort_index()\n",
    "for idx, count in label_counts.items():\n",
    "    print(f\"  {IDX_TO_CLASS[idx]}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f252612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "testset_dir = os.path.join(CONFIG['eurosat_dir'], \"testset\")\n",
    "test_samples = glob.glob(os.path.join(testset_dir, \"*.npy\"))\n",
    "print(f\"Found {len(test_samples)} test samples\")\n",
    "\n",
    "# Sort test samples for consistent ordering\n",
    "test_samples.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c32562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "class_names = [IDX_TO_CLASS[i] for i in range(NUM_CLASSES)]\n",
    "counts = [label_counts.get(i, 0) for i in range(NUM_CLASSES)]\n",
    "\n",
    "plt.bar(class_names, counts)\n",
    "plt.title('Distribution of Classes in Training Data')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc68953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from each class\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, class_name in enumerate(CLASSES):\n",
    "    # Find a sample from this class\n",
    "    class_samples = [s for s in train_samples if class_name in s]\n",
    "    if class_samples:\n",
    "        sample_path = class_samples[0]\n",
    "        \n",
    "        # Load and display\n",
    "        with rio.open(sample_path, \"r\") as f:\n",
    "            img = f.read([1,2,3,4,5,6,7,8,9,10,11,12,13])\n",
    "            img = reshape_as_image(img)\n",
    "        \n",
    "        normalized_img = normalize_for_display(img)\n",
    "        rgb_img = normalized_img[:, :, [3, 2, 1]]\n",
    "        \n",
    "        axes[i].imshow(rgb_img)\n",
    "        axes[i].set_title(class_name, fontsize=10)\n",
    "        axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Images from Each Class', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3240581f",
   "metadata": {},
   "source": [
    "## 6. Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b131b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into train and validation sets\n",
    "train_paths, val_paths, train_labels_split, val_labels_split = train_test_split(\n",
    "    train_samples, train_labels, \n",
    "    test_size=CONFIG['validation_split'], \n",
    "    stratify=train_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_paths)}\")\n",
    "print(f\"Validation samples: {len(val_paths)}\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = EuroSATDataset(train_paths, train_labels_split, transform=train_transforms)\n",
    "val_dataset = EuroSATDataset(val_paths, val_labels_split, transform=val_transforms)\n",
    "test_dataset = EuroSATDataset(test_samples, transform=val_transforms, is_test=True)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=CONFIG['batch_size'], \n",
    "    shuffle=True, \n",
    "    num_workers=CONFIG['num_workers']\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=CONFIG['batch_size'], \n",
    "    shuffle=False, \n",
    "    num_workers=CONFIG['num_workers']\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=CONFIG['batch_size'], \n",
    "    shuffle=False, \n",
    "    num_workers=CONFIG['num_workers']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7354a95d",
   "metadata": {},
   "source": [
    "## 7. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db205172",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EuroSATClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN model for EuroSAT classification.\n",
    "    \n",
    "    TODO: Design your model architecture. Consider:\n",
    "    - Convolutional layers for feature extraction\n",
    "    - Batch normalization for training stability\n",
    "    - Dropout for regularization\n",
    "    - Appropriate pooling layers\n",
    "    - Multi-spectral input handling (13 bands)\n",
    "    - Skip connections or attention mechanisms\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=NUM_CLASSES, input_channels=13):\n",
    "        super(EuroSATClassifier, self).__init__()\n",
    "        \n",
    "        # TODO: Implement your architecture\n",
    "        # Example basic architecture:\n",
    "        self.features = nn.Sequential(\n",
    "            # First conv block\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Second conv block\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Third conv block\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Fourth conv block\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = EuroSATClassifier(num_classes=NUM_CLASSES)\n",
    "model = model.to(CONFIG['device'])\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af76c8",
   "metadata": {},
   "source": [
    "## 8. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a12db60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO: Experiment with different optimizers and parameters\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'])\n",
    "\n",
    "# TODO: Consider learning rate scheduling\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb169d9",
   "metadata": {},
   "source": [
    "## 9. Training and Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59578d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"Train the model for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc='Training')\n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'Loss': f'{running_loss/(batch_idx+1):.4f}',\n",
    "            'Acc': f'{100*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate the model for one epoch.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc='Validation')\n",
    "        for batch_idx, (data, target) in enumerate(pbar):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'Loss': f'{running_loss/(batch_idx+1):.4f}',\n",
    "                'Acc': f'{100*correct/total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8343241",
   "metadata": {},
   "source": [
    "## 10. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274555bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement training loop\n",
    "print(\"Starting training...\")\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(CONFIG['num_epochs']):\n",
    "    print(f\"\\nEpoch {epoch+1}/{CONFIG['num_epochs']}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, CONFIG['device'])\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = validate_epoch(model, val_loader, criterion, CONFIG['device'])\n",
    "    \n",
    "    # Update history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Print epoch results\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f\"New best model saved with validation accuracy: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    # TODO: Implement early stopping if needed\n",
    "    # if early_stopping_condition:\n",
    "    #     break\n",
    "\n",
    "print(f\"\\nTraining completed. Best validation accuracy: {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db562ce",
   "metadata": {},
   "source": [
    "## 11. Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f35958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(history['train_loss'], label='Train Loss')\n",
    "ax1.plot(history['val_loss'], label='Validation Loss')\n",
    "ax1.set_title('Model Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Accuracy plot\n",
    "ax2.plot(history['train_acc'], label='Train Accuracy')\n",
    "ax2.plot(history['val_acc'], label='Validation Accuracy')\n",
    "ax2.set_title('Model Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad586f93",
   "metadata": {},
   "source": [
    "## 12. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8663215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for evaluation\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Get predictions on validation set\n",
    "val_predictions = []\n",
    "val_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in tqdm(val_loader, desc='Getting validation predictions'):\n",
    "        data, target = data.to(CONFIG['device']), target.to(CONFIG['device'])\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        \n",
    "        val_predictions.extend(predicted.cpu().numpy())\n",
    "        val_true_labels.extend(target.cpu().numpy())\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(val_true_labels, val_predictions, target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e14dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(val_true_labels, val_predictions)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=CLASSES, yticklabels=CLASSES)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64de5c20",
   "metadata": {},
   "source": [
    "## 13. Domain Shift Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d6013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze domain shift between training and test data\n",
    "# This is crucial for this challenge as mentioned in the notebook\n",
    "\n",
    "def analyze_domain_shift():\n",
    "    \"\"\"\n",
    "    Analyze potential domain shift between training and test data.\n",
    "    \n",
    "    TODO: Implement analysis techniques:\n",
    "    - Statistical comparison of band values\n",
    "    - Distribution comparison (histograms, KL divergence)\n",
    "    - Principal Component Analysis (PCA)\n",
    "    - Feature visualization with t-SNE or UMAP\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sample some training and test data for comparison\n",
    "    sample_train_data = []\n",
    "    sample_test_data = []\n",
    "    \n",
    "    # Get training samples\n",
    "    for i in range(min(100, len(train_samples))):\n",
    "        with rio.open(train_samples[i], \"r\") as f:\n",
    "            img = f.read([1,2,3,4,5,6,7,8,9,10,11,12,13])\n",
    "            img = reshape_as_image(img)\n",
    "            sample_train_data.append(img.flatten())\n",
    "    \n",
    "    # Get test samples\n",
    "    for i in range(min(100, len(test_samples))):\n",
    "        img = np.load(test_samples[i])\n",
    "        sample_test_data.append(img.flatten())\n",
    "    \n",
    "    sample_train_data = np.array(sample_train_data)\n",
    "    sample_test_data = np.array(sample_test_data)\n",
    "    \n",
    "    # Compare statistics\n",
    "    print(\"Training data statistics (mean, std):\")\n",
    "    print(f\"Mean: {sample_train_data.mean():.4f}, Std: {sample_train_data.std():.4f}\")\n",
    "    \n",
    "    print(\"Test data statistics (mean, std):\")\n",
    "    print(f\"Mean: {sample_test_data.mean():.4f}, Std: {sample_test_data.std():.4f}\")\n",
    "    \n",
    "    # TODO: Add more sophisticated analysis\n",
    "    \n",
    "analyze_domain_shift()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aab6c8",
   "metadata": {},
   "source": [
    "## 14. Domain Adaptation Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4512f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement domain adaptation techniques to address domain shift\n",
    "# Possible approaches:\n",
    "# 1. Test Time Adaptation (TTA)\n",
    "# 2. Domain Adversarial Training\n",
    "# 3. Self-training/Pseudo-labeling on test data\n",
    "# 4. Statistical normalization alignment\n",
    "# 5. Fine-tuning on a subset of test data (if allowed)\n",
    "\n",
    "def apply_test_time_adaptation(model, test_loader):\n",
    "    \"\"\"\n",
    "    Apply Test Time Adaptation techniques.\n",
    "    \n",
    "    TODO: Implement TTA strategies:\n",
    "    - Entropy minimization\n",
    "    - Batch normalization adaptation\n",
    "    - Self-supervised objectives\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def normalize_test_data_with_train_stats(test_data, train_stats):\n",
    "    \"\"\"\n",
    "    Normalize test data using training data statistics.\n",
    "    \n",
    "    TODO: Implement proper normalization alignment\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# Placeholder for domain adaptation implementation\n",
    "print(\"TODO: Implement domain adaptation techniques\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d35908d",
   "metadata": {},
   "source": [
    "## 15. Test Set Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3841a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test set\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "test_filenames = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, filenames in tqdm(test_loader, desc='Generating test predictions'):\n",
    "        data = data.to(CONFIG['device'])\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        \n",
    "        test_predictions.extend(predicted.cpu().numpy())\n",
    "        test_filenames.extend(filenames)\n",
    "\n",
    "# Convert predictions to class names\n",
    "test_class_predictions = [IDX_TO_CLASS[pred] for pred in test_predictions]\n",
    "\n",
    "print(f\"Generated {len(test_predictions)} predictions\")\n",
    "print(\"Sample predictions:\", test_class_predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575d0e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'filename': [os.path.basename(f) for f in test_filenames],\n",
    "    'predicted_class': test_class_predictions\n",
    "})\n",
    "\n",
    "submission_df = submission_df.sort_values('filename').reset_index(drop=True)\n",
    "submission_df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "print(\"Submission file created: predictions.csv\")\n",
    "print(submission_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a753fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze test predictions distribution\n",
    "prediction_counts = pd.Series(test_class_predictions).value_counts()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(prediction_counts.index, prediction_counts.values)\n",
    "plt.title('Distribution of Predicted Classes on Test Set')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of Predictions')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Test set prediction distribution:\")\n",
    "for class_name, count in prediction_counts.items():\n",
    "    print(f\"  {class_name}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7b6d22",
   "metadata": {},
   "source": [
    "## 16. Model Interpretation and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aee468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement model interpretation techniques\n",
    "# - Gradient-based attribution methods\n",
    "# - Occlusion analysis\n",
    "# - Feature visualization\n",
    "# - Band importance analysis for multi-spectral data\n",
    "\n",
    "def analyze_band_importance():\n",
    "    \"\"\"Analyze which spectral bands are most important for classification.\"\"\"\n",
    "    # TODO: Implement band importance analysis\n",
    "    pass\n",
    "\n",
    "def visualize_model_attention():\n",
    "    \"\"\"Visualize what the model is focusing on.\"\"\"\n",
    "    # TODO: Implement attention visualization\n",
    "    pass\n",
    "\n",
    "print(\"TODO: Implement model interpretation and analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0543da",
   "metadata": {},
   "source": [
    "## 17. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4958e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform detailed error analysis\n",
    "# - Identify most confused classes\n",
    "# - Analyze failure cases\n",
    "# - Visualize misclassified samples\n",
    "\n",
    "def analyze_misclassified_samples():\n",
    "    \"\"\"Analyze samples that were misclassified.\"\"\"\n",
    "    # TODO: Implement error analysis\n",
    "    pass\n",
    "\n",
    "def analyze_class_confusion():\n",
    "    \"\"\"Analyze which classes are most often confused.\"\"\"\n",
    "    # TODO: Implement class confusion analysis\n",
    "    pass\n",
    "\n",
    "print(\"TODO: Implement error analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607c3e55",
   "metadata": {},
   "source": [
    "## 18. Model Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57059d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Ideas for model improvements:\n",
    "# 1. Advanced architectures (ResNet, EfficientNet, Vision Transformers)\n",
    "# 2. Multi-scale feature extraction\n",
    "# 3. Attention mechanisms\n",
    "# 4. Ensemble methods\n",
    "# 5. Advanced data augmentation\n",
    "# 6. Transfer learning from pre-trained models\n",
    "# 7. Multi-task learning (e.g., NDVI regression as auxiliary task)\n",
    "# 8. Advanced regularization techniques\n",
    "\n",
    "print(\"TODO: Implement model improvements\")\n",
    "print(\"Consider:\")\n",
    "print(\"- Advanced CNN architectures (ResNet, EfficientNet)\")\n",
    "print(\"- Vision Transformers\")\n",
    "print(\"- Ensemble methods\")\n",
    "print(\"- Advanced data augmentation\")\n",
    "print(\"- Transfer learning\")\n",
    "print(\"- Multi-task learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd61e65b",
   "metadata": {},
   "source": [
    "## 19. Final Evaluation and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c40fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of results\n",
    "print(\"=\"*50)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"Total Training Samples: {len(train_paths):,}\")\n",
    "print(f\"Total Validation Samples: {len(val_paths):,}\")\n",
    "print(f\"Total Test Samples: {len(test_samples):,}\")\n",
    "print(f\"Model Parameters: {trainable_params:,}\")\n",
    "print(f\"Training Epochs: {len(history['train_loss'])}\")\n",
    "\n",
    "# TODO: Add more comprehensive evaluation metrics\n",
    "# - Per-class accuracy\n",
    "# - F1-scores\n",
    "# - Model confidence analysis\n",
    "# - Uncertainty quantification\n",
    "\n",
    "print(\"\\nTODO: Complete implementation of all sections marked with TODO\")\n",
    "print(\"Focus areas for improvement:\")\n",
    "print(\"1. Implement proper data normalization\")\n",
    "print(\"2. Design better model architecture\")  \n",
    "print(\"3. Add data augmentation techniques\")\n",
    "print(\"4. Address domain shift between train and test data\")\n",
    "print(\"5. Implement domain adaptation methods\")\n",
    "print(\"6. Add model interpretation and error analysis\")\n",
    "print(\"7. Experiment with advanced techniques\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
