{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7b1bf07",
   "metadata": {},
   "source": [
    "# Code Challenge 1 — B10 Reconstruction & Inference Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a95877",
   "metadata": {},
   "source": [
    "This notebook trains a lightweight CNN to reconstruct the missing Sentinel-2 B10 band and then applies a pre-trained EuroSAT classifier to Kaggle tiles after inserting the predicted band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b68e34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cyrilgabriele/anaconda3/envs/ml/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/cyrilgabriele/anaconda3/envs/ml/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import os, random, math, re, zipfile, platform\n",
    "import sys\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "if not hasattr(np, 'float'):\n",
    "    np.float = float\n",
    "if not hasattr(np, 'int'):\n",
    "    np.int = int\n",
    "if not hasattr(np, 'bool'):\n",
    "    np.bool = bool\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from timm.models.layers import trunc_normal_\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import rasterio\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, roc_curve, auc, roc_auc_score, precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available() and hasattr(torch, 'mps'):\n",
    "        torch.mps.manual_seed(seed)  # type: ignore[attr-defined]\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "def resolve_device() -> torch.device:\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "set_seed(RANDOM_SEED)\n",
    "\n",
    "DEVICE = resolve_device()\n",
    "print(f\"Using device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdd83418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already available at /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/EuroSAT_MS\n",
      "RUN_TIMESTAMP=20251114_153828\n",
      "Plots -> /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/plots\n",
      "Models -> /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/artifacts/models\n",
      "Outputs -> /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/ML2025-Lab/cc_1/outputs\n"
     ]
    }
   ],
   "source": [
    "def _env_path(var_name: str, default: Path) -> Path:\n",
    "    default_path = Path(default)\n",
    "    value = os.environ.get(var_name)\n",
    "    return Path(value).expanduser() if value else default_path\n",
    "\n",
    "REPO_ROOT = Path.cwd()\n",
    "DATA_BASE = _env_path('EUROSAT_DATA_BASE', Path('/Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project'))\n",
    "DATA_ROOT = _env_path('EUROSAT_DATA_ROOT', DATA_BASE / 'EuroSAT_MS')\n",
    "DATA_ZIP = _env_path('EUROSAT_DATA_ZIP', DATA_BASE / 'EuroSAT_MS.zip')\n",
    "MODELS_DIR = _env_path('EUROSAT_MODELS_DIR', REPO_ROOT / 'artifacts' / 'models')\n",
    "PLOT_DIR = _env_path('EUROSAT_PLOTS_DIR', REPO_ROOT / 'artifacts' / 'plots')\n",
    "B10_MODEL_DIR = _env_path('EUROSAT_B10_MODEL_DIR', MODELS_DIR / 'cirrus_cnn')\n",
    "OUTPUT_DIR = _env_path('EUROSAT_OUTPUT_DIR', REPO_ROOT / 'outputs')\n",
    "KAGGLE_TEST_DIR = _env_path('EUROSAT_KAGGLE_TEST_DIR', DATA_BASE / 'kaggle_data' / 'testset' / 'testset')\n",
    "\n",
    "for path in (MODELS_DIR, PLOT_DIR, B10_MODEL_DIR, OUTPUT_DIR):\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not DATA_ROOT.exists():\n",
    "    if DATA_ZIP.exists():\n",
    "        print(f\"Extracting dataset from {DATA_ZIP} ...\")\n",
    "        with zipfile.ZipFile(DATA_ZIP, 'r') as zip_ref:\n",
    "            zip_ref.extractall(DATA_ROOT.parent)\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Dataset directory {DATA_ROOT} not found. Update EUROSAT_DATA_ROOT or place an archive at {DATA_ZIP}.\"\n",
    "        )\n",
    "else:\n",
    "    print(f\"Dataset already available at {DATA_ROOT}\")\n",
    "\n",
    "RUN_TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(f\"RUN_TIMESTAMP={RUN_TIMESTAMP}\")\n",
    "print(f\"Plots -> {PLOT_DIR}\")\n",
    "print(f\"Models -> {MODELS_DIR}\")\n",
    "print(f\"Outputs -> {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99e3e55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SatMAE repo -> /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/SatMAE\n",
      "SatMAE checkpoint -> /Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/pretrain-vit-base-e199.pth\n",
      "SatMAE input 13 bands resized to 96x96\n"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "import types\n",
    "SATMAE_ROOT = _env_path('SATMAE_REPO_ROOT', DATA_BASE / 'SatMAE').resolve()\n",
    "SATMAE_CHECKPOINT = _env_path('SATMAE_CHECKPOINT_PATH', Path('/Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/pretrain-vit-base-e199.pth')).resolve()\n",
    "SATMAE_INPUT_SIZE = int(os.environ.get('SATMAE_INPUT_SIZE', 96))\n",
    "SATMAE_PATCH_SIZE = int(os.environ.get('SATMAE_PATCH_SIZE', 8))\n",
    "SATMAE_IN_CHANNELS = 13\n",
    "SATMAE_BAND_MEAN = [1370.19151926, 1184.3824625, 1120.77120066, 1136.26026392,\n",
    "                    1263.73947144, 1645.40315151, 1846.87040806, 1762.59530783,\n",
    "                    1972.62420416, 582.72633433, 14.77112979, 1732.16362238, 1247.91870117]\n",
    "SATMAE_BAND_STD = [633.15169573, 650.2842772, 712.12507725, 965.23119807,\n",
    "                   948.9819932, 1108.06650639, 1258.36394548, 1233.1492281,\n",
    "                   1364.38688993, 472.37967789, 14.3114637, 1310.36996126, 1087.6020813]\n",
    "\n",
    "if not SATMAE_ROOT.exists():\n",
    "    raise FileNotFoundError(f\"SatMAE repository not found at {SATMAE_ROOT}. Set SATMAE_REPO_ROOT to the cloned repo path.\")\n",
    "\n",
    "if not SATMAE_CHECKPOINT.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"SatMAE checkpoint missing. Download the multispectral ViT-Base weights (pretrain-vit-base-e199.pth) and set \"\n",
    "        \"SATMAE_CHECKPOINT_PATH to its location.\"\n",
    "    )\n",
    "\n",
    "if str(SATMAE_ROOT) not in sys.path:\n",
    "    sys.path.append(str(SATMAE_ROOT))\n",
    "\n",
    "print(f\"SatMAE repo -> {SATMAE_ROOT}\")\n",
    "print(f\"SatMAE checkpoint -> {SATMAE_CHECKPOINT}\")\n",
    "print(f\"SatMAE input {SATMAE_IN_CHANNELS} bands resized to {SATMAE_INPUT_SIZE}x{SATMAE_INPUT_SIZE}\")\n",
    "\n",
    "pos_embed_path = SATMAE_ROOT / 'util' / 'pos_embed.py'\n",
    "if not pos_embed_path.exists():\n",
    "    raise FileNotFoundError(f\"SatMAE pos_embed.py not found at {pos_embed_path}\")\n",
    "pos_embed_spec = importlib.util.spec_from_file_location('satmae_pos_embed', pos_embed_path)\n",
    "pos_embed_module = importlib.util.module_from_spec(pos_embed_spec)\n",
    "pos_embed_spec.loader.exec_module(pos_embed_module)\n",
    "if 'util' not in sys.modules:\n",
    "    util_module = types.ModuleType('util')\n",
    "    sys.modules['util'] = util_module\n",
    "else:\n",
    "    util_module = sys.modules['util']\n",
    "util_module.pos_embed = pos_embed_module\n",
    "sys.modules['util.pos_embed'] = pos_embed_module\n",
    "from util.pos_embed import interpolate_pos_embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0ba9e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatMAEImageProcessor:\n",
    "    def __init__(self, image_size: int = SATMAE_INPUT_SIZE,\n",
    "                 mean = SATMAE_BAND_MEAN,\n",
    "                 std = SATMAE_BAND_STD):\n",
    "        self.image_size = image_size\n",
    "        mean_arr = torch.tensor(mean, dtype=torch.float32).view(-1, 1, 1)\n",
    "        std_arr = torch.tensor(std, dtype=torch.float32).view(-1, 1, 1)\n",
    "        self.min_val = mean_arr - 2 * std_arr\n",
    "        self.max_val = mean_arr + 2 * std_arr\n",
    "\n",
    "    def _to_chw(self, image: np.ndarray) -> np.ndarray:\n",
    "        arr = np.asarray(image, dtype=np.float32)\n",
    "        if arr.ndim != 3:\n",
    "            raise ValueError(f'Expected 3D array, got {arr.shape}')\n",
    "        if arr.shape[0] == SATMAE_IN_CHANNELS:\n",
    "            return arr\n",
    "        if arr.shape[-1] == SATMAE_IN_CHANNELS:\n",
    "            return np.moveaxis(arr, -1, 0)\n",
    "        raise ValueError(f'Expected {SATMAE_IN_CHANNELS} channels, got {arr.shape}')\n",
    "\n",
    "    def __call__(self, images, return_tensors: str | None = 'pt'):\n",
    "        chw = self._to_chw(images)\n",
    "        tensor = torch.from_numpy(chw).float()\n",
    "        tensor = (tensor - self.min_val) / (self.max_val - self.min_val)\n",
    "        tensor = torch.clamp(tensor, 0.0, 1.0)\n",
    "        tensor = F.interpolate(\n",
    "            tensor.unsqueeze(0),\n",
    "            size=(self.image_size, self.image_size),\n",
    "            mode='bilinear',\n",
    "            align_corners=False,\n",
    "        ).squeeze(0)\n",
    "        if return_tensors in (None, 'pt'):\n",
    "            return {'pixel_values': tensor}\n",
    "        raise ValueError(f'Unsupported return_tensors value: {return_tensors!r}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efe40d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 10 classes\n",
      "Total samples: 27000\n"
     ]
    }
   ],
   "source": [
    "CLASS_NAMES = []\n",
    "CIRRUS_TILE_PATHS = []\n",
    "\n",
    "if DATA_ROOT.exists():\n",
    "    class_dirs = sorted([d for d in DATA_ROOT.iterdir() if d.is_dir()])\n",
    "    for d in class_dirs:\n",
    "        label = len(CLASS_NAMES)\n",
    "        CLASS_NAMES.append(d.name)\n",
    "        for tif_path in sorted(d.glob('*.tif')):\n",
    "            CIRRUS_TILE_PATHS.append(tif_path)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"{DATA_ROOT} not found. Extract the archive first.\")\n",
    "\n",
    "CLASS_TO_IDX = {name: idx for idx, name in enumerate(CLASS_NAMES)}\n",
    "IDX_TO_CLASS = {idx: name for name, idx in CLASS_TO_IDX.items()}\n",
    "\n",
    "print(f\"Detected {len(CLASS_NAMES)} classes\")\n",
    "print(f\"Total samples: {len(CIRRUS_TILE_PATHS)}\")\n",
    "\n",
    "TRAIN_BAND_ORDER = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B9', 'B10', 'B11', 'B12', 'B8A']\n",
    "TEST_BAND_ORDER = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12']\n",
    "DROP_BAND_NAME = 'B10'\n",
    "DROP_BAND_INDEX = TRAIN_BAND_ORDER.index(DROP_BAND_NAME)\n",
    "KEEP_IDX_13 = np.array([i for i, band in enumerate(TRAIN_BAND_ORDER) if band != DROP_BAND_NAME])\n",
    "CANONICAL_12_BAND_ORDER = [band for band in TRAIN_BAND_ORDER if band != DROP_BAND_NAME]\n",
    "KEEP_IDX_12 = np.arange(len(CANONICAL_12_BAND_ORDER))\n",
    "TEST_TO_CANONICAL_12 = np.array([CANONICAL_12_BAND_ORDER.index(band) for band in TEST_BAND_ORDER], dtype=np.int64)\n",
    "CIRRUS_SCALE = 10000.0\n",
    "CIRRUS_MODEL = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "band_order_utils",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_test_to_canonical(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Reorders 12-band Sentinel-2 L2A (test layout) tiles to the canonical training layout without B10.\"\"\"\n",
    "    if arr.shape[0] != len(TEST_BAND_ORDER):\n",
    "        raise ValueError(f\"Expected array with {len(TEST_BAND_ORDER)} bands, got {arr.shape[0]}\")\n",
    "    out = np.empty_like(arr)\n",
    "    for src_idx, dst_idx in enumerate(TEST_TO_CANONICAL_12):\n",
    "        out[dst_idx] = arr[src_idx]\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48c71ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CirrusCNN(nn.Module):\n",
    "    def __init__(self, in_channels: int = 12, hidden_dim: int = 64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_dim, 1, kernel_size=1, bias=True)\n",
    "        )\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "def sample_patches(arr: np.ndarray, num_patches: int, patch_size: int, rng: np.random.Generator):\n",
    "    c, h, w = arr.shape\n",
    "    ps = min(patch_size, h, w)\n",
    "    patches_x = []\n",
    "    patches_y = []\n",
    "    for _ in range(num_patches):\n",
    "        top = int(rng.integers(0, max(1, h - ps + 1)))\n",
    "        left = int(rng.integers(0, max(1, w - ps + 1)))\n",
    "        patch = arr[:, top:top + ps, left:left + ps]\n",
    "        patches_x.append(patch[KEEP_IDX_13])\n",
    "        patches_y.append(patch[DROP_BAND_INDEX:DROP_BAND_INDEX + 1])\n",
    "    return patches_x, patches_y\n",
    "\n",
    "\n",
    "def _iter_patch_batches(tile_paths, patches_per_tile, patch_size, batch_size, rng: np.random.Generator, desc: str | None = None):\n",
    "    if not tile_paths:\n",
    "        return\n",
    "\n",
    "    order = np.arange(len(tile_paths))\n",
    "    rng.shuffle(order)\n",
    "    iterator = order\n",
    "    if desc is not None:\n",
    "        iterator = tqdm(order, desc=desc, leave=False)\n",
    "    batch_x, batch_y = [], []\n",
    "    for idx in iterator:\n",
    "        path = tile_paths[idx]\n",
    "        with rasterio.open(path) as src:\n",
    "            arr = src.read().astype(np.float32)\n",
    "        if arr.shape[0] != 13:\n",
    "            continue\n",
    "        arr = np.clip(arr, 0.0, CIRRUS_SCALE) / CIRRUS_SCALE\n",
    "        px, py = sample_patches(arr, patches_per_tile, patch_size, rng)\n",
    "        for x_patch, y_patch in zip(px, py):\n",
    "            batch_x.append(x_patch)\n",
    "            batch_y.append(y_patch)\n",
    "            if len(batch_x) == batch_size:\n",
    "                yield torch.from_numpy(np.stack(batch_x)).float(), torch.from_numpy(np.stack(batch_y)).float()\n",
    "                batch_x, batch_y = [], []\n",
    "    if batch_x:\n",
    "        yield torch.from_numpy(np.stack(batch_x)).float(), torch.from_numpy(np.stack(batch_y)).float()\n",
    "\n",
    "\n",
    "def fit_cirrus_cnn(sample_paths,\n",
    "                    patches_per_tile: int = 64,\n",
    "                    patch_size: int = 64,\n",
    "                    epochs: int = 5,\n",
    "                    batch_size: int = 128,\n",
    "                    lr: float = 5e-4,\n",
    "                    val_fraction: float = 0.1,\n",
    "                    max_tiles: int | None = None,\n",
    "                    early_stopping_patience: int = 3) -> dict:\n",
    "    if not sample_paths:\n",
    "        raise ValueError(\"No samples provided for cirrus CNN fitting\")\n",
    "\n",
    "    base_rng = np.random.default_rng(RANDOM_SEED)\n",
    "    paths = list(sample_paths)\n",
    "    if max_tiles is not None and len(paths) > max_tiles:\n",
    "        idx = base_rng.choice(len(paths), size=max_tiles, replace=False)\n",
    "        paths = [paths[i] for i in idx]\n",
    "    base_rng.shuffle(paths)\n",
    "\n",
    "    val_count = max(1, int(len(paths) * val_fraction))\n",
    "    val_paths = paths[:val_count]\n",
    "    train_paths = paths[val_count:]\n",
    "    if not train_paths:\n",
    "        raise ValueError(\"Not enough tiles for training after validation split\")\n",
    "\n",
    "    print(f\"[CirrusCNN] Training on {len(train_paths)} tiles (+{len(val_paths)} val) with {patches_per_tile} patches per tile per epoch.\")\n",
    "\n",
    "    model = CirrusCNN().to(DEVICE)\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "    best_state = None\n",
    "    best_val = float('inf')\n",
    "    best_epoch = 0\n",
    "\n",
    "    history = []\n",
    "\n",
    "    patience = max(1, early_stopping_patience)\n",
    "    no_improve_epochs = 0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_rng = np.random.default_rng(base_rng.integers(0, 1 << 32))\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_samples = 0\n",
    "        for xb, yb in _iter_patch_batches(train_paths, patches_per_tile, patch_size, batch_size, epoch_rng, desc=f'Train patches (epoch {epoch})'):\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * xb.size(0)\n",
    "            train_samples += xb.size(0)\n",
    "        train_loss = train_loss / max(1, train_samples)\n",
    "\n",
    "        val_rng = np.random.default_rng(epoch_rng.integers(0, 1 << 32))\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in _iter_patch_batches(val_paths, patches_per_tile, patch_size, batch_size, val_rng, desc=f'Val patches (epoch {epoch})'):\n",
    "                xb = xb.to(DEVICE)\n",
    "                yb = yb.to(DEVICE)\n",
    "                preds = model(xb)\n",
    "                val_loss += criterion(preds, yb).item() * xb.size(0)\n",
    "                val_samples += xb.size(0)\n",
    "        val_loss = val_loss / max(1, val_samples)\n",
    "        print(f\"[CirrusCNN] epoch {epoch}/{epochs} train={train_loss:.6f} val={val_loss:.6f}\")\n",
    "\n",
    "        history.append({'epoch': epoch, 'train_loss': train_loss, 'val_loss': val_loss, 'train_samples': train_samples, 'val_samples': val_samples})\n",
    "\n",
    "        if val_loss < best_val and val_samples > 0:\n",
    "            best_val = val_loss\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            best_epoch = epoch\n",
    "            no_improve_epochs = 0\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "            if no_improve_epochs >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch}; best val {best_val:.6f} at epoch {best_epoch}\")\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    eval_rng = np.random.default_rng(RANDOM_SEED + 1234)\n",
    "    mae_sum = 0.0\n",
    "    mse_sum = 0.0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in _iter_patch_batches(paths, patches_per_tile, patch_size, 256, eval_rng, desc='Evaluating cirrus CNN'):\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "            preds = model(xb)\n",
    "            mae_sum += torch.nn.functional.l1_loss(preds, yb, reduction='sum').item()\n",
    "            mse_sum += torch.nn.functional.mse_loss(preds, yb, reduction='sum').item()\n",
    "            count += xb.size(0)\n",
    "    mae = mae_sum / max(1, count)\n",
    "    rmse = math.sqrt(mse_sum / max(1, count))\n",
    "\n",
    "    print(f\"[CirrusCNN] Aggregated over ~{count} patches | MAE={mae:.6f} | RMSE={rmse:.6f}\")\n",
    "\n",
    "    if history:\n",
    "        hist_df = pd.DataFrame(history)\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        ax.plot(hist_df['epoch'], hist_df['train_loss'], label='Train')\n",
    "        ax.plot(hist_df['epoch'], hist_df['val_loss'], label='Val')\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('SmoothL1 Loss')\n",
    "        ax.set_title('CirrusCNN Training History')\n",
    "        ax.legend()\n",
    "        ax.grid(True, linestyle='--', alpha=0.3)\n",
    "        fig.tight_layout()\n",
    "        plot_path = PLOT_DIR / f'cirrus_cnn_history_{RUN_TIMESTAMP}.png'\n",
    "        fig.savefig(plot_path, dpi=180, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "        print(f\"Saved CirrusCNN training plot to {plot_path}\")\n",
    "\n",
    "    return {\n",
    "        'module': model,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'scale': CIRRUS_SCALE,\n",
    "    }\n",
    "\n",
    "\n",
    "def synthesize_cirrus(arr: np.ndarray, band_order: str | None = None) -> np.ndarray:\n",
    "    arr = np.asarray(arr, dtype=np.float32)\n",
    "    if CIRRUS_MODEL is None:\n",
    "        raise RuntimeError('CIRRUS_MODEL is None. Train or load the B10 reconstruction model before calling synthesize_cirrus.')\n",
    "\n",
    "    if band_order is None:\n",
    "        if arr.shape[0] == len(TRAIN_BAND_ORDER):\n",
    "            band_order = 'train'\n",
    "        elif arr.shape[0] == len(TEST_BAND_ORDER):\n",
    "            band_order = 'test'\n",
    "        elif arr.shape[0] == len(CANONICAL_12_BAND_ORDER):\n",
    "            band_order = 'canonical_12'\n",
    "        else:\n",
    "            raise ValueError(f\"Expected 12 or 13 bands, got {arr.shape}\")\n",
    "\n",
    "    scale = CIRRUS_MODEL['scale']\n",
    "    if band_order == 'train':\n",
    "        arr_scaled = np.clip(arr, 0.0, scale) / scale\n",
    "        feats = arr_scaled[KEEP_IDX_13]\n",
    "    elif band_order == 'test':\n",
    "        reordered = reorder_test_to_canonical(arr)\n",
    "        arr_scaled = np.clip(reordered, 0.0, scale) / scale\n",
    "        feats = arr_scaled\n",
    "    elif band_order == 'canonical_12':\n",
    "        if arr.shape[0] != len(CANONICAL_12_BAND_ORDER):\n",
    "            raise ValueError(f\"Expected canonical 12-band array with shape (12, H, W), got {arr.shape}\")\n",
    "        arr_scaled = np.clip(arr, 0.0, scale) / scale\n",
    "        feats = arr_scaled\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported band_order: {band_order}\")\n",
    "\n",
    "    tensor = torch.from_numpy(feats).unsqueeze(0).to(DEVICE)\n",
    "    module = CIRRUS_MODEL['module'].to(DEVICE)\n",
    "    CIRRUS_MODEL['module'] = module\n",
    "    module.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = module(tensor).squeeze(0).squeeze(0).detach().cpu().numpy()\n",
    "    pred = np.clip(pred, 0.0, 1.0) * scale\n",
    "    return pred.astype(np.float32)\n",
    "\n",
    "\n",
    "def pad_to_13_bands(arr: np.ndarray, band_order: str | None = None) -> np.ndarray:\n",
    "    arr = np.asarray(arr, dtype=np.float32)\n",
    "    if band_order is None:\n",
    "        if arr.shape[0] == len(TRAIN_BAND_ORDER):\n",
    "            band_order = 'train'\n",
    "        elif arr.shape[0] == len(TEST_BAND_ORDER):\n",
    "            band_order = 'test'\n",
    "        elif arr.shape[0] == len(CANONICAL_12_BAND_ORDER):\n",
    "            band_order = 'canonical_12'\n",
    "        else:\n",
    "            raise ValueError(f\"Expected 12 or 13 bands, got {arr.shape}\")\n",
    "\n",
    "    if band_order == 'train':\n",
    "        out = arr.copy()\n",
    "        out[DROP_BAND_INDEX] = synthesize_cirrus(arr, band_order='train')\n",
    "        return out\n",
    "\n",
    "    if band_order == 'test':\n",
    "        canonical = reorder_test_to_canonical(arr)\n",
    "    elif band_order == 'canonical_12':\n",
    "        if arr.shape[0] != len(CANONICAL_12_BAND_ORDER):\n",
    "            raise ValueError(f\"Expected canonical 12-band array with shape (12, H, W), got {arr.shape}\")\n",
    "        canonical = arr\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported band_order: {band_order}\")\n",
    "\n",
    "    cirrus = synthesize_cirrus(canonical, band_order='canonical_12')\n",
    "    return np.concatenate(\n",
    "        [canonical[:DROP_BAND_INDEX], cirrus[np.newaxis, ...], canonical[DROP_BAND_INDEX:]],\n",
    "        axis=0\n",
    "    )\n",
    "\n",
    "\n",
    "def robust_normalize(arr: np.ndarray) -> np.ndarray:\n",
    "    arr = arr.astype(np.float32, copy=False)\n",
    "    out = np.empty_like(arr)\n",
    "    for i in range(arr.shape[0]):\n",
    "        band = arr[i]\n",
    "        lo, hi = np.percentile(band, [2, 98])\n",
    "        if hi > lo:\n",
    "            band = (band - lo) / (hi - lo)\n",
    "        else:\n",
    "            min_v, max_v = band.min(), band.max()\n",
    "            if max_v > min_v:\n",
    "                band = (band - min_v) / (max_v - min_v)\n",
    "            else:\n",
    "                band = np.zeros_like(band)\n",
    "        out[i] = np.clip(band, 0.0, 1.0)\n",
    "    return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0617de28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CirrusCNN] Training on 24300 tiles (+2700 val) with 64 patches per tile per epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CirrusCNN] epoch 1/2 train=0.000277 val=0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train patches (epoch 2):  78%|███████▊  | 18856/24300 [09:31<02:46, 32.78it/s]"
     ]
    }
   ],
   "source": [
    "cirrus_paths = CIRRUS_TILE_PATHS\n",
    "CIRRUS_MODEL = fit_cirrus_cnn(cirrus_paths, epochs=2, patches_per_tile=64, patch_size=64)\n",
    "CIRRUS_MODEL['module'] = CIRRUS_MODEL['module'].to(DEVICE)\n",
    "CIRRUS_MODEL['module'].eval()\n",
    "\n",
    "cirrus_state_dict = {k: v.detach().cpu() for k, v in CIRRUS_MODEL['module'].state_dict().items()}\n",
    "\n",
    "b10_bundle = {\n",
    "    'state_dict': cirrus_state_dict,\n",
    "    'mae': CIRRUS_MODEL['mae'],\n",
    "    'rmse': CIRRUS_MODEL['rmse'],\n",
    "    'scale': CIRRUS_MODEL['scale'],\n",
    "    'drop_band_index': DROP_BAND_INDEX,\n",
    "    'keep_idx_12': KEEP_IDX_12,\n",
    "    'keep_idx_13': KEEP_IDX_13,\n",
    "    'train_band_order': TRAIN_BAND_ORDER,\n",
    "    'test_band_order': TEST_BAND_ORDER,\n",
    "    'canonical_12_band_order': CANONICAL_12_BAND_ORDER,\n",
    "}\n",
    "\n",
    "b10_model_path = B10_MODEL_DIR / f'cirrus_cnn_{RUN_TIMESTAMP}.pt'\n",
    "torch.save(b10_bundle, b10_model_path)\n",
    "print(f\"Saved B10 reconstruction weights to {b10_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6cc538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_vit import VisionTransformer\n",
    "from pos_embed import interpolate_pos_embed\n",
    "\n",
    "MODEL_ID = 'satmae_s2_base_local'\n",
    "\n",
    "\n",
    "def build_satmae_classifier(num_classes: int) -> VisionTransformer:\n",
    "    model = VisionTransformer(\n",
    "        img_size=SATMAE_INPUT_SIZE,\n",
    "        patch_size=SATMAE_PATCH_SIZE,\n",
    "        in_chans=SATMAE_IN_CHANNELS,\n",
    "        num_classes=num_classes,\n",
    "        embed_dim=768,\n",
    "        depth=12,\n",
    "        num_heads=12,\n",
    "        mlp_ratio=4,\n",
    "        qkv_bias=True,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6),\n",
    "        global_pool=False,\n",
    "    )\n",
    "\n",
    "    checkpoint = torch.load(SATMAE_CHECKPOINT, map_location='cpu')\n",
    "    checkpoint_model = checkpoint.get('model', checkpoint)\n",
    "    model_state = model.state_dict()\n",
    "\n",
    "    removed = []\n",
    "    for key in list(checkpoint_model.keys()):\n",
    "        if key in model_state and checkpoint_model[key].shape != model_state[key].shape:\n",
    "            removed.append(key)\n",
    "            del checkpoint_model[key]\n",
    "    if removed:\n",
    "        print(f\"Removed incompatible keys from checkpoint: {removed}\")\n",
    "\n",
    "    interpolate_pos_embed(model, checkpoint_model)\n",
    "    msg = model.load_state_dict(checkpoint_model, strict=False)\n",
    "    print(f\"Loaded SatMAE checkpoint from {SATMAE_CHECKPOINT}\")\n",
    "    print(f\"Missing keys: {msg.missing_keys}\")\n",
    "    print(f\"Unexpected keys: {msg.unexpected_keys}\")\n",
    "\n",
    "    trunc_normal_(model.head.weight, std=2e-5)\n",
    "    nn.init.zeros_(model.head.bias)\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        param.requires_grad = name.startswith('head')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_satmae_classifier(len(CLASS_NAMES))\n",
    "processor = SatMAEImageProcessor(image_size=SATMAE_INPUT_SIZE,\n",
    "                                 mean=SATMAE_BAND_MEAN,\n",
    "                                 std=SATMAE_BAND_STD)\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "print('SatMAE backbone frozen; classifier head ready for fine-tuning.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e170d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_logits(model, pixel_values):\n",
    "    outputs = model(pixel_values)\n",
    "    if isinstance(outputs, torch.Tensor):\n",
    "        return outputs\n",
    "    if isinstance(outputs, dict):\n",
    "        if 'logits' in outputs:\n",
    "            return outputs['logits']\n",
    "        raise KeyError(\"Model output dict missing 'logits'\")\n",
    "    if hasattr(outputs, 'logits'):\n",
    "        return outputs.logits\n",
    "    raise RuntimeError('Model output does not contain logits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89200af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the classifier using CirrusCNN-synthesized B10 inputs so it sees the same distribution as at inference time\n",
    "\n",
    "\n",
    "def _build_finetune_records(val_fraction: float = 0.1, test_fraction: float = 0.0, limit_per_class: int | None = None, seed: int = RANDOM_SEED):\n",
    "    if not (0.0 < val_fraction < 1.0):\n",
    "        raise ValueError('val_fraction must be between 0 and 1 for fine-tuning splits')\n",
    "    if not (0.0 <= test_fraction < 1.0):\n",
    "        raise ValueError('test_fraction must be between 0 and 1 for fine-tuning splits')\n",
    "    if val_fraction + test_fraction >= 1.0:\n",
    "        raise ValueError('val_fraction + test_fraction must sum to less than 1.0 for fine-tuning splits')\n",
    "    rng = np.random.default_rng(seed)\n",
    "    train_records: list[tuple[Path, int]] = []\n",
    "    val_records: list[tuple[Path, int]] = []\n",
    "    test_records: list[tuple[Path, int]] = []\n",
    "    for class_name in CLASS_NAMES:\n",
    "        class_idx = CLASS_TO_IDX[class_name]\n",
    "        class_dir = DATA_ROOT / class_name\n",
    "        tif_paths = sorted(class_dir.glob('*.tif'))\n",
    "        if not tif_paths:\n",
    "            continue\n",
    "        if limit_per_class is not None and len(tif_paths) > limit_per_class:\n",
    "            selection = rng.choice(len(tif_paths), size=limit_per_class, replace=False)\n",
    "            tif_paths = [tif_paths[i] for i in selection]\n",
    "        order = rng.permutation(len(tif_paths))\n",
    "        tif_paths = [tif_paths[i] for i in order]\n",
    "        if len(tif_paths) < 2:\n",
    "            train_records.extend((path, class_idx) for path in tif_paths)\n",
    "            continue\n",
    "        total = len(tif_paths)\n",
    "        val_count = 0\n",
    "        test_count = 0\n",
    "        if val_fraction > 0.0:\n",
    "            val_count = max(1, int(total * val_fraction))\n",
    "            val_count = min(total - 1, val_count)\n",
    "        remaining = total - val_count\n",
    "        if test_fraction > 0.0 and remaining > 1:\n",
    "            test_count = max(1, int(total * test_fraction))\n",
    "            test_count = min(test_count, remaining - 1)\n",
    "        val_slice = tif_paths[:val_count]\n",
    "        test_slice = tif_paths[val_count:val_count + test_count]\n",
    "        train_slice = tif_paths[val_count + test_count:]\n",
    "        if not train_slice:\n",
    "            raise RuntimeError('Unable to keep at least one training tile per class; adjust val/test fractions or increase data availability.')\n",
    "        val_records.extend((path, class_idx) for path in val_slice)\n",
    "        test_records.extend((path, class_idx) for path in test_slice)\n",
    "        train_records.extend((path, class_idx) for path in train_slice)\n",
    "    if not train_records or not val_records:\n",
    "        raise RuntimeError('Unable to build stratified fine-tuning splits; consider lowering val_fraction or increasing data availability.')\n",
    "    if test_fraction > 0.0 and not test_records:\n",
    "        raise RuntimeError('Unable to build stratified fine-tuning test split; consider lowering test_fraction or increasing data availability.')\n",
    "    return train_records, val_records, test_records\n",
    "\n",
    "\n",
    "class EuroSATCirrusFinetuneDataset(Dataset):\n",
    "    def __init__(self, records, processor, inject_cirrus_b10: bool = True):\n",
    "        if processor is None:\n",
    "            raise RuntimeError('processor must be initialized before building the fine-tuning dataset')\n",
    "        if inject_cirrus_b10 and CIRRUS_MODEL is None:\n",
    "            raise RuntimeError('CIRRUS_MODEL is None; train or load the B10 reconstruction model before fine-tuning the classifier')\n",
    "        self.records = records\n",
    "        self.processor = processor\n",
    "        self.inject_cirrus_b10 = inject_cirrus_b10\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        path, label = self.records[idx]\n",
    "        with rasterio.open(path) as src:\n",
    "            arr = src.read().astype(np.float32)\n",
    "        if self.inject_cirrus_b10:\n",
    "            arr = pad_to_13_bands(arr, band_order='train')\n",
    "        inputs = self.processor(images=arr, return_tensors='pt')\n",
    "        pixel_values = inputs['pixel_values'].squeeze(0)\n",
    "        return {\n",
    "            'pixel_values': pixel_values,\n",
    "            'labels': torch.tensor(label, dtype=torch.long),\n",
    "            'path': str(path),\n",
    "        }\n",
    "\n",
    "\n",
    "def _save_plot(fig, filename: str):\n",
    "    path = PLOT_DIR / filename\n",
    "    fig.savefig(path, dpi=180, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved plot to {path}\")\n",
    "\n",
    "\n",
    "def _plot_training_curves(history: list[dict], tag: str):\n",
    "    if not history:\n",
    "        return\n",
    "    epochs = [entry['epoch'] for entry in history]\n",
    "    train_loss = [entry['train_loss'] for entry in history]\n",
    "    val_loss = [entry['val_loss'] for entry in history]\n",
    "    train_acc = [entry['train_acc'] for entry in history]\n",
    "    val_acc = [entry['val_acc'] for entry in history]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    axes[0].plot(epochs, train_acc, label='Train')\n",
    "    axes[0].plot(epochs, val_acc, label='Val')\n",
    "    axes[0].set_title('Accuracy over epochs')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].grid(True, linestyle='--', alpha=0.3)\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].plot(epochs, train_loss, label='Train')\n",
    "    axes[1].plot(epochs, val_loss, label='Val')\n",
    "    axes[1].set_title('Loss over epochs')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].grid(True, linestyle='--', alpha=0.3)\n",
    "    axes[1].legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    _save_plot(fig, f'{tag}_accuracy_loss.png')\n",
    "\n",
    "\n",
    "def _plot_confusion_matrix(cm: np.ndarray, tag: str):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(len(CLASS_NAMES)),\n",
    "           yticks=np.arange(len(CLASS_NAMES)),\n",
    "           xticklabels=CLASS_NAMES,\n",
    "           yticklabels=CLASS_NAMES,\n",
    "           xlabel='Predicted label',\n",
    "           ylabel='True label',\n",
    "           title='Confusion matrix (test set)')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')\n",
    "\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], 'd'), ha='center', va='center', color='white' if cm[i, j] > cm.max() / 2 else 'black')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    _save_plot(fig, f'{tag}_confusion_matrix.png')\n",
    "\n",
    "\n",
    "def _plot_per_class_metrics(precision: np.ndarray, recall: np.ndarray, f1: np.ndarray, tag: str):\n",
    "    indices = np.arange(len(CLASS_NAMES))\n",
    "    width = 0.25\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    ax.bar(indices - width, precision, width, label='Precision')\n",
    "    ax.bar(indices, recall, width, label='Recall')\n",
    "    ax.bar(indices + width, f1, width, label='F1')\n",
    "    ax.set_xticks(indices)\n",
    "    ax.set_xticklabels(CLASS_NAMES, rotation=45, ha='right')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title('Per-class metrics (test set)')\n",
    "    ax.grid(True, axis='y', linestyle='--', alpha=0.3)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    _save_plot(fig, f'{tag}_per_class_metrics.png')\n",
    "\n",
    "\n",
    "def _plot_roc_curves(y_true: np.ndarray, probs: np.ndarray, tag: str):\n",
    "    classes = np.arange(len(CLASS_NAMES))\n",
    "    y_bin = label_binarize(y_true, classes=classes)\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    auc_scores: dict[str, float] = {}\n",
    "    for idx, class_name in enumerate(CLASS_NAMES):\n",
    "        fpr, tpr, _ = roc_curve(y_bin[:, idx], probs[:, idx])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        auc_scores[class_name] = roc_auc\n",
    "        ax.plot(fpr, tpr, label=f'{class_name} (AUC={roc_auc:.3f})')\n",
    "    micro_fpr, micro_tpr, _ = roc_curve(y_bin.ravel(), probs.ravel())\n",
    "    micro_auc = auc(micro_fpr, micro_tpr)\n",
    "    auc_scores['micro'] = micro_auc\n",
    "    ax.plot(micro_fpr, micro_tpr, color='black', linewidth=2, label=f'Micro (AUC={micro_auc:.3f})')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('ROC curves (one-vs-rest)')\n",
    "    ax.legend(fontsize='small', ncol=2)\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    fig.tight_layout()\n",
    "    _save_plot(fig, f'{tag}_roc_curves.png')\n",
    "    return auc_scores\n",
    "\n",
    "\n",
    "def _plot_roc_auc_bars(auc_scores: dict[str, float], tag: str):\n",
    "    labels = list(auc_scores.keys())\n",
    "    scores = [auc_scores[label] for label in labels]\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    ax.bar(labels, scores, color='teal')\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_ylabel('AUC')\n",
    "    ax.set_title('ROC-AUC by class')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    ax.grid(True, axis='y', linestyle='--', alpha=0.3)\n",
    "    fig.tight_layout()\n",
    "    _save_plot(fig, f'{tag}_roc_auc_bars.png')\n",
    "\n",
    "\n",
    "def _plot_precision_recall_curves(y_true: np.ndarray, probs: np.ndarray, tag: str):\n",
    "    classes = np.arange(len(CLASS_NAMES))\n",
    "    y_bin = label_binarize(y_true, classes=classes)\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    for idx, class_name in enumerate(CLASS_NAMES):\n",
    "        precision, recall, _ = precision_recall_curve(y_bin[:, idx], probs[:, idx])\n",
    "        pr_auc = auc(recall, precision)\n",
    "        ax.plot(recall, precision, label=f'{class_name} (AUC={pr_auc:.3f})')\n",
    "    precision_micro, recall_micro, _ = precision_recall_curve(y_bin.ravel(), probs.ravel())\n",
    "    pr_auc_micro = auc(recall_micro, precision_micro)\n",
    "    ax.plot(recall_micro, precision_micro, color='black', linewidth=2, label=f'Micro (AUC={pr_auc_micro:.3f})')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_title('Precision-Recall curves (one-vs-rest)')\n",
    "    ax.legend(fontsize='small', ncol=2)\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    fig.tight_layout()\n",
    "    _save_plot(fig, f'{tag}_precision_recall_curves.png')\n",
    "\n",
    "\n",
    "def _plot_score_distribution(y_true: np.ndarray, y_pred: np.ndarray, probs: np.ndarray, tag: str):\n",
    "    max_probs = probs.max(axis=1)\n",
    "    correct = y_pred == y_true\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.hist(max_probs[correct], bins=30, alpha=0.7, label='Correct', color='green', density=True)\n",
    "    ax.hist(max_probs[~correct], bins=30, alpha=0.7, label='Incorrect', color='red', density=True)\n",
    "    ax.set_xlabel('Predicted probability (max class)')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Prediction confidence distribution')\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    fig.tight_layout()\n",
    "    _save_plot(fig, f'{tag}_score_distribution.png')\n",
    "\n",
    "\n",
    "def finetune_classifier_with_cirrus(model, processor, cfg: dict):\n",
    "    train_records, val_records, test_records = _build_finetune_records(\n",
    "        val_fraction=cfg.get('val_fraction', 0.1),\n",
    "        test_fraction=cfg.get('test_fraction', 0.0),\n",
    "        limit_per_class=cfg.get('limit_per_class'),\n",
    "        seed=cfg.get('seed', RANDOM_SEED),\n",
    "    )\n",
    "    train_dataset = EuroSATCirrusFinetuneDataset(train_records, processor, inject_cirrus_b10=True)\n",
    "    val_dataset = EuroSATCirrusFinetuneDataset(val_records, processor, inject_cirrus_b10=True)\n",
    "    test_dataset = EuroSATCirrusFinetuneDataset(test_records, processor, inject_cirrus_b10=True) if test_records else None\n",
    "\n",
    "    num_workers = cfg.get('num_workers')\n",
    "    if num_workers is None:\n",
    "        num_workers = 0 if platform.system() == 'Darwin' else 4\n",
    "    pin_memory = DEVICE.type == 'cuda'\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=cfg.get('train_batch_size', 32),\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=cfg.get('val_batch_size', 64),\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "    )\n",
    "    test_loader = None\n",
    "    if test_dataset is not None:\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=cfg.get('test_batch_size', cfg.get('val_batch_size', 64)),\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=pin_memory,\n",
    "        )\n",
    "\n",
    "    print(f\"[FineTune] Split sizes -> train: {len(train_records)} | val: {len(val_records)} | test: {len(test_records)}\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=cfg.get('label_smoothing', 0.0))\n",
    "    trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        trainable_params,\n",
    "        lr=cfg.get('lr', 5e-5),\n",
    "        weight_decay=cfg.get('weight_decay', 1e-2),\n",
    "    )\n",
    "    max_grad_norm = cfg.get('max_grad_norm', 1.0)\n",
    "    epochs = cfg.get('epochs', 3)\n",
    "    transfer_non_blocking = DEVICE.type == 'cuda'\n",
    "    mixup_alpha = float(cfg.get('mixup_alpha', 0.0) or 0.0)\n",
    "    mixup_prob = float(cfg.get('mixup_prob', 0.0) or 0.0)\n",
    "    mixup_enabled = mixup_alpha > 0 and mixup_prob > 0\n",
    "    mixup_rng = np.random.default_rng(cfg.get('seed', RANDOM_SEED) + 1337)\n",
    "\n",
    "    best_state = None\n",
    "    best_val_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    history = []\n",
    "\n",
    "    patience = max(1, cfg.get('early_stopping_patience', 3))\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_samples = 0\n",
    "        for batch in tqdm(train_loader, desc=f'Fine-tune train {epoch}/{epochs}', leave=False):\n",
    "            pixel_values = batch['pixel_values'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "            labels = batch['labels'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "            labels_for_metrics = labels.detach()\n",
    "            apply_mixup = False\n",
    "            mix_labels = None\n",
    "            lam = 1.0\n",
    "            if mixup_enabled and pixel_values.size(0) > 1 and mixup_rng.random() < mixup_prob:\n",
    "                lam = float(mixup_rng.beta(mixup_alpha, mixup_alpha))\n",
    "                perm = torch.from_numpy(mixup_rng.permutation(pixel_values.size(0))).to(pixel_values.device)\n",
    "                mix_labels = labels[perm]\n",
    "                pixel_values = lam * pixel_values + (1.0 - lam) * pixel_values[perm]\n",
    "                apply_mixup = True\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            logits = get_model_logits(model, pixel_values)\n",
    "            if apply_mixup and mix_labels is not None:\n",
    "                loss = lam * criterion(logits, labels) + (1.0 - lam) * criterion(logits, mix_labels)\n",
    "            else:\n",
    "                loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            if max_grad_norm is not None and max_grad_norm > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * labels.size(0)\n",
    "            train_correct += (logits.argmax(dim=1) == labels_for_metrics).sum().item()\n",
    "            train_samples += labels.size(0)\n",
    "        train_loss = train_loss / max(1, train_samples)\n",
    "        train_acc = train_correct / max(1, train_samples)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=f'Fine-tune val {epoch}/{epochs}', leave=False):\n",
    "                pixel_values = batch['pixel_values'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "                labels = batch['labels'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "                logits = get_model_logits(model, pixel_values)\n",
    "                loss = criterion(logits, labels)\n",
    "                val_loss += loss.item() * labels.size(0)\n",
    "                val_correct += (logits.argmax(dim=1) == labels).sum().item()\n",
    "                val_samples += labels.size(0)\n",
    "        val_loss = val_loss / max(1, val_samples)\n",
    "        val_acc = val_correct / max(1, val_samples)\n",
    "\n",
    "        history.append({\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'train_samples': train_samples,\n",
    "            'val_samples': val_samples,\n",
    "        })\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            no_improve_epochs = 0\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "            if no_improve_epochs >= patience:\n",
    "                print(f\"[FineTune] Early stopping triggered at epoch {epoch} (patience={patience}).\")\n",
    "                break\n",
    "\n",
    "        print(f\"[FineTune] epoch {epoch}/{epochs} | train_loss={train_loss:.4f} train_acc={train_acc:.4f} | val_loss={val_loss:.4f} val_acc={val_acc:.4f}\")\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "        print(f\"Loaded best fine-tuned weights from epoch {best_epoch} (val_acc={best_val_acc:.4f})\")\n",
    "\n",
    "    test_results = None\n",
    "    test_plot_payload = None\n",
    "    if test_loader is not None:\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct = 0\n",
    "        test_samples = 0\n",
    "        collected_probs = []\n",
    "        collected_labels = []\n",
    "        collected_preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc='Fine-tune test', leave=False):\n",
    "                pixel_values = batch['pixel_values'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "                labels = batch['labels'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "                logits = get_model_logits(model, pixel_values)\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                loss = criterion(logits, labels)\n",
    "                test_loss += loss.item() * labels.size(0)\n",
    "                predictions = probs.argmax(dim=1)\n",
    "                test_correct += (predictions == labels).sum().item()\n",
    "                test_samples += labels.size(0)\n",
    "                collected_probs.append(probs.detach().cpu())\n",
    "                collected_labels.append(labels.detach().cpu())\n",
    "                collected_preds.append(predictions.detach().cpu())\n",
    "        test_loss = test_loss / max(1, test_samples)\n",
    "        test_acc = test_correct / max(1, test_samples)\n",
    "        if collected_probs:\n",
    "            probs_np = torch.cat(collected_probs).numpy()\n",
    "            labels_np = torch.cat(collected_labels).numpy()\n",
    "            preds_np = torch.cat(collected_preds).numpy()\n",
    "            test_plot_payload = {\n",
    "                'labels': labels_np,\n",
    "                'preds': preds_np,\n",
    "                'probs': probs_np,\n",
    "            }\n",
    "        test_results = {\n",
    "            'test_loss': test_loss,\n",
    "            'test_acc': test_acc,\n",
    "            'test_samples': test_samples,\n",
    "        }\n",
    "        print(f\"[FineTune/Test] loss={test_loss:.4f} acc={test_acc:.4f} | samples={test_samples}\")\n",
    "\n",
    "    plot_tag = f'finetune_{RUN_TIMESTAMP}'\n",
    "    _plot_training_curves(history, plot_tag)\n",
    "    if test_plot_payload is not None:\n",
    "        labels = test_plot_payload['labels']\n",
    "        preds = test_plot_payload['preds']\n",
    "        probs = test_plot_payload['probs']\n",
    "        cm = confusion_matrix(labels, preds, labels=list(range(len(CLASS_NAMES))))\n",
    "        _plot_confusion_matrix(cm, plot_tag)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            labels,\n",
    "            preds,\n",
    "            labels=list(range(len(CLASS_NAMES))),\n",
    "            zero_division=0,\n",
    "        )\n",
    "        _plot_per_class_metrics(precision, recall, f1, plot_tag)\n",
    "        auc_scores = _plot_roc_curves(labels, probs, plot_tag)\n",
    "        _plot_roc_auc_bars(auc_scores, plot_tag)\n",
    "        _plot_precision_recall_curves(labels, probs, plot_tag)\n",
    "        _plot_score_distribution(labels, preds, probs, plot_tag)\n",
    "\n",
    "    model.eval()\n",
    "    if cfg.get('save_weights', True):\n",
    "        tag = MODEL_ID.replace('/', '_') if MODEL_ID else 'eurosat_classifier'\n",
    "        save_path = MODELS_DIR / f'{tag}_cirrus_finetuned_{RUN_TIMESTAMP}.pt'\n",
    "        torch.save({\n",
    "            'state_dict': model.state_dict(),\n",
    "            'config': getattr(model, 'config', None),\n",
    "            'history': history,\n",
    "            'class_names': CLASS_NAMES,\n",
    "            'test_results': test_results,\n",
    "        }, save_path)\n",
    "        print(f\"Saved fine-tuned classifier weights to {save_path}\")\n",
    "\n",
    "    return history, test_results\n",
    "\n",
    "\n",
    "FINETUNE_CFG = {\n",
    "    'val_fraction': 0.15,\n",
    "    'test_fraction': 0.15,\n",
    "    'limit_per_class': None,\n",
    "    'epochs': 7,\n",
    "    'early_stopping_patience': 3,\n",
    "    'train_batch_size': 8,\n",
    "    'val_batch_size': 16,\n",
    "    'test_batch_size': 16,\n",
    "    'lr': 2e-4,\n",
    "    'weight_decay': 5e-2,\n",
    "    'label_smoothing': 0.1,\n",
    "    'mixup_alpha': 0.8,\n",
    "    'mixup_prob': 1.0,\n",
    "    'max_grad_norm': None,\n",
    "    'num_workers': None,\n",
    "    'save_weights': True,\n",
    "    'seed': RANDOM_SEED,\n",
    "}\n",
    "RUN_CLASSIFIER_FINE_TUNE = True\n",
    "\n",
    "finetune_history = None\n",
    "finetune_test_results = None\n",
    "if RUN_CLASSIFIER_FINE_TUNE:\n",
    "    finetune_history, finetune_test_results = finetune_classifier_with_cirrus(model, processor, FINETUNE_CFG)\n",
    "else:\n",
    "    print('Skipping classifier fine-tuning. Set RUN_CLASSIFIER_FINE_TUNE = True to enable it.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c4358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EuroSATNPYDataset(Dataset):\n",
    "    def __init__(self, paths, processor):\n",
    "        self.paths = paths\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        arr = np.load(path, allow_pickle=False)\n",
    "        if arr.ndim == 3 and arr.shape[0] not in (12, 13) and arr.shape[-1] in (12, 13):\n",
    "            arr = np.moveaxis(arr, -1, 0)\n",
    "        arr = pad_to_13_bands(arr, band_order='test')\n",
    "        inputs = self.processor(images=arr, return_tensors='pt')\n",
    "        pixel_values = inputs['pixel_values'].squeeze(0)\n",
    "        sample_id = self._extract_id(path.stem)\n",
    "        return {'pixel_values': pixel_values, 'id': sample_id}\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_id(stem: str) -> int:\n",
    "        match = re.search(r'(\\d+)$', stem)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        digits = ''.join(ch for ch in stem if ch.isdigit())\n",
    "        return int(digits) if digits else -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c6a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_ROOT = KAGGLE_TEST_DIR\n",
    "if not TEST_ROOT.exists():\n",
    "    raise FileNotFoundError(f\"Expected test directory at {TEST_ROOT}\")\n",
    "\n",
    "npy_paths = sorted(TEST_ROOT.glob('*.npy'))\n",
    "if not npy_paths:\n",
    "    npy_paths = sorted(TEST_ROOT.glob('**/*.npy'))\n",
    "\n",
    "if len(npy_paths) == 0:\n",
    "    raise FileNotFoundError('No .npy files found in Kaggle test directory')\n",
    "\n",
    "print(f\"Found {len(npy_paths)} inference tiles\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0 if platform.system() == 'Darwin' else 2\n",
    "PIN_MEMORY = DEVICE.type == 'cuda'\n",
    "\n",
    "kaggle_dataset = EuroSATNPYDataset(npy_paths, processor)\n",
    "kaggle_loader = DataLoader(\n",
    "    kaggle_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "pred_ids = []\n",
    "pred_indices = []\n",
    "transfer_non_blocking = DEVICE.type == 'cuda'\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(kaggle_loader, desc='Kaggle inference'):\n",
    "        pixel_values = batch['pixel_values'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "        logits = get_model_logits(model, pixel_values)\n",
    "        preds = logits.argmax(dim=1).cpu().tolist()\n",
    "        pred_indices.extend(preds)\n",
    "        if isinstance(batch['id'], torch.Tensor):\n",
    "            pred_ids.extend(batch['id'].cpu().tolist())\n",
    "        else:\n",
    "            pred_ids.extend(batch['id'])\n",
    "\n",
    "pred_labels = [IDX_TO_CLASS[idx] for idx in pred_indices]\n",
    "submission = pd.DataFrame({'test_id': pred_ids, 'label': pred_labels})\n",
    "submission = submission.sort_values('test_id').reset_index(drop=True)\n",
    "\n",
    "submission_name = f'submission_with_cirrus_{RUN_TIMESTAMP}.csv'\n",
    "submission_path = OUTPUT_DIR / submission_name\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Saved submission to {submission_path}\")\n",
    "print(submission.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
