{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7b1bf07",
   "metadata": {},
   "source": [
    "# Code Challenge 1 â€” B10 Reconstruction & Inference Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a95877",
   "metadata": {},
   "source": [
    "This notebook trains a lightweight CNN to reconstruct the missing Sentinel-2 B10 band and then applies a pre-trained EuroSAT classifier to Kaggle tiles after inserting the predicted band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b68e34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cyrilgabriele/anaconda3/envs/ml/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import os, random, math, re, zipfile, platform\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import rasterio\n",
    "\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available() and hasattr(torch, 'mps'):\n",
    "        torch.mps.manual_seed(seed)  # type: ignore[attr-defined]\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "def resolve_device() -> torch.device:\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "set_seed(RANDOM_SEED)\n",
    "\n",
    "DEVICE = resolve_device()\n",
    "print(f\"Using device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd83418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _env_path(var_name: str, default: Path) -> Path:\n",
    "    default_path = Path(default)\n",
    "    value = os.environ.get(var_name)\n",
    "    return Path(value).expanduser() if value else default_path\n",
    "\n",
    "REPO_ROOT = Path.cwd()\n",
    "DATA_BASE = _env_path('EUROSAT_DATA_BASE', Path('/Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project'))\n",
    "DATA_ROOT = _env_path('EUROSAT_DATA_ROOT', DATA_BASE / 'EuroSAT_MS')\n",
    "DATA_ZIP = _env_path('EUROSAT_DATA_ZIP', DATA_BASE / 'EuroSAT_MS.zip')\n",
    "MODELS_DIR = _env_path('EUROSAT_MODELS_DIR', REPO_ROOT / 'artifacts' / 'models')\n",
    "PLOT_DIR = _env_path('EUROSAT_PLOTS_DIR', REPO_ROOT / 'artifacts' / 'plots')\n",
    "B10_MODEL_DIR = _env_path('EUROSAT_B10_MODEL_DIR', MODELS_DIR / 'cirrus_cnn')\n",
    "OUTPUT_DIR = _env_path('EUROSAT_OUTPUT_DIR', REPO_ROOT / 'outputs')\n",
    "KAGGLE_TEST_DIR = _env_path('EUROSAT_KAGGLE_TEST_DIR', DATA_BASE / 'kaggle_data' / 'testset' / 'testset')\n",
    "\n",
    "for path in (MODELS_DIR, PLOT_DIR, B10_MODEL_DIR, OUTPUT_DIR):\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not DATA_ROOT.exists():\n",
    "    if DATA_ZIP.exists():\n",
    "        print(f\"Extracting dataset from {DATA_ZIP} ...\")\n",
    "        with zipfile.ZipFile(DATA_ZIP, 'r') as zip_ref:\n",
    "            zip_ref.extractall(DATA_ROOT.parent)\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Dataset directory {DATA_ROOT} not found. Update EUROSAT_DATA_ROOT or place an archive at {DATA_ZIP}.\"\n",
    "        )\n",
    "else:\n",
    "    print(f\"Dataset already available at {DATA_ROOT}\")\n",
    "\n",
    "RUN_TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(f\"RUN_TIMESTAMP={RUN_TIMESTAMP}\")\n",
    "print(f\"Plots -> {PLOT_DIR}\")\n",
    "print(f\"Models -> {MODELS_DIR}\")\n",
    "print(f\"Outputs -> {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe40d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = []\n",
    "CIRRUS_TILE_PATHS = []\n",
    "\n",
    "if DATA_ROOT.exists():\n",
    "    class_dirs = sorted([d for d in DATA_ROOT.iterdir() if d.is_dir()])\n",
    "    for d in class_dirs:\n",
    "        label = len(CLASS_NAMES)\n",
    "        CLASS_NAMES.append(d.name)\n",
    "        for tif_path in sorted(d.glob('*.tif')):\n",
    "            CIRRUS_TILE_PATHS.append(tif_path)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"{DATA_ROOT} not found. Extract the archive first.\")\n",
    "\n",
    "CLASS_TO_IDX = {name: idx for idx, name in enumerate(CLASS_NAMES)}\n",
    "IDX_TO_CLASS = {idx: name for name, idx in CLASS_TO_IDX.items()}\n",
    "\n",
    "print(f\"Detected {len(CLASS_NAMES)} classes\")\n",
    "print(f\"Total samples: {len(CIRRUS_TILE_PATHS)}\")\n",
    "\n",
    "TRAIN_BAND_ORDER = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B9', 'B10', 'B11', 'B12', 'B8A']\n",
    "TEST_BAND_ORDER = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12']\n",
    "DROP_BAND_NAME = 'B10'\n",
    "DROP_BAND_INDEX = TRAIN_BAND_ORDER.index(DROP_BAND_NAME)\n",
    "KEEP_IDX_13 = np.array([i for i, band in enumerate(TRAIN_BAND_ORDER) if band != DROP_BAND_NAME])\n",
    "CANONICAL_12_BAND_ORDER = [band for band in TRAIN_BAND_ORDER if band != DROP_BAND_NAME]\n",
    "KEEP_IDX_12 = np.arange(len(CANONICAL_12_BAND_ORDER))\n",
    "TEST_TO_CANONICAL_12 = np.array([CANONICAL_12_BAND_ORDER.index(band) for band in TEST_BAND_ORDER], dtype=np.int64)\n",
    "CIRRUS_SCALE = 10000.0\n",
    "CIRRUS_MODEL = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "band_order_utils",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_test_to_canonical(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Reorders 12-band Sentinel-2 L2A (test layout) tiles to the canonical training layout without B10.\"\"\"\n",
    "    if arr.shape[0] != len(TEST_BAND_ORDER):\n",
    "        raise ValueError(f\"Expected array with {len(TEST_BAND_ORDER)} bands, got {arr.shape[0]}\")\n",
    "    out = np.empty_like(arr)\n",
    "    for src_idx, dst_idx in enumerate(TEST_TO_CANONICAL_12):\n",
    "        out[dst_idx] = arr[src_idx]\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf8d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CirrusCNN(nn.Module):\n",
    "    def __init__(self, in_channels: int = 12, hidden_dim: int = 64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_dim, 1, kernel_size=1, bias=True)\n",
    "        )\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "def sample_patches(arr: np.ndarray, num_patches: int, patch_size: int, rng: np.random.Generator):\n",
    "    c, h, w = arr.shape\n",
    "    ps = min(patch_size, h, w)\n",
    "    patches_x = []\n",
    "    patches_y = []\n",
    "    for _ in range(num_patches):\n",
    "        top = int(rng.integers(0, max(1, h - ps + 1)))\n",
    "        left = int(rng.integers(0, max(1, w - ps + 1)))\n",
    "        patch = arr[:, top:top + ps, left:left + ps]\n",
    "        patches_x.append(patch[KEEP_IDX_13])\n",
    "        patches_y.append(patch[DROP_BAND_INDEX:DROP_BAND_INDEX + 1])\n",
    "    return patches_x, patches_y\n",
    "\n",
    "\n",
    "def _iter_patch_batches(tile_paths, patches_per_tile, patch_size, batch_size, rng: np.random.Generator, desc: str | None = None):\n",
    "    if not tile_paths:\n",
    "        return\n",
    "\n",
    "    order = np.arange(len(tile_paths))\n",
    "    rng.shuffle(order)\n",
    "    iterator = order\n",
    "    if desc is not None:\n",
    "        iterator = tqdm(order, desc=desc, leave=False)\n",
    "    batch_x, batch_y = [], []\n",
    "    for idx in iterator:\n",
    "        path = tile_paths[idx]\n",
    "        with rasterio.open(path) as src:\n",
    "            arr = src.read().astype(np.float32)\n",
    "        if arr.shape[0] != 13:\n",
    "            continue\n",
    "        arr = np.clip(arr, 0.0, CIRRUS_SCALE) / CIRRUS_SCALE\n",
    "        px, py = sample_patches(arr, patches_per_tile, patch_size, rng)\n",
    "        for x_patch, y_patch in zip(px, py):\n",
    "            batch_x.append(x_patch)\n",
    "            batch_y.append(y_patch)\n",
    "            if len(batch_x) == batch_size:\n",
    "                yield torch.from_numpy(np.stack(batch_x)).float(), torch.from_numpy(np.stack(batch_y)).float()\n",
    "                batch_x, batch_y = [], []\n",
    "    if batch_x:\n",
    "        yield torch.from_numpy(np.stack(batch_x)).float(), torch.from_numpy(np.stack(batch_y)).float()\n",
    "\n",
    "\n",
    "def fit_cirrus_cnn(sample_paths,\n",
    "                    patches_per_tile: int = 64,\n",
    "                    patch_size: int = 64,\n",
    "                    epochs: int = 5,\n",
    "                    batch_size: int = 128,\n",
    "                    lr: float = 5e-4,\n",
    "                    val_fraction: float = 0.1,\n",
    "                    max_tiles: int | None = None,\n",
    "                    early_stopping_patience: int = 3) -> dict:\n",
    "    if not sample_paths:\n",
    "        raise ValueError(\"No samples provided for cirrus CNN fitting\")\n",
    "\n",
    "    base_rng = np.random.default_rng(RANDOM_SEED)\n",
    "    paths = list(sample_paths)\n",
    "    if max_tiles is not None and len(paths) > max_tiles:\n",
    "        idx = base_rng.choice(len(paths), size=max_tiles, replace=False)\n",
    "        paths = [paths[i] for i in idx]\n",
    "    base_rng.shuffle(paths)\n",
    "\n",
    "    val_count = max(1, int(len(paths) * val_fraction))\n",
    "    val_paths = paths[:val_count]\n",
    "    train_paths = paths[val_count:]\n",
    "    if not train_paths:\n",
    "        raise ValueError(\"Not enough tiles for training after validation split\")\n",
    "\n",
    "    print(f\"[CirrusCNN] Training on {len(train_paths)} tiles (+{len(val_paths)} val) with {patches_per_tile} patches per tile per epoch.\")\n",
    "\n",
    "    model = CirrusCNN().to(DEVICE)\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "    best_state = None\n",
    "    best_val = float('inf')\n",
    "    best_epoch = 0\n",
    "\n",
    "    history = []\n",
    "\n",
    "    patience = max(1, early_stopping_patience)\n",
    "    no_improve_epochs = 0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_rng = np.random.default_rng(base_rng.integers(0, 1 << 32))\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_samples = 0\n",
    "        for xb, yb in _iter_patch_batches(train_paths, patches_per_tile, patch_size, batch_size, epoch_rng, desc=f'Train patches (epoch {epoch})'):\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * xb.size(0)\n",
    "            train_samples += xb.size(0)\n",
    "        train_loss = train_loss / max(1, train_samples)\n",
    "\n",
    "        val_rng = np.random.default_rng(epoch_rng.integers(0, 1 << 32))\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in _iter_patch_batches(val_paths, patches_per_tile, patch_size, batch_size, val_rng, desc=f'Val patches (epoch {epoch})'):\n",
    "                xb = xb.to(DEVICE)\n",
    "                yb = yb.to(DEVICE)\n",
    "                preds = model(xb)\n",
    "                val_loss += criterion(preds, yb).item() * xb.size(0)\n",
    "                val_samples += xb.size(0)\n",
    "        val_loss = val_loss / max(1, val_samples)\n",
    "        print(f\"[CirrusCNN] epoch {epoch}/{epochs} train={train_loss:.6f} val={val_loss:.6f}\")\n",
    "\n",
    "        history.append({'epoch': epoch, 'train_loss': train_loss, 'val_loss': val_loss, 'train_samples': train_samples, 'val_samples': val_samples})\n",
    "\n",
    "        if val_loss < best_val and val_samples > 0:\n",
    "            best_val = val_loss\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            best_epoch = epoch\n",
    "            no_improve_epochs = 0\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "            if no_improve_epochs >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch}; best val {best_val:.6f} at epoch {best_epoch}\")\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    eval_rng = np.random.default_rng(RANDOM_SEED + 1234)\n",
    "    mae_sum = 0.0\n",
    "    mse_sum = 0.0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in _iter_patch_batches(paths, patches_per_tile, patch_size, 256, eval_rng, desc='Evaluating cirrus CNN'):\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "            preds = model(xb)\n",
    "            mae_sum += torch.nn.functional.l1_loss(preds, yb, reduction='sum').item()\n",
    "            mse_sum += torch.nn.functional.mse_loss(preds, yb, reduction='sum').item()\n",
    "            count += xb.size(0)\n",
    "    mae = mae_sum / max(1, count)\n",
    "    rmse = math.sqrt(mse_sum / max(1, count))\n",
    "\n",
    "    print(f\"[CirrusCNN] Aggregated over ~{count} patches | MAE={mae:.6f} | RMSE={rmse:.6f}\")\n",
    "\n",
    "    if history:\n",
    "        hist_df = pd.DataFrame(history)\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        ax.plot(hist_df['epoch'], hist_df['train_loss'], label='Train')\n",
    "        ax.plot(hist_df['epoch'], hist_df['val_loss'], label='Val')\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('SmoothL1 Loss')\n",
    "        ax.set_title('CirrusCNN Training History')\n",
    "        ax.legend()\n",
    "        ax.grid(True, linestyle='--', alpha=0.3)\n",
    "        fig.tight_layout()\n",
    "        plot_path = PLOT_DIR / f'cirrus_cnn_history_{RUN_TIMESTAMP}.png'\n",
    "        fig.savefig(plot_path, dpi=180, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "        print(f\"Saved CirrusCNN training plot to {plot_path}\")\n",
    "\n",
    "    return {\n",
    "        'module': model,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'scale': CIRRUS_SCALE,\n",
    "    }\n",
    "\n",
    "\n",
    "def synthesize_cirrus(arr: np.ndarray, band_order: str | None = None) -> np.ndarray:\n",
    "    arr = np.asarray(arr, dtype=np.float32)\n",
    "    if CIRRUS_MODEL is None:\n",
    "        raise RuntimeError('CIRRUS_MODEL is None. Train or load the B10 reconstruction model before calling synthesize_cirrus.')\n",
    "\n",
    "    if band_order is None:\n",
    "        if arr.shape[0] == len(TRAIN_BAND_ORDER):\n",
    "            band_order = 'train'\n",
    "        elif arr.shape[0] == len(TEST_BAND_ORDER):\n",
    "            band_order = 'test'\n",
    "        elif arr.shape[0] == len(CANONICAL_12_BAND_ORDER):\n",
    "            band_order = 'canonical_12'\n",
    "        else:\n",
    "            raise ValueError(f\"Expected 12 or 13 bands, got {arr.shape}\")\n",
    "\n",
    "    scale = CIRRUS_MODEL['scale']\n",
    "    if band_order == 'train':\n",
    "        arr_scaled = np.clip(arr, 0.0, scale) / scale\n",
    "        feats = arr_scaled[KEEP_IDX_13]\n",
    "    elif band_order == 'test':\n",
    "        reordered = reorder_test_to_canonical(arr)\n",
    "        arr_scaled = np.clip(reordered, 0.0, scale) / scale\n",
    "        feats = arr_scaled\n",
    "    elif band_order == 'canonical_12':\n",
    "        if arr.shape[0] != len(CANONICAL_12_BAND_ORDER):\n",
    "            raise ValueError(f\"Expected canonical 12-band array with shape (12, H, W), got {arr.shape}\")\n",
    "        arr_scaled = np.clip(arr, 0.0, scale) / scale\n",
    "        feats = arr_scaled\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported band_order: {band_order}\")\n",
    "\n",
    "    tensor = torch.from_numpy(feats).unsqueeze(0).to(DEVICE)\n",
    "    module = CIRRUS_MODEL['module'].to(DEVICE)\n",
    "    CIRRUS_MODEL['module'] = module\n",
    "    module.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = module(tensor).squeeze(0).squeeze(0).detach().cpu().numpy()\n",
    "    pred = np.clip(pred, 0.0, 1.0) * scale\n",
    "    return pred.astype(np.float32)\n",
    "\n",
    "\n",
    "def pad_to_13_bands(arr: np.ndarray, band_order: str | None = None) -> np.ndarray:\n",
    "    arr = np.asarray(arr, dtype=np.float32)\n",
    "    if band_order is None:\n",
    "        if arr.shape[0] == len(TRAIN_BAND_ORDER):\n",
    "            band_order = 'train'\n",
    "        elif arr.shape[0] == len(TEST_BAND_ORDER):\n",
    "            band_order = 'test'\n",
    "        elif arr.shape[0] == len(CANONICAL_12_BAND_ORDER):\n",
    "            band_order = 'canonical_12'\n",
    "        else:\n",
    "            raise ValueError(f\"Expected 12 or 13 bands, got {arr.shape}\")\n",
    "\n",
    "    if band_order == 'train':\n",
    "        out = arr.copy()\n",
    "        out[DROP_BAND_INDEX] = synthesize_cirrus(arr, band_order='train')\n",
    "        return out\n",
    "\n",
    "    if band_order == 'test':\n",
    "        canonical = reorder_test_to_canonical(arr)\n",
    "    elif band_order == 'canonical_12':\n",
    "        if arr.shape[0] != len(CANONICAL_12_BAND_ORDER):\n",
    "            raise ValueError(f\"Expected canonical 12-band array with shape (12, H, W), got {arr.shape}\")\n",
    "        canonical = arr\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported band_order: {band_order}\")\n",
    "\n",
    "    cirrus = synthesize_cirrus(canonical, band_order='canonical_12')\n",
    "    return np.concatenate(\n",
    "        [canonical[:DROP_BAND_INDEX], cirrus[np.newaxis, ...], canonical[DROP_BAND_INDEX:]],\n",
    "        axis=0\n",
    "    )\n",
    "\n",
    "\n",
    "def robust_normalize(arr: np.ndarray) -> np.ndarray:\n",
    "    arr = arr.astype(np.float32, copy=False)\n",
    "    out = np.empty_like(arr)\n",
    "    for i in range(arr.shape[0]):\n",
    "        band = arr[i]\n",
    "        lo, hi = np.percentile(band, [2, 98])\n",
    "        if hi > lo:\n",
    "            band = (band - lo) / (hi - lo)\n",
    "        else:\n",
    "            min_v, max_v = band.min(), band.max()\n",
    "            if max_v > min_v:\n",
    "                band = (band - min_v) / (max_v - min_v)\n",
    "            else:\n",
    "                band = np.zeros_like(band)\n",
    "        out[i] = np.clip(band, 0.0, 1.0)\n",
    "    return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0617de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "cirrus_paths = CIRRUS_TILE_PATHS\n",
    "CIRRUS_MODEL = fit_cirrus_cnn(cirrus_paths, epochs=3, patches_per_tile=64, patch_size=64)\n",
    "CIRRUS_MODEL['module'] = CIRRUS_MODEL['module'].to(DEVICE)\n",
    "CIRRUS_MODEL['module'].eval()\n",
    "\n",
    "cirrus_state_dict = {k: v.detach().cpu() for k, v in CIRRUS_MODEL['module'].state_dict().items()}\n",
    "\n",
    "b10_bundle = {\n",
    "    'state_dict': cirrus_state_dict,\n",
    "    'mae': CIRRUS_MODEL['mae'],\n",
    "    'rmse': CIRRUS_MODEL['rmse'],\n",
    "    'scale': CIRRUS_MODEL['scale'],\n",
    "    'drop_band_index': DROP_BAND_INDEX,\n",
    "    'keep_idx_12': KEEP_IDX_12,\n",
    "    'keep_idx_13': KEEP_IDX_13,\n",
    "    'train_band_order': TRAIN_BAND_ORDER,\n",
    "    'test_band_order': TEST_BAND_ORDER,\n",
    "    'canonical_12_band_order': CANONICAL_12_BAND_ORDER,\n",
    "}\n",
    "\n",
    "b10_model_path = B10_MODEL_DIR / f'cirrus_cnn_{RUN_TIMESTAMP}.pt'\n",
    "torch.save(b10_bundle, b10_model_path)\n",
    "print(f\"Saved B10 reconstruction weights to {b10_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b837ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = 'Rhodham96/EuroSatCNN'\n",
    "MODEL_SOURCE = 'auto'  # auto -> local first, fallback to HF\n",
    "LOCAL_MODEL_DIR_CANDIDATES = [\n",
    "    Path('/Users/cyrilgabriele/Documents/School/00_Courses/02_ML/03_project/Rhodham96-EuroSatCNN'),\n",
    "    MODELS_DIR / 'Rhodham96-EuroSatCNN',\n",
    "    Path('./local_models/Rhodham96-EuroSatCNN'),\n",
    "    Path('./models/Rhodham96-EuroSatCNN'),\n",
    "    Path.home() / 'models' / 'Rhodham96-EuroSatCNN',\n",
    "]\n",
    "\n",
    "LOCAL_MODEL_DIR = next((p for p in LOCAL_MODEL_DIR_CANDIDATES if p.exists()), LOCAL_MODEL_DIR_CANDIDATES[0])\n",
    "LOCAL_MODEL_DEF = LOCAL_MODEL_DIR / 'model_def.py'\n",
    "LOCAL_MODEL_WEIGHTS = LOCAL_MODEL_DIR / 'pytorch_model.bin'\n",
    "\n",
    "print(f\"Loading classifier {MODEL_ID} (source={MODEL_SOURCE})\")\n",
    "print(f\"Resolved local directory: {LOCAL_MODEL_DIR}\")\n",
    "model = None\n",
    "processor = None\n",
    "image_size = 224\n",
    "\n",
    "local_available = LOCAL_MODEL_DEF.exists() and LOCAL_MODEL_WEIGHTS.exists()\n",
    "\n",
    "if MODEL_SOURCE in ('auto', 'local') and local_available:\n",
    "    import importlib.util\n",
    "    spec = importlib.util.spec_from_file_location('eurosat_local_model', LOCAL_MODEL_DEF)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    if not hasattr(module, 'EuroSATCNN'):\n",
    "        raise AttributeError(f\"EuroSATCNN class not found in {LOCAL_MODEL_DEF}\")\n",
    "    EuroSATCNN = module.EuroSATCNN\n",
    "    model = EuroSATCNN(num_classes=len(CLASS_NAMES))\n",
    "    state_dict = torch.load(LOCAL_MODEL_WEIGHTS, map_location='cpu')\n",
    "    if isinstance(state_dict, dict) and 'state_dict' in state_dict:\n",
    "        state_dict = state_dict['state_dict']\n",
    "    model.load_state_dict(state_dict)\n",
    "    image_size = getattr(model, 'image_size', getattr(model, 'input_resolution', 64))\n",
    "    if not hasattr(model, 'image_size'):\n",
    "        model.image_size = image_size\n",
    "    print(f\"Loaded local weights from {LOCAL_MODEL_WEIGHTS}\")\n",
    "\n",
    "if model is None and MODEL_SOURCE in ('auto', 'hf'):\n",
    "    print(f\"Falling back to Hugging Face hub for {MODEL_ID}\")\n",
    "    model = AutoModelForImageClassification.from_pretrained(MODEL_ID)\n",
    "    image_size = getattr(model.config, 'image_size', image_size)\n",
    "    try:\n",
    "        processor = AutoImageProcessor.from_pretrained(MODEL_ID)\n",
    "    except (OSError, IndexError) as hf_proc_err:\n",
    "        print(f\"Processor load failed: {hf_proc_err}\")\n",
    "        processor = None\n",
    "\n",
    "if processor is None:\n",
    "    print('Using fallback processor.')\n",
    "\n",
    "    class EuroSatFallbackImageProcessor:\n",
    "        def __init__(self, image_size: int = 224):\n",
    "            self.image_size = image_size\n",
    "\n",
    "        def _prep_single(self, image):\n",
    "            if isinstance(image, np.ndarray):\n",
    "                tensor = torch.from_numpy(image)\n",
    "                if tensor.dtype != torch.float32:\n",
    "                    tensor = tensor.float()\n",
    "            elif torch.is_tensor(image):\n",
    "                tensor = image.float()\n",
    "            else:\n",
    "                tensor = torch.from_numpy(np.asarray(image, dtype=np.float32))\n",
    "\n",
    "            if tensor.ndim != 3:\n",
    "                raise ValueError(f\"Expected image with 3 dims, got {tuple(tensor.shape)}\")\n",
    "\n",
    "            if tensor.shape[0] not in (3, 13):\n",
    "                tensor = tensor.permute(2, 0, 1)\n",
    "\n",
    "            tensor = tensor.clamp(0.0, 1.0)\n",
    "\n",
    "            if tensor.shape[1:] != (self.image_size, self.image_size):\n",
    "                tensor = torch.nn.functional.interpolate(\n",
    "                    tensor.unsqueeze(0),\n",
    "                    size=(self.image_size, self.image_size),\n",
    "                    mode='bilinear',\n",
    "                    align_corners=False\n",
    "                ).squeeze(0)\n",
    "\n",
    "            return tensor\n",
    "\n",
    "        def __call__(self, images, return_tensors=None):\n",
    "            if isinstance(images, (list, tuple)):\n",
    "                batch = torch.stack([self._prep_single(img) for img in images])\n",
    "            else:\n",
    "                batch = self._prep_single(images).unsqueeze(0)\n",
    "\n",
    "            if return_tensors in (None, 'pt'):\n",
    "                return {'pixel_values': batch}\n",
    "\n",
    "            raise ValueError(f\"Unsupported return_tensors value: {return_tensors!r}\")\n",
    "\n",
    "    processor = EuroSatFallbackImageProcessor(image_size=image_size)\n",
    "\n",
    "if not hasattr(model, 'config'):\n",
    "    from types import SimpleNamespace\n",
    "    model.config = SimpleNamespace()\n",
    "\n",
    "model.config.label2id = {cls: idx for idx, cls in enumerate(CLASS_NAMES)}\n",
    "model.config.id2label = {idx: cls for cls, idx in model.config.label2id.items()}\n",
    "model.config.num_labels = len(CLASS_NAMES)\n",
    "model.config.image_size = image_size\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "print('Classifier ready for inference.')\n",
    "\n",
    "def get_model_logits(model, pixel_values):\n",
    "    try:\n",
    "        outputs = model(pixel_values=pixel_values)\n",
    "    except TypeError:\n",
    "        outputs = model(pixel_values)\n",
    "    if isinstance(outputs, torch.Tensor):\n",
    "        return outputs\n",
    "    if isinstance(outputs, dict):\n",
    "        if 'logits' in outputs:\n",
    "            return outputs['logits']\n",
    "        raise KeyError(\"Model output dict missing 'logits'\")\n",
    "    if hasattr(outputs, 'logits'):\n",
    "        return outputs.logits\n",
    "    raise RuntimeError('Model output does not contain logits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89200af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the classifier using CirrusCNN-synthesized B10 inputs so it sees the same distribution as at inference time\n",
    "\n",
    "\n",
    "def _build_finetune_records(val_fraction: float = 0.1, test_fraction: float = 0.0, limit_per_class: int | None = None, seed: int = RANDOM_SEED):\n",
    "    if not (0.0 < val_fraction < 1.0):\n",
    "        raise ValueError('val_fraction must be between 0 and 1 for fine-tuning splits')\n",
    "    if not (0.0 <= test_fraction < 1.0):\n",
    "        raise ValueError('test_fraction must be between 0 and 1 for fine-tuning splits')\n",
    "    if val_fraction + test_fraction >= 1.0:\n",
    "        raise ValueError('val_fraction + test_fraction must sum to less than 1.0 for fine-tuning splits')\n",
    "    rng = np.random.default_rng(seed)\n",
    "    train_records: list[tuple[Path, int]] = []\n",
    "    val_records: list[tuple[Path, int]] = []\n",
    "    test_records: list[tuple[Path, int]] = []\n",
    "    for class_name in CLASS_NAMES:\n",
    "        class_idx = CLASS_TO_IDX[class_name]\n",
    "        class_dir = DATA_ROOT / class_name\n",
    "        tif_paths = sorted(class_dir.glob('*.tif'))\n",
    "        if not tif_paths:\n",
    "            continue\n",
    "        if limit_per_class is not None and len(tif_paths) > limit_per_class:\n",
    "            selection = rng.choice(len(tif_paths), size=limit_per_class, replace=False)\n",
    "            tif_paths = [tif_paths[i] for i in selection]\n",
    "        order = rng.permutation(len(tif_paths))\n",
    "        tif_paths = [tif_paths[i] for i in order]\n",
    "        if len(tif_paths) < 2:\n",
    "            train_records.extend((path, class_idx) for path in tif_paths)\n",
    "            continue\n",
    "        total = len(tif_paths)\n",
    "        val_count = 0\n",
    "        test_count = 0\n",
    "        if val_fraction > 0.0:\n",
    "            val_count = max(1, int(total * val_fraction))\n",
    "            val_count = min(total - 1, val_count)\n",
    "        remaining = total - val_count\n",
    "        if test_fraction > 0.0 and remaining > 1:\n",
    "            test_count = max(1, int(total * test_fraction))\n",
    "            test_count = min(test_count, remaining - 1)\n",
    "        val_slice = tif_paths[:val_count]\n",
    "        test_slice = tif_paths[val_count:val_count + test_count]\n",
    "        train_slice = tif_paths[val_count + test_count:]\n",
    "        if not train_slice:\n",
    "            raise RuntimeError('Unable to keep at least one training tile per class; adjust val/test fractions or increase data availability.')\n",
    "        val_records.extend((path, class_idx) for path in val_slice)\n",
    "        test_records.extend((path, class_idx) for path in test_slice)\n",
    "        train_records.extend((path, class_idx) for path in train_slice)\n",
    "    if not train_records or not val_records:\n",
    "        raise RuntimeError('Unable to build stratified fine-tuning splits; consider lowering val_fraction or increasing data availability.')\n",
    "    if test_fraction > 0.0 and not test_records:\n",
    "        raise RuntimeError('Unable to build stratified fine-tuning test split; consider lowering test_fraction or increasing data availability.')\n",
    "    return train_records, val_records, test_records\n",
    "\n",
    "\n",
    "class EuroSATCirrusFinetuneDataset(Dataset):\n",
    "    def __init__(self, records, processor, inject_cirrus_b10: bool = True):\n",
    "        if processor is None:\n",
    "            raise RuntimeError('processor must be initialized before building the fine-tuning dataset')\n",
    "        if inject_cirrus_b10 and CIRRUS_MODEL is None:\n",
    "            raise RuntimeError('CIRRUS_MODEL is None; train or load the B10 reconstruction model before fine-tuning the classifier')\n",
    "        self.records = records\n",
    "        self.processor = processor\n",
    "        self.inject_cirrus_b10 = inject_cirrus_b10\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        path, label = self.records[idx]\n",
    "        with rasterio.open(path) as src:\n",
    "            arr = src.read().astype(np.float32)\n",
    "        if self.inject_cirrus_b10:\n",
    "            arr = pad_to_13_bands(arr, band_order='train')\n",
    "        arr = robust_normalize(arr)\n",
    "        arr = np.moveaxis(arr, 0, -1)\n",
    "        inputs = self.processor(images=arr, return_tensors='pt')\n",
    "        pixel_values = inputs['pixel_values'].squeeze(0)\n",
    "        return {\n",
    "            'pixel_values': pixel_values,\n",
    "            'labels': torch.tensor(label, dtype=torch.long),\n",
    "            'path': str(path),\n",
    "        }\n",
    "\n",
    "\n",
    "def finetune_classifier_with_cirrus(model, processor, cfg: dict):\n",
    "    train_records, val_records, test_records = _build_finetune_records(\n",
    "        val_fraction=cfg.get('val_fraction', 0.1),\n",
    "        test_fraction=cfg.get('test_fraction', 0.0),\n",
    "        limit_per_class=cfg.get('limit_per_class'),\n",
    "        seed=cfg.get('seed', RANDOM_SEED),\n",
    "    )\n",
    "    train_dataset = EuroSATCirrusFinetuneDataset(train_records, processor, inject_cirrus_b10=True)\n",
    "    val_dataset = EuroSATCirrusFinetuneDataset(val_records, processor, inject_cirrus_b10=True)\n",
    "    test_dataset = EuroSATCirrusFinetuneDataset(test_records, processor, inject_cirrus_b10=True) if test_records else None\n",
    "\n",
    "    num_workers = cfg.get('num_workers')\n",
    "    if num_workers is None:\n",
    "        num_workers = 0 if platform.system() == 'Darwin' else 4\n",
    "    pin_memory = DEVICE.type == 'cuda'\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=cfg.get('train_batch_size', 32),\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=cfg.get('val_batch_size', 64),\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "    )\n",
    "    test_loader = None\n",
    "    if test_dataset is not None:\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=cfg.get('test_batch_size', cfg.get('val_batch_size', 64)),\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=pin_memory,\n",
    "        )\n",
    "\n",
    "    print(f\"[FineTune] Split sizes -> train: {len(train_records)} | val: {len(val_records)} | test: {len(test_records)}\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=cfg.get('lr', 5e-5),\n",
    "        weight_decay=cfg.get('weight_decay', 1e-2),\n",
    "    )\n",
    "    max_grad_norm = cfg.get('max_grad_norm', 1.0)\n",
    "    epochs = cfg.get('epochs', 3)\n",
    "    transfer_non_blocking = DEVICE.type == 'cuda'\n",
    "\n",
    "    best_state = None\n",
    "    best_val_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    history = []\n",
    "\n",
    "    patience = max(1, cfg.get('early_stopping_patience', 3))\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_samples = 0\n",
    "        for batch in tqdm(train_loader, desc=f'Fine-tune train {epoch}/{epochs}', leave=False):\n",
    "            pixel_values = batch['pixel_values'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "            labels = batch['labels'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            logits = get_model_logits(model, pixel_values)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            if max_grad_norm is not None and max_grad_norm > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * labels.size(0)\n",
    "            train_correct += (logits.argmax(dim=1) == labels).sum().item()\n",
    "            train_samples += labels.size(0)\n",
    "        train_loss = train_loss / max(1, train_samples)\n",
    "        train_acc = train_correct / max(1, train_samples)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=f'Fine-tune val {epoch}/{epochs}', leave=False):\n",
    "                pixel_values = batch['pixel_values'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "                labels = batch['labels'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "                logits = get_model_logits(model, pixel_values)\n",
    "                loss = criterion(logits, labels)\n",
    "                val_loss += loss.item() * labels.size(0)\n",
    "                val_correct += (logits.argmax(dim=1) == labels).sum().item()\n",
    "                val_samples += labels.size(0)\n",
    "        val_loss = val_loss / max(1, val_samples)\n",
    "        val_acc = val_correct / max(1, val_samples)\n",
    "\n",
    "        history.append({\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'train_samples': train_samples,\n",
    "            'val_samples': val_samples,\n",
    "        })\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            no_improve_epochs = 0\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "            if no_improve_epochs >= patience:\n",
    "                print(f\"[FineTune] Early stopping triggered at epoch {epoch} (patience={patience}).\")\n",
    "                break\n",
    "\n",
    "        print(f\"[FineTune] epoch {epoch}/{epochs} | train_loss={train_loss:.4f} train_acc={train_acc:.4f} | val_loss={val_loss:.4f} val_acc={val_acc:.4f}\")\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "        print(f\"Loaded best fine-tuned weights from epoch {best_epoch} (val_acc={best_val_acc:.4f})\")\n",
    "\n",
    "    test_results = None\n",
    "    if test_loader is not None:\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct = 0\n",
    "        test_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc='Fine-tune test', leave=False):\n",
    "                pixel_values = batch['pixel_values'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "                labels = batch['labels'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "                logits = get_model_logits(model, pixel_values)\n",
    "                loss = criterion(logits, labels)\n",
    "                test_loss += loss.item() * labels.size(0)\n",
    "                test_correct += (logits.argmax(dim=1) == labels).sum().item()\n",
    "                test_samples += labels.size(0)\n",
    "        test_loss = test_loss / max(1, test_samples)\n",
    "        test_acc = test_correct / max(1, test_samples)\n",
    "        test_results = {\n",
    "            'test_loss': test_loss,\n",
    "            'test_acc': test_acc,\n",
    "            'test_samples': test_samples,\n",
    "        }\n",
    "        print(f\"[FineTune/Test] loss={test_loss:.4f} acc={test_acc:.4f} | samples={test_samples}\")\n",
    "\n",
    "    model.eval()\n",
    "    if cfg.get('save_weights', True):\n",
    "        tag = MODEL_ID.replace('/', '_') if MODEL_ID else 'eurosat_classifier'\n",
    "        save_path = MODELS_DIR / f'{tag}_cirrus_finetuned_{RUN_TIMESTAMP}.pt'\n",
    "        torch.save({\n",
    "            'state_dict': model.state_dict(),\n",
    "            'config': getattr(model, 'config', None),\n",
    "            'history': history,\n",
    "            'class_names': CLASS_NAMES,\n",
    "            'test_results': test_results,\n",
    "        }, save_path)\n",
    "        print(f\"Saved fine-tuned classifier weights to {save_path}\")\n",
    "\n",
    "    return history, test_results\n",
    "\n",
    "\n",
    "FINETUNE_CFG = {\n",
    "    'val_fraction': 0.15,\n",
    "    'test_fraction': 0.15,\n",
    "    'limit_per_class': None,\n",
    "    'epochs': 15,\n",
    "    'early_stopping_patience': 3,\n",
    "    'train_batch_size': 32,\n",
    "    'val_batch_size': 64,\n",
    "    'test_batch_size': 64,\n",
    "    'lr': 5e-5,\n",
    "    'weight_decay': 1e-2,\n",
    "    'max_grad_norm': 1.0,\n",
    "    'num_workers': None,\n",
    "    'save_weights': True,\n",
    "    'seed': RANDOM_SEED,\n",
    "}\n",
    "RUN_CLASSIFIER_FINE_TUNE = True\n",
    "\n",
    "finetune_history = None\n",
    "finetune_test_results = None\n",
    "if RUN_CLASSIFIER_FINE_TUNE:\n",
    "    finetune_history, finetune_test_results = finetune_classifier_with_cirrus(model, processor, FINETUNE_CFG)\n",
    "else:\n",
    "    print('Skipping classifier fine-tuning. Set RUN_CLASSIFIER_FINE_TUNE = True to enable it.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c4358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EuroSATNPYDataset(Dataset):\n",
    "    def __init__(self, paths, processor):\n",
    "        self.paths = paths\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        arr = np.load(path, allow_pickle=False)\n",
    "        if arr.ndim == 3 and arr.shape[0] not in (12, 13) and arr.shape[-1] in (12, 13):\n",
    "            arr = np.moveaxis(arr, -1, 0)\n",
    "        arr = pad_to_13_bands(arr, band_order='test')\n",
    "        arr = robust_normalize(arr)\n",
    "        arr = np.moveaxis(arr, 0, -1)\n",
    "        inputs = self.processor(images=arr, return_tensors='pt')\n",
    "        pixel_values = inputs['pixel_values'].squeeze(0)\n",
    "        sample_id = self._extract_id(path.stem)\n",
    "        return {'pixel_values': pixel_values, 'id': sample_id}\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_id(stem: str) -> int:\n",
    "        match = re.search(r'(\\d+)$', stem)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        digits = ''.join(ch for ch in stem if ch.isdigit())\n",
    "        return int(digits) if digits else -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c6a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_ROOT = KAGGLE_TEST_DIR\n",
    "if not TEST_ROOT.exists():\n",
    "    raise FileNotFoundError(f\"Expected test directory at {TEST_ROOT}\")\n",
    "\n",
    "npy_paths = sorted(TEST_ROOT.glob('*.npy'))\n",
    "if not npy_paths:\n",
    "    npy_paths = sorted(TEST_ROOT.glob('**/*.npy'))\n",
    "\n",
    "if len(npy_paths) == 0:\n",
    "    raise FileNotFoundError('No .npy files found in Kaggle test directory')\n",
    "\n",
    "print(f\"Found {len(npy_paths)} inference tiles\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0 if platform.system() == 'Darwin' else 2\n",
    "PIN_MEMORY = DEVICE.type == 'cuda'\n",
    "\n",
    "kaggle_dataset = EuroSATNPYDataset(npy_paths, processor)\n",
    "kaggle_loader = DataLoader(\n",
    "    kaggle_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "pred_ids = []\n",
    "pred_indices = []\n",
    "transfer_non_blocking = DEVICE.type == 'cuda'\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(kaggle_loader, desc='Kaggle inference'):\n",
    "        pixel_values = batch['pixel_values'].to(DEVICE, non_blocking=transfer_non_blocking)\n",
    "        logits = get_model_logits(model, pixel_values)\n",
    "        preds = logits.argmax(dim=1).cpu().tolist()\n",
    "        pred_indices.extend(preds)\n",
    "        if isinstance(batch['id'], torch.Tensor):\n",
    "            pred_ids.extend(batch['id'].cpu().tolist())\n",
    "        else:\n",
    "            pred_ids.extend(batch['id'])\n",
    "\n",
    "pred_labels = [IDX_TO_CLASS[idx] for idx in pred_indices]\n",
    "submission = pd.DataFrame({'test_id': pred_ids, 'label': pred_labels})\n",
    "submission = submission.sort_values('test_id').reset_index(drop=True)\n",
    "\n",
    "submission_name = f'submission_with_cirrus_{RUN_TIMESTAMP}.csv'\n",
    "submission_path = OUTPUT_DIR / submission_name\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Saved submission to {submission_path}\")\n",
    "print(submission.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
