{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7b1bf07",
   "metadata": {},
   "source": [
    "# Code Challenge 1 â€” B10 Reconstruction & Inference Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a95877",
   "metadata": {},
   "source": [
    "This notebook trains a lightweight CNN to reconstruct the missing Sentinel-2 B10 band and then applies a pre-trained EuroSAT classifier to Kaggle tiles after inserting the predicted band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552dec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q rasterio transformers huggingface_hub accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b68e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import os, random, math, time, shutil, glob, re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import rasterio\n",
    "\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "set_seed(RANDOM_SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ee7415",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "ZIP_PATH = \"/content/drive/MyDrive/ML_HSG/EuroSAT_MS.zip\"\n",
    "DATA_ROOT = Path('/content/EuroSAT_MS')\n",
    "MODELS_DIR = Path('/content/drive/MyDrive/ML_HSG/models')\n",
    "PLOT_DIR = Path('/content/drive/MyDrive/ML_HSG/plots')\n",
    "B10_MODEL_DIR = MODELS_DIR / 'cirrus_cnn'\n",
    "OUTPUT_DIR = Path('/content/drive/MyDrive/ML_HSG/kaggle_submissions')\n",
    "\n",
    "for path in (MODELS_DIR, PLOT_DIR, B10_MODEL_DIR, OUTPUT_DIR):\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not DATA_ROOT.exists():\n",
    "    print(f\"Extracting dataset from {ZIP_PATH} ...\")\n",
    "    !unzip -q -o \"$ZIP_PATH\" -d '/content'\n",
    "else:\n",
    "    print(f\"Dataset already available at {DATA_ROOT}\")\n",
    "\n",
    "RUN_TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(f\"RUN_TIMESTAMP={RUN_TIMESTAMP}\")\n",
    "print(f\"Plots -> {PLOT_DIR}\")\n",
    "print(f\"Models -> {MODELS_DIR}\")\n",
    "print(f\"Kaggle submissions -> {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd83418",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = []\n",
    "samples = []\n",
    "\n",
    "if DATA_ROOT.exists():\n",
    "    class_dirs = sorted([d for d in DATA_ROOT.iterdir() if d.is_dir()])\n",
    "    for d in class_dirs:\n",
    "        label = len(CLASS_NAMES)\n",
    "        CLASS_NAMES.append(d.name)\n",
    "        for tif_path in sorted(d.glob('*.tif')):\n",
    "            samples.append((tif_path, label))\n",
    "else:\n",
    "    raise FileNotFoundError(f\"{DATA_ROOT} not found. Extract the archive first.\")\n",
    "\n",
    "CLASS_TO_IDX = {name: idx for idx, name in enumerate(CLASS_NAMES)}\n",
    "IDX_TO_CLASS = {idx: name for name, idx in CLASS_TO_IDX.items()}\n",
    "\n",
    "print(f\"Detected {len(CLASS_NAMES)} classes\")\n",
    "print(f\"Total samples: {len(samples)}\")\n",
    "\n",
    "DROP_BAND_INDEX = 10  # Sentinel-2 B10 (cirrus)\n",
    "KEEP_IDX_13 = np.array([i for i in range(13) if i != DROP_BAND_INDEX])\n",
    "KEEP_IDX_12 = np.array([i for i in range(12)])\n",
    "CIRRUS_SCALE = 10000.0\n",
    "CIRRUS_MODEL = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf8d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CirrusCNN(nn.Module):\n",
    "    def __init__(self, in_channels: int = 12, hidden_dim: int = 64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_dim, 1, kernel_size=1, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "def sample_patches(arr: np.ndarray, num_patches: int, patch_size: int, rng: np.random.Generator):\n",
    "    c, h, w = arr.shape\n",
    "    ps = min(patch_size, h, w)\n",
    "    patches_x = []\n",
    "    patches_y = []\n",
    "    for _ in range(num_patches):\n",
    "        top = int(rng.integers(0, max(1, h - ps + 1)))\n",
    "        left = int(rng.integers(0, max(1, w - ps + 1)))\n",
    "        patch = arr[:, top:top + ps, left:left + ps]\n",
    "        patches_x.append(patch[KEEP_IDX_13])\n",
    "        patches_y.append(patch[DROP_BAND_INDEX:DROP_BAND_INDEX + 1])\n",
    "    return patches_x, patches_y\n",
    "\n",
    "\n",
    "def _iter_patch_batches(tile_paths, patches_per_tile, patch_size, batch_size, rng: np.random.Generator, desc: str | None = None):\n",
    "    if not tile_paths:\n",
    "        return\n",
    "\n",
    "    order = np.arange(len(tile_paths))\n",
    "    rng.shuffle(order)\n",
    "    iterator = order\n",
    "    if desc is not None:\n",
    "        iterator = tqdm(order, desc=desc, leave=False)\n",
    "    batch_x, batch_y = [], []\n",
    "    for idx in iterator:\n",
    "        path = tile_paths[idx]\n",
    "        with rasterio.open(path) as src:\n",
    "            arr = src.read().astype(np.float32)\n",
    "        if arr.shape[0] != 13:\n",
    "            continue\n",
    "        arr = np.clip(arr, 0.0, CIRRUS_SCALE) / CIRRUS_SCALE\n",
    "        px, py = sample_patches(arr, patches_per_tile, patch_size, rng)\n",
    "        for x_patch, y_patch in zip(px, py):\n",
    "            batch_x.append(x_patch)\n",
    "            batch_y.append(y_patch)\n",
    "            if len(batch_x) == batch_size:\n",
    "                yield torch.from_numpy(np.stack(batch_x)).float(), torch.from_numpy(np.stack(batch_y)).float()\n",
    "                batch_x, batch_y = [], []\n",
    "    if batch_x:\n",
    "        yield torch.from_numpy(np.stack(batch_x)).float(), torch.from_numpy(np.stack(batch_y)).float()\n",
    "\n",
    "\n",
    "def fit_cirrus_cnn(sample_paths,\n",
    "                    patches_per_tile: int = 48,\n",
    "                    patch_size: int = 64,\n",
    "                    epochs: int = 10,\n",
    "                    batch_size: int = 128,\n",
    "                    lr: float = 5e-4,\n",
    "                    val_fraction: float = 0.1,\n",
    "                    max_tiles: int | None = None) -> dict:\n",
    "    if not sample_paths:\n",
    "        raise ValueError(\"No samples provided for cirrus CNN fitting\")\n",
    "\n",
    "    base_rng = np.random.default_rng(RANDOM_SEED)\n",
    "    paths = list(sample_paths)\n",
    "    if max_tiles is not None and len(paths) > max_tiles:\n",
    "        idx = base_rng.choice(len(paths), size=max_tiles, replace=False)\n",
    "        paths = [paths[i] for i in idx]\n",
    "    base_rng.shuffle(paths)\n",
    "\n",
    "    val_count = max(1, int(len(paths) * val_fraction))\n",
    "    val_paths = paths[:val_count]\n",
    "    train_paths = paths[val_count:]\n",
    "    if not train_paths:\n",
    "        raise ValueError(\"Not enough tiles for training after validation split\")\n",
    "\n",
    "    print(f\"[CirrusCNN] Training on {len(train_paths)} tiles (+{len(val_paths)} val) with {patches_per_tile} patches per tile per epoch.\")\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = CirrusCNN().to(device)\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "    best_state = None\n",
    "    best_val = float('inf')\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_rng = np.random.default_rng(base_rng.integers(0, 1 << 32))\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_samples = 0\n",
    "        for xb, yb in _iter_patch_batches(train_paths, patches_per_tile, patch_size, batch_size, epoch_rng, desc=f'Train patches (epoch {epoch})'):\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * xb.size(0)\n",
    "            train_samples += xb.size(0)\n",
    "        train_loss = train_loss / max(1, train_samples)\n",
    "\n",
    "        val_rng = np.random.default_rng(epoch_rng.integers(0, 1 << 32))\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in _iter_patch_batches(val_paths, patches_per_tile, patch_size, batch_size, val_rng, desc=f'Val patches (epoch {epoch})'):\n",
    "                xb = xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "                preds = model(xb)\n",
    "                val_loss += criterion(preds, yb).item() * xb.size(0)\n",
    "                val_samples += xb.size(0)\n",
    "        val_loss = val_loss / max(1, val_samples)\n",
    "        print(f\"[CirrusCNN] epoch {epoch}/{epochs} train={train_loss:.6f} val={val_loss:.6f}\")\n",
    "\n",
    "        if val_loss < best_val and val_samples > 0:\n",
    "            best_val = val_loss\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    eval_rng = np.random.default_rng(RANDOM_SEED + 1234)\n",
    "    mae_sum = 0.0\n",
    "    mse_sum = 0.0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in _iter_patch_batches(paths, patches_per_tile, patch_size, 256, eval_rng, desc='Evaluating cirrus CNN'):\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            preds = model(xb)\n",
    "            mae_sum += torch.nn.functional.l1_loss(preds, yb, reduction='sum').item()\n",
    "            mse_sum += torch.nn.functional.mse_loss(preds, yb, reduction='sum').item()\n",
    "            count += xb.size(0)\n",
    "    mae = mae_sum / max(1, count)\n",
    "    rmse = math.sqrt(mse_sum / max(1, count))\n",
    "\n",
    "    print(f\"[CirrusCNN] Aggregated over ~{count} patches | MAE={mae:.6f} | RMSE={rmse:.6f}\")\n",
    "\n",
    "    model.cpu()\n",
    "    return {\n",
    "        'module': model,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'scale': CIRRUS_SCALE,\n",
    "    }\n",
    "\n",
    "\n",
    "def synthesize_cirrus(arr: np.ndarray) -> np.ndarray:\n",
    "    arr = np.asarray(arr, dtype=np.float32)\n",
    "    if CIRRUS_MODEL is None:\n",
    "        raise RuntimeError('CIRRUS_MODEL is None. Train or load the B10 reconstruction model before calling synthesize_cirrus.')\n",
    "\n",
    "    scale = CIRRUS_MODEL['scale']\n",
    "    arr_scaled = np.clip(arr, 0.0, scale) / scale\n",
    "    if arr.shape[0] == 13:\n",
    "        feats = arr_scaled[KEEP_IDX_13]\n",
    "    elif arr.shape[0] == 12:\n",
    "        feats = arr_scaled[KEEP_IDX_12]\n",
    "    else:\n",
    "        raise ValueError(f\"Expected 12 or 13 bands, got {arr.shape}\")\n",
    "\n",
    "    tensor = torch.from_numpy(feats).unsqueeze(0)\n",
    "    module = CIRRUS_MODEL['module']\n",
    "    module.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = module(tensor).squeeze(0).squeeze(0).numpy()\n",
    "    pred = np.clip(pred, 0.0, 1.0) * scale\n",
    "    return pred.astype(np.float32)\n",
    "\n",
    "\n",
    "def pad_to_13_bands(arr: np.ndarray) -> np.ndarray:\n",
    "    arr = np.asarray(arr, dtype=np.float32)\n",
    "    if arr.shape[0] == 13:\n",
    "        out = arr.copy()\n",
    "        out[DROP_BAND_INDEX] = synthesize_cirrus(arr)\n",
    "        return out\n",
    "    if arr.shape[0] == 12:\n",
    "        cirrus = synthesize_cirrus(arr)\n",
    "        return np.concatenate([arr[:DROP_BAND_INDEX], cirrus[np.newaxis, ...], arr[DROP_BAND_INDEX:]], axis=0)\n",
    "    raise ValueError(f\"Expected 12 or 13 bands, got {arr.shape}\")\n",
    "\n",
    "\n",
    "def robust_normalize(arr: np.ndarray) -> np.ndarray:\n",
    "    arr = arr.astype(np.float32, copy=False)\n",
    "    out = np.empty_like(arr)\n",
    "    for i in range(arr.shape[0]):\n",
    "        band = arr[i]\n",
    "        lo, hi = np.percentile(band, [2, 98])\n",
    "        if hi > lo:\n",
    "            band = (band - lo) / (hi - lo)\n",
    "        else:\n",
    "            min_v, max_v = band.min(), band.max()\n",
    "            if max_v > min_v:\n",
    "                band = (band - min_v) / (max_v - min_v)\n",
    "            else:\n",
    "                band = np.zeros_like(band)\n",
    "        out[i] = np.clip(band, 0.0, 1.0)\n",
    "    return out\n",
    "\n",
    "\n",
    "def load_multispectral(path: Path) -> np.ndarray:\n",
    "    with rasterio.open(path) as src:\n",
    "        arr = src.read()\n",
    "    arr = pad_to_13_bands(arr)\n",
    "    arr = robust_normalize(arr)\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0617de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "cirrus_paths = [p for p, _ in samples]\n",
    "CIRRUS_MODEL = fit_cirrus_cnn(cirrus_paths, epochs=12, patches_per_tile=64, patch_size=64)\n",
    "CIRRUS_MODEL['module'] = CIRRUS_MODEL['module'].cpu()\n",
    "CIRRUS_MODEL['module'].eval()\n",
    "\n",
    "b10_bundle = {\n",
    "    'state_dict': CIRRUS_MODEL['module'].state_dict(),\n",
    "    'mae': CIRRUS_MODEL['mae'],\n",
    "    'rmse': CIRRUS_MODEL['rmse'],\n",
    "    'scale': CIRRUS_MODEL['scale'],\n",
    "    'drop_band_index': DROP_BAND_INDEX,\n",
    "    'keep_idx_12': KEEP_IDX_12,\n",
    "    'keep_idx_13': KEEP_IDX_13,\n",
    "}\n",
    "\n",
    "b10_model_path = B10_MODEL_DIR / f'cirrus_cnn_{RUN_TIMESTAMP}.pt'\n",
    "torch.save(b10_bundle, b10_model_path)\n",
    "print(f\"Saved B10 reconstruction weights to {b10_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b837ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = 'Rhodham96/EuroSatCNN'\n",
    "MODEL_SOURCE = 'auto'  # auto -> local first, fallback to HF\n",
    "LOCAL_MODEL_DIR_CANDIDATES = [\n",
    "    Path('./local_models/Rhodham96-EuroSatCNN'),\n",
    "    Path('/content/drive/MyDrive/ML_HSG/models/Rhodham96-EuroSatCNN'),\n",
    "    Path('/content/drive/MyDrive/ML_HSG/models/Rhodham96- EuroSatCNN'),\n",
    "]\n",
    "\n",
    "LOCAL_MODEL_DIR = next((p for p in LOCAL_MODEL_DIR_CANDIDATES if p.exists()), LOCAL_MODEL_DIR_CANDIDATES[0])\n",
    "LOCAL_MODEL_DEF = LOCAL_MODEL_DIR / 'model_def.py'\n",
    "LOCAL_MODEL_WEIGHTS = LOCAL_MODEL_DIR / 'pytorch_model.bin'\n",
    "\n",
    "print(f\"Loading classifier {MODEL_ID} (source={MODEL_SOURCE})\")\n",
    "print(f\"Resolved local directory: {LOCAL_MODEL_DIR}\")\n",
    "model = None\n",
    "processor = None\n",
    "image_size = 224\n",
    "\n",
    "local_available = LOCAL_MODEL_DEF.exists() and LOCAL_MODEL_WEIGHTS.exists()\n",
    "\n",
    "if MODEL_SOURCE in ('auto', 'local') and local_available:\n",
    "    import importlib.util\n",
    "    spec = importlib.util.spec_from_file_location('eurosat_local_model', LOCAL_MODEL_DEF)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    if not hasattr(module, 'EuroSATCNN'):\n",
    "        raise AttributeError(f\"EuroSATCNN class not found in {LOCAL_MODEL_DEF}\")\n",
    "    EuroSATCNN = module.EuroSATCNN\n",
    "    model = EuroSATCNN(num_classes=len(CLASS_NAMES))\n",
    "    state_dict = torch.load(LOCAL_MODEL_WEIGHTS, map_location='cpu')\n",
    "    if isinstance(state_dict, dict) and 'state_dict' in state_dict:\n",
    "        state_dict = state_dict['state_dict']\n",
    "    model.load_state_dict(state_dict)\n",
    "    image_size = getattr(model, 'image_size', getattr(model, 'input_resolution', image_size))\n",
    "    print(f\"Loaded local weights from {LOCAL_MODEL_WEIGHTS}\")\n",
    "\n",
    "if model is None and MODEL_SOURCE in ('auto', 'hf'):\n",
    "    print(f\"Falling back to Hugging Face hub for {MODEL_ID}\")\n",
    "    model = AutoModelForImageClassification.from_pretrained(MODEL_ID)\n",
    "    image_size = getattr(model.config, 'image_size', image_size)\n",
    "    try:\n",
    "        processor = AutoImageProcessor.from_pretrained(MODEL_ID)\n",
    "    except (OSError, IndexError) as hf_proc_err:\n",
    "        print(f\"Processor load failed: {hf_proc_err}\")\n",
    "        processor = None\n",
    "\n",
    "if processor is None:\n",
    "    print('Using fallback processor.')\n",
    "\n",
    "    class EuroSatFallbackImageProcessor:\n",
    "        def __init__(self, image_size: int = 224):\n",
    "            self.image_size = image_size\n",
    "\n",
    "        def _prep_single(self, image):\n",
    "            if isinstance(image, np.ndarray):\n",
    "                tensor = torch.from_numpy(image)\n",
    "                if tensor.dtype != torch.float32:\n",
    "                    tensor = tensor.float()\n",
    "            elif torch.is_tensor(image):\n",
    "                tensor = image.float()\n",
    "            else:\n",
    "                tensor = torch.from_numpy(np.asarray(image, dtype=np.float32))\n",
    "\n",
    "            if tensor.ndim != 3:\n",
    "                raise ValueError(f\"Expected image with 3 dims, got {tuple(tensor.shape)}\")\n",
    "\n",
    "            if tensor.shape[0] not in (3, 13):\n",
    "                tensor = tensor.permute(2, 0, 1)\n",
    "\n",
    "            tensor = tensor.clamp(0.0, 1.0)\n",
    "\n",
    "            if tensor.shape[1:] != (self.image_size, self.image_size):\n",
    "                tensor = torch.nn.functional.interpolate(\n",
    "                    tensor.unsqueeze(0),\n",
    "                    size=(self.image_size, self.image_size),\n",
    "                    mode='bilinear',\n",
    "                    align_corners=False\n",
    "                ).squeeze(0)\n",
    "\n",
    "            return tensor\n",
    "\n",
    "        def __call__(self, images, return_tensors=None):\n",
    "            if isinstance(images, (list, tuple)):\n",
    "                batch = torch.stack([self._prep_single(img) for img in images])\n",
    "            else:\n",
    "                batch = self._prep_single(images).unsqueeze(0)\n",
    "\n",
    "            if return_tensors in (None, 'pt'):\n",
    "                return {'pixel_values': batch}\n",
    "\n",
    "            raise ValueError(f\"Unsupported return_tensors value: {return_tensors!r}\")\n",
    "\n",
    "    processor = EuroSatFallbackImageProcessor(image_size=image_size)\n",
    "\n",
    "if not hasattr(model, 'config'):\n",
    "    from types import SimpleNamespace\n",
    "    model.config = SimpleNamespace()\n",
    "\n",
    "model.config.label2id = {cls: idx for idx, cls in enumerate(CLASS_NAMES)}\n",
    "model.config.id2label = {idx: cls for cls, idx in model.config.label2id.items()}\n",
    "model.config.num_labels = len(CLASS_NAMES)\n",
    "model.config.image_size = image_size\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "print('Classifier ready for inference.')\n",
    "\n",
    "def get_model_logits(model, pixel_values):\n",
    "    try:\n",
    "        outputs = model(pixel_values=pixel_values)\n",
    "    except TypeError:\n",
    "        outputs = model(pixel_values)\n",
    "    if isinstance(outputs, torch.Tensor):\n",
    "        return outputs\n",
    "    if isinstance(outputs, dict):\n",
    "        if 'logits' in outputs:\n",
    "            return outputs['logits']\n",
    "        raise KeyError(\"Model output dict missing 'logits'\")\n",
    "    if hasattr(outputs, 'logits'):\n",
    "        return outputs.logits\n",
    "    raise RuntimeError('Model output does not contain logits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c4358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EuroSATNPYDataset(Dataset):\n",
    "    def __init__(self, paths, processor):\n",
    "        self.paths = paths\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        arr = np.load(path, allow_pickle=False)\n",
    "        if arr.ndim == 3 and arr.shape[0] not in (12, 13) and arr.shape[-1] in (12, 13):\n",
    "            arr = np.moveaxis(arr, -1, 0)\n",
    "        arr = pad_to_13_bands(arr)\n",
    "        arr = robust_normalize(arr)\n",
    "        arr = np.moveaxis(arr, 0, -1)\n",
    "        inputs = self.processor(images=arr, return_tensors='pt')\n",
    "        pixel_values = inputs['pixel_values'].squeeze(0)\n",
    "        sample_id = self._extract_id(path.stem)\n",
    "        return {'pixel_values': pixel_values, 'id': sample_id}\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_id(stem: str) -> int:\n",
    "        match = re.search(r'(\\d+)$', stem)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        digits = ''.join(ch for ch in stem if ch.isdigit())\n",
    "        return int(digits) if digits else -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c6a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_ROOT = Path('/content/drive/MyDrive/ML_HSG/kaggle_data/testset/testset')\n",
    "if not TEST_ROOT.exists():\n",
    "    raise FileNotFoundError(f\"Expected test directory at {TEST_ROOT}\")\n",
    "\n",
    "npy_paths = sorted(TEST_ROOT.glob('*.npy'))\n",
    "if not npy_paths:\n",
    "    npy_paths = sorted(TEST_ROOT.glob('**/*.npy'))\n",
    "\n",
    "if len(npy_paths) == 0:\n",
    "    raise FileNotFoundError('No .npy files found in Kaggle test directory')\n",
    "\n",
    "print(f\"Found {len(npy_paths)} inference tiles\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "kaggle_dataset = EuroSATNPYDataset(npy_paths, processor)\n",
    "kaggle_loader = DataLoader(kaggle_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "model.eval()\n",
    "pred_ids = []\n",
    "pred_indices = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(kaggle_loader, desc='Kaggle inference'):\n",
    "        pixel_values = batch['pixel_values'].to(DEVICE, non_blocking=True)\n",
    "        logits = get_model_logits(model, pixel_values)\n",
    "        preds = logits.argmax(dim=1).cpu().tolist()\n",
    "        pred_indices.extend(preds)\n",
    "        if isinstance(batch['id'], torch.Tensor):\n",
    "            pred_ids.extend(batch['id'].cpu().tolist())\n",
    "        else:\n",
    "            pred_ids.extend(batch['id'])\n",
    "\n",
    "pred_labels = [IDX_TO_CLASS[idx] for idx in pred_indices]\n",
    "submission = pd.DataFrame({'test_id': pred_ids, 'label': pred_labels})\n",
    "submission = submission.sort_values('test_id').reset_index(drop=True)\n",
    "\n",
    "submission_name = f'submission_with_cirrus_{RUN_TIMESTAMP}.csv'\n",
    "submission_path = Path('/content') / submission_name\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Saved submission to {submission_path}\")\n",
    "print(submission.head())\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "drive_submission_path = OUTPUT_DIR / submission_name\n",
    "shutil.copy2(submission_path, drive_submission_path)\n",
    "print(f\"Copied submission to {drive_submission_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
